"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"DrivEmo: A Novel Approach for EEG-Based Emotion Classification for Drivers","T. A. Gamage; E. R. C. Sandamali; P. Kalansooriya","Department of Computer Science, General Sir John Kotelawala Defence University, Sri Lanka; Department of Computational Mathematics, General Sir John Kotelawala Defence University, Sri Lanka; Department of Computer Science, General Sir John Kotelawala Defence University, Sri Lanka",2023 International Research Conference on Smart Computing and Systems Engineering (SCSE),"17 Aug 2023","2023","6","","1","6","Electroencephalogram (EEG) based emotion recognition approaches have proven to be successful with the latest technologies, and therefore, driver emotion recognition is also being widely discussed for enhancing road safety. This paper reveals a unique approach to driver emotion recognition for the calm, fear, sad, and anger emotional states where calm is the desired state of mind while driving. Emotiv EPOC X 14 channel EEG headset is utilised for the EEG collection, and ten subjects are involved in the experiment. EEG preprocessing of the collected EEG data is done using the EEGLAB toolbox in Matlab. EEG feature extraction is performed using Matlab, and feature selection and classification model training is done using the Classification Learner app in Matlab. ANOVA and ReliefF are employed as the feature selection algorithms, and Support Vector Machine (SVM) and Naïve Bayes classifiers are utilised for the emotion classification. The outcomes reveal that the highest mean accuracy of 95% is achieved from the Coarse Gaussian SVM classifier, while the lowest mean accuracy of 85% is obtained from the Fine Gaussian SVM classifier detecting the calm, fear, sad, and anger emotional states. In addition, all the other trained classifier models have an accuracy between 85% and 95%. Therefore, the findings suggest that the proposed EEG-based implementation approach of an emotion classification model for drivers is highly successful and can be employed in future research in the paradigm of driver emotion recognition as well. Besides, this research presents a critical literature review concerning critical aspects of EEG-based emotion recognition research.","2613-8662","979-8-3503-4145-4","10.1109/SCSE59836.2023.10215028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10215028","EEG;emotion recognition;feature extraction;feature selection;road safety","Support vector machines;Training;Emotion recognition;Feature extraction;Brain modeling;Electroencephalography;Mathematical models","","1","","48","IEEE","17 Aug 2023","","","IEEE","IEEE Conferences"
"An Emotion Classification Model for Driver Emotion Recognition Using Electroencephalography (EEG)","T. A. Gamage; L. P. Kalansooriya; E. R. C. Sandamali","Department of Computer Science, General Sir John Kotelawala Defence University, Sri Lanka; Department of Computer Science, General Sir John Kotelawala Defence University, Sri Lanka; Dept. of Computational Mathematics, General Sir John Kotelawala Defence University, Sri Lanka",2022 International Research Conference on Smart Computing and Systems Engineering (SCSE),"4 Oct 2022","2022","5","","76","82","Road accidents have been a critical issue that has resulted in fatal injuries, disabilities, and deaths for many individuals worldwide. The notion of Human-Computer Interaction (HCI) is widely considered in monitoring drivers to safeguard their lives on roads. As a solution to the issue of the higher rate of road accidents, driver emotion recognition approaches have gained much attention, and the involvement of biological signals in detecting the emotional states of drivers is also significant. The authors have conducted a comprehensive literature review that concerns contemporary literature on the driver emotion recognition paradigm and comes up with four emotional states in this research to monitor the drivers' affective states. This paper presents a novel approach to detecting sad, angry, fearful, and calm emotional states of drivers with an emotion classification model using Electroencephalography (EEG) signals where the EEG data acquisition for the research is done using the Emotiv EPOC X device. The collected EEG data are preprocessed using the EEGLAB toolbox in Matlab, and feature extraction, selection, and emotion classification model training are done using Matlab. EEG acquisition and preprocessing have already been achieved, and as further work, the authors are to train the proposed emotion classification model as laid out in this paper. The findings of this research encourage the authors to continue towards the completion and provide further insights into enhancing research in the driver emotion recognition paradigm.","2613-8662","978-1-6654-7375-0","10.1109/SCSE56529.2022.9905108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9905108","driver emotion recognition;EEG;EEGLAB;emotion classification;road safety","Human computer interaction;Emotion recognition;Road accidents;Brain modeling;Electroencephalography;Mathematical models;Data models","","7","","34","IEEE","4 Oct 2022","","","IEEE","IEEE Conferences"
"EEG-Based on Emotion Recognition Using Machine Learning","Y. Zhang","Huazhong Agricultural University, Wuhan, China",2023 IEEE International Conference on Image Processing and Computer Applications (ICIPCA),"27 Sep 2023","2023","","","226","232","Emotion is of great significance in human's daily interaction. Contemporarily, emotion recognition systems are beneficial in various areas, ranging from human-computer interaction (HCI) system to healthcare safety. So far, the Electroencephalogram (EEG) has received much attention because of its sensitivity to mood changes. However, the relationship hasn't been fully researched. To investigate the relationship among emotions, bands, channels and find a better classifier, this experiment organize the framework based on the DEAP dataset. After the data preprocessing, EEG data is reduced by principal component analysis (PCA). Then to create the emotion feature vectors, the discrete wavelet transform (DWT) is chosen as the parameter. Lastly, to categorize the EEG signal, support vector machine (SVM), random forest (RF), k-nearest neighbor (KNN), XGboost model is created. According to the experiment, this paper obtained the following relevant conclusions: 1) RF, SVM, KNN and XGboost classifier, performed with the accuracy of 77.01%, 80.44%, 66.75% and 77.75%, respectively; 2) In temperal and whole brain regions, gamma has the highest recognition ability, reaching 76.77% and 77.02%. The beta performs best in occipital, parietal, and central regions with 78.00%, 77.26%, and 78.00%, respectively; 3) The higher the frequency, the greater the oscillatory dynamics of brain activity on positive / negative emotions; 4) The AF3, AF4 area has a greater effect in reflecting emotions because of less irrelevant influences.","","979-8-3503-1467-0","10.1109/ICIPCA59209.2023.10257784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10257784","EEG;emotion recognition;DEAP;machine learning","Support vector machines;Human computer interaction;Emotion recognition;Sensitivity;Transforms;Brain modeling;Electroencephalography;Discrete wavelet transforms;Classification tree analysis;Principal component analysis","","","","11","IEEE","27 Sep 2023","","","IEEE","IEEE Conferences"
"A Review on Face Emotion Recognition using EEG Features and Facial Features","S. A. Bhosale; S. R. Chougule","Department of Electronics Engineering, KITCOE Research Center, Shivaji Univesity, Kolhapur, India; Department of Electronics Engineering, KITCOE Research Center, Shivaji Univesity, Kolhapur, India",2023 1st International Conference on Cognitive Computing and Engineering Education (ICCCEE),"12 Feb 2024","2023","","","1","5","Emotions recognition using feature extraction from face, Speech and EEG signal have become emerging research field. It has contributed in different research areas like safety, biomedical sector, industrial automation and Human Computer Interface. Deep Learning approach using Convolution Neural Networks (CNN) has provided better results in obtaining an accuracy in Facial Emotion Recognition. Researcher are trying to get better results by using a novel approach along with CNN’s to obtain better results. This paper will help the researchers to understand the novel approach in Deep Learning used for Facial Emotion Recognition (FER) with different techniques and Electroencephalogram (EEG) based emotion recognition classified on basis of Valence, Arousal and Dominance with different datasets like DEAP (Database of Emotion Analysis using Physiological signals), SEED (SJTU Emotion EEG Dataset). The review provided use of different dataset and the accuracy of models while using those dataset along with the novel approaches in Emotion Recognition. This paper also reviews different algorithms, architectures and recent work carried by different researchers.","","979-8-3503-3280-3","10.1109/ICCCEE55951.2023.10424432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10424432","Facial Emotion Recognition;CNN;Deep Learning;EEG and database","Deep learning;Emotion recognition;Databases;Face recognition;Computer architecture;Electroencephalography;Facial features","","1","","39","IEEE","12 Feb 2024","","","IEEE","IEEE Conferences"
"Emotional State Evaluation during Collision Avoidance Operations of Seafarers Using Ship Bridge Simulator and Wearable EEG","Z. Wang; J. Zhang; Z. Mao; S. Fan; Z. Wang; H. Wang","Intelligent Transportation Systems Center, Wuhan University of Technology; National Engineering Research Center for Water Transport Safety, Wuhan University of Technology, Inland Port and Shipping Industry Researc Co. Ltd., Guangdong, China; Intelligent Transportation Systems Center, Wuhan University of Technology; National Engineering Research Center for Water Transport Safety, Wuhan University of Technology, Inland Port and Shipping Industry Researc Co. Ltd., Guangdong, China; Intelligent Transportation Systems Center, Wuhan University of Technology; National Engineering Research Center for Water Transport Safety, Wuhan University of Technology, Wuhan, China; Liverpool Logistics, Offshore and Marine (LOOM) Research Institute, Liverpool John Moores University, Liverpool, UK; Zhangjiagang Maritime Safety Administration, Jiangsu, China; Zhangjiagang Maritime Safety Administration, Jiangsu, China",2021 6th International Conference on Transportation Information and Safety (ICTIS),"27 Jun 2022","2021","","","415","422","Seafarers' emotional states (e.g., pleasure, displeasure, excitement, and stress) has been proved as a critical factor that affects their performance during collision avoidance operations. The emotion can be quantified using an electroencephalogram (EEG) sensor to reflect its correlations with human performance. Given the advantages of wearable EEG (portable, wireless and high resolutions), it provides an effective method for non-intrusive emotion measurement. This study conducted experiments to measure the emotional states of the seafarers. Firstly, two encounter situations based on the ship bridge simulator were formulated for the test. During the experiments, the participants were required to wear an EEG that measures brain activity reflecting the emotional states of seafarers while operating using the ship bridge simulator. At the same time, the trajectories of vessel movement were recorded accordingly. Next, a bipolar dimensional emotion model consisting of valence (from displeasure to pleasure) and arousal (from relaxation to excitement) dimensions, was generated to identify seafarers' emotional states. Integrated with vessel trajectory data (such as rudder angle, ship speed, etc.), the correlation analysis was conducted to explore the patterns of seafarers' emotion during collision avoidance operations. The results show that the emotional states of seafarers varied in different ship encounter situations and were closely related to the vessel trajectory. Also, it demonstrated the applicability of wearable EEG technology in emotional state evaluations for seafarers.","","978-1-6654-9713-8","10.1109/ICTIS54573.2021.9798643","National Natural Science Foundation of China(grant numbers:52071247); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9798643","maritime transportation;maritime safety;electroencephalogram;emotion;ship bridge simulator","Bridges;Wireless sensor networks;Correlation;Atmospheric measurements;Navigation;Particle measurements;Electroencephalography","","","","17","IEEE","27 Jun 2022","","","IEEE","IEEE Conferences"
"Efficient Sample and Feature Importance Mining in Semi-Supervised EEG Emotion Recognition","X. Li; F. Shen; Y. Peng; W. Kong; B. -L. Lu","School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Circuits and Systems II: Express Briefs,"28 Jun 2022","2022","69","7","3349","3353","Recently, electroencephalogram (EEG)-based emotion recognition has attracted increasing interests in research community. The weak, non-stationary, multi-rhythm and multi-channel properties of EEG data easily cause the extracted EEG samples and features contribute differently in recognizing emotional states. However, existing studies either failed to consider both the issues of sample and feature importance or only considered one of them. In this brief, we propose a new model termed sJSFE (semi-supervised Joint Sample and Feature importance Evaluation) to quantitatively measure the sample and feature importance by self-paced learning and feature self-weighting respectively. Experimental results on the SEED-IV data set show that the emotion recognition performance is greatly improved by mining both the sample and feature importance. Specifically, the average accuracy obtained by sJSFE across the three cross-session recognition tasks is 82.45%, which is respectively 3.72% and 7.21% and 10.47% and 18.82% higher than the results of traditional models. Besides, the feature importance vector depicts that the Gamma frequency band contributes the most, and the brain regions of prefrontal, left/right temporal and (central) parietal lobes correlate more to emotion recognition. The sample importance descriptor shows that continual transitions of video types in consecutive trials might weaken the feature-label consistency of the collected EEG data.","1558-3791","","10.1109/TCSII.2022.3163141","National Key Research and Development Program of China(grant numbers:2017YFE0116800); National Natural Science Foundation of China(grant numbers:61971173); Fundamental Research Funds for the Provincial Universities of Zhejiang(grant numbers:GK209907299001-008); CAAC Key Laboratory of Flight Techniques and Flight Safety(grant numbers:FZ2021KF16); Guangxi Key Laboratory of Optoelectronic Information Processing (Guilin University of Electronic Technology)(grant numbers:GD21202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9744018","EEG;emotion recognition;feature importance;sample importance;semi-supervised learning","Electroencephalography;Emotion recognition;Brain modeling;Task analysis;Feature extraction;Data models;Data mining","","9","","15","IEEE","29 Mar 2022","","","IEEE","IEEE Journals"
"An investigation of pilot emotion change detection based on multimodal physiological signals","F. Wei; D. Wu; D. Chen","College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China",2020 IEEE 2nd International Conference on Civil Aviation Safety and Information Technology (ICCASIT,"9 Mar 2021","2020","","","1029","1034","Aviation safety assurance is the most important point in the course of civil aviation flight. During the flight, the control of the aircraft and the handling of emergencies are also closely related to the emotional changes of pilots. This paper collects pilot physiological signals, performs signal preprocessing, signal feature extraction, classification, etc., and finally establishes a model of emotion-physiological signal. The classification accuracy of this model for Valence, Arousal and Dominance is 0.9413, 0.9735 and 0.9804, respectively, which proves the feasibility of using biological signals to classify pilot emotions.","","978-1-7281-9948-1","10.1109/ICCASIT50869.2020.9368711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9368711","Flight simulation;physiological signals;emotion recognition","Support vector machines;Radio frequency;Emotion recognition;Feature extraction;Brain modeling;Physiology;Safety","","3","","11","IEEE","9 Mar 2021","","","IEEE","IEEE Conferences"
"A smart HMI for driving safety using emotion prediction of EEG signals","G. S. Thirunavukkarasu; H. Abdi; N. Mohajer","Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Australia; Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Australia; Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Australia","2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","9 Feb 2017","2016","","","004148","004153","This paper provides an overview on the past pieces of literature on emotion prediction systems and the different machine learning algorithms used to classify emotions. We propose a system which incorporates the emotion prediction system with a custom Smart Human Machine Interface (SHMI) for vehicle drivers to improve drive safety. This is achieved based on EEG signals and basic vehicle information's obtained from an OBD (On-Board Diagnostics) data. EEG signals are classified into four emotional states: happy, sad, relaxed and angry. In this paper, we present an initial development of the Smart Human Machine Interface (SHMI) for emotion detection for vehicle applications. To evaluate the classification of the EEG signals we use Russell's circumflex model, Higuchi Fractal Dimension (HFD), PSD (Power Spectral Density) for feature extraction and Support Vector Machines (SVM) for classification.","","978-1-5090-1897-0","10.1109/SMC.2016.7844882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7844882","Electroencephalogram (EEG) Sensors;Smart Human Machine Interface (SHMI);Support Vector Machines (SVM);PSD (Power Spectral Density);OBD (On-Board Diagnostics);Higuchi Fractal Dimension (HFD)","Support vector machines;Music;Electroencephalography;Niobium;Feature extraction;Modems;Emotion recognition","","15","","45","IEEE","9 Feb 2017","","","IEEE","IEEE Conferences"
"An EEG Data Processing Approach for Emotion Recognition","G. Li; D. Ouyang; Y. Yuan; W. Li; Z. Guo; X. Qu; P. Green","Institute of Human Factors and Ergonomics, College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, China; Institute of Human Factors and Ergonomics, College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, China; Institute of Human Factors and Ergonomics, College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, China; State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility, Tsinghua University, Beijing, China; School of Transportation and Logistics, Southwest Jiaotong University, Chengdu, China; Institute of Human Factors and Ergonomics, College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, China; Department of Industrial and Operations Engineering, University of Michigan Transportation Research Institute (UMTRI), University of Michigan, Ann Arbor, MI, USA",IEEE Sensors Journal,"30 May 2022","2022","22","11","10751","10763","As the most direct way to measure the true emotional states of humans, EEG-based emotion recognition has been widely used in affective computing applications. In this paper, we aim to propose a novel emotion recognition approach that relies on a reduced number of EEG electrode channels and at the same time overcomes the negative impact of individual differences to achieve a high recognition accuracy. According to the statistical significance results of EEG power spectral density (PSD) features obtained from the SJTU Emotion EEG Dataset (SEED), six candidate sets of EEG electrode channels are determined. An experiment-level batch normalization (BN) is proposed and applied on the features from the candidate sets, and the normalized features are then used for emotion recognition across individuals. Eleven well-accepted classifiers are used for emotion recognition. The experimental results show that the recognition accuracy when using a small portion of the available electrodes is almost the same or even better than that when using all the channels. Based on the reduced number of electrode channels, the application of experiment-level BN can help further improve the recognition accuracy, specifically from 73.33% to 89.63% when using the LR classifier. These results demonstrate that better and easier emotion recognition performance can be achieved based on the batch normalized features from fewer channels, indicating promising applications of our proposed method in real-time emotion recognition applications in intelligent systems.","1558-1748","","10.1109/JSEN.2022.3168572","NSF China(grant numbers:51805332,52072320); Shenzhen Fundamental Research and Discipline Layout project(grant numbers:JCYJ20190808142613246,20200803015912001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761248","Electroencephalogram (EEG);emotion recognition;electrode channels selection;batch normalization;individual difference","Emotion recognition;Electroencephalography;Electrodes;Feature extraction;Sensors;Neural networks;Deep learning","","39","","67","IEEE","21 Apr 2022","","","IEEE","IEEE Journals"
"4D Recurrent Neural Network Based on Time-Space-Frequency Domain Fusion for EEG Emotion Recognition","H. Yang; M. Wang","College of Arts and Sciences, Northeast Agricultural University, Harbin, China; College of Arts and Sciences, Northeast Agricultural University, Harbin, China",2022 IEEE 4th International Conference on Civil Aviation Safety and Information Technology (ICCASIT),"27 Dec 2022","2022","","","230","236","In recent years, EEG emotion recognition has had broad prospects in various research fields. Most of the existing EEG identification studies use a single feature and do not simultaneously consider the effects of EEG information on time, space and frequency. However, neuroscience shows that the response degree of emotion depends on the EEG channels of different frequencies. In this paper, A recursive neural network approach is proposed to analyze EEG signals at different times and regions by integrating the time domain, frequency domain, and space domain. Firstly, the 2D channel map is extracted to obtain frequency domain features, and then the 2D channel map with different frequency domain features is fused to obtain 3D spatial frequency domain data. Finally, the 3D data in different time periods are connected to obtain the 4D feature structure used for the training depth model. 4D data feature makes up for the defect that a single feature cannot perceive channel information of different frequencies and produce a more significant effect than single feature emotion recognition. Experiments on the SEED data set show that the multi-feature fusion model performs better than other models in EEG emotion recognition.","","978-1-6654-6766-7","10.1109/ICCASIT55263.2022.9986771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9986771","emotion recognition;feature fusion;RNN neural network","Training;Emotion recognition;Time-frequency analysis;Recurrent neural networks;Three-dimensional displays;Brain modeling;Feature extraction","","","","10","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"Joint Feature Adaptation and Graph Adaptive Label Propagation for Cross-Subject Emotion Recognition From EEG Signals","Y. Peng; W. Wang; W. Kong; F. Nie; B. -L. Lu; A. Cichocki","School of Computer Science and Technology, Zhejiang Key Laboratory of Brain-Machine Collaborative Intelligence, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Zhejiang Key Laboratory of Brain-Machine Collaborative Intelligence, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Zhejiang Key Laboratory of Brain-Machine Collaborative Intelligence, Hangzhou Dianzi University, Hangzhou, China; School of Artificial Intelligence, OPtics and ElectroNics (iOPEN), Northwestern Polytechnical University, Xi’an, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Center for Computational and Data-Intensive Science and Engineering, Skolkov Institute of Science and Technology, Moscow, Russia",IEEE Transactions on Affective Computing,"28 Nov 2022","2022","13","4","1941","1958","Though Electroencephalogram (EEG) could objectively reflect emotional states of our human beings, its weak, non-stationary, and low signal-to-noise properties easily cause the individual differences. To enhance the universality of affective brain-computer interface systems, transfer learning has been widely used to alleviate the data distribution discrepancies among subjects. However, most of existing approaches focused mainly on the domain-invariant feature learning, which is not unified together with the recognition process. In this paper, we propose a joint feature adaptation and graph adaptive label propagation model (JAGP) for cross-subject emotion recognition from EEG signals, which seamlessly unifies the three components of domain-invariant feature learning, emotional state estimation and optimal graph learning together into a single objective. We conduct extensive experiments on two benchmark SEED_IV and SEED_V data sets and the results reveal that 1) the recognition performance is greatly improved, indicating the effectiveness of the triple unification mode; 2) the emotion metric of EEG samples are gradually optimized during model training, showing the necessity of optimal graph learning, and 3) the projection matrix-induced feature importance is obtained based on which the critical frequency bands and brain regions corresponding to subject-invariant features can be automatically identified, demonstrating the superiority of the learned shared subspace.","1949-3045","","10.1109/TAFFC.2022.3189222","National Natural Science Foundation of China(grant numbers:61971173,U20B2074); National Key Research and Development Program of China(grant numbers:2017YFE0116800); Fundamental Research Funds for the Provincial Universities of Zhejiang(grant numbers:GK209907299001-008); Natural Science Foundation of Zhejiang Province(grant numbers:LY21F030005); China Postdoctoral Science Foundation(grant numbers:2017M620470); CAAC Key Laboratory of Flight Techniques and Flight Safety(grant numbers:FZ2021KF16); Guangxi Key Laboratory of Optoelectronic Information Processing(grant numbers:GD21202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817639","Electroencephalogram (EEG);emotion recognition;feature adaptation;graph learning;label propagation","Electroencephalography;Brain modeling;Emotion recognition;Data models;Adaptation models;Training;State estimation","","19","","60","IEEE","7 Jul 2022","","","IEEE","IEEE Journals"
"Research on Multimodal Emotion Recognition Based on Fusion of Electroencephalogram and Electrooculography","J. Yin; M. Wu; Y. Yang; P. Li; F. Li; W. Liang; Z. Lv","AHU-IAI AI Joint Laboratory, Anhui University, Hefei, China; Laboratory of Intelligent Information and Human-Computer Interaction, Anhui University, Hefei, China; State Key Laboratory of Brain and Cognitive Sciences, Institute of Biophysics (IBP), Chinese Academy of Sciences, Beijing, China; Laboratory of Intelligent Information and Human-Computer Interaction, Anhui University, Hefei, China; Key Laboratory of Flight Techniques and Flight Safety, Civil Aviation Flight University of China, Guanghan, China; Google Research, Mountain View, CA, USA; Key Laboratory of Flight Techniques and Flight Safety, Civil Aviation Flight University of China, Guanghan, China",IEEE Transactions on Instrumentation and Measurement,"6 Mar 2024","2024","73","","1","12","Emotion recognition plays a vital role in building a harmonious society and emotional interaction. Recent research has demonstrated that multimodal interchannel correlations and insufficient emotion elicitation plague deep learning-based emotion identification techniques. To cope with these problems, we propose a multimodal and channel attention fusion transformer (MCAF-Transformer). First, we employ an olfactory video approach to evoke emotional expression more fully and acquire electroencephalogram (EEG) and electrooculography (EOG) signal data. Second, the model makes full use of multimodal channel information, time-domain and spatial-domain information of EEG and EOG signals, captures the correlation of different channels using channel attention, and improves the accuracy of emotion recognition by focusing on the global dependence on the temporal order using the transformer. We conducted extensive experiments on the olfactory video sentiment dataset, and the experimental results were correct at 94.63%. The results show that olfactory videos evoke emotion more adequately than pure videos and that the MCAF-Transformer model significantly outperforms other emotion recognition methods.","1557-9662","","10.1109/TIM.2024.3370813","National Natural Science Foundation of China (NSFC)(grant numbers:61972437); Distinguish Youth Foundation of Anhui Scientific Committee(grant numbers:2208085J05); Open Fund of Key Laboratory of Flight Techniques and Flight Safety, Civil Aviation Administration of China (CAAC)(grant numbers:FZ2022KF15); Special Fund for Key Program of Science and Technology of Anhui Province(grant numbers:202203a07020008); Cloud Ginger XR-1 Platform; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10445754","Attention mechanisms;electroencephalogram (EEG) and electrooculography (EOG);multimodal;olfactory video emotion evocation;transformer","Electroencephalography;Feature extraction;Emotion recognition;Brain modeling;Transformers;Electrooculography;Time-domain analysis","","","","45","IEEE","27 Feb 2024","","","IEEE","IEEE Journals"
"Using EEG to detect drivers' emotion with Bayesian Networks","X. -A. Fan; L. -Z. Bi; Z. -L. Chen","School of Mechanical and Vehicular Engineering, Beijing Institute of Technology, Beijing, China; School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China; School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China",2010 International Conference on Machine Learning and Cybernetics,"20 Sep 2010","2010","3","","1177","1181","Driver behavior plays a critical role in driving safety. Besides alcohol and fatigue, emotion is another factor influencing driver behavior. Thus, the detection of driver emotion can contribute to improve driving safety. In this paper, we use Bayesian Network (BNs) to develop a detection model of driver emotion with electroencephalogram (EEG), which considers two factors of driver personality and traffic situation. The preliminary experiment results suggest that this method is feasible and therefore can be used to provide adaptive aiding.","2160-1348","978-1-4244-6527-9","10.1109/ICMLC.2010.5580919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580919","Driver emotion;Driving safety;EEG;Detection model;Bayesian Networks","Brain modeling;Driver circuits;Electroencephalography;Bayesian methods;Probability distribution;Safety;Biological system modeling","","17","","16","IEEE","20 Sep 2010","","","IEEE","IEEE Conferences"
"Multimodal Emotion Recognition Based on EEG and EOG Signals Evoked by the Video-Odor Stimuli","M. Wu; W. Teng; C. Fan; S. Pei; P. Li; G. Pei; T. Li; W. Liang; Z. Lv","Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China; Zhejiang Laboratory, Institute of Artificial Intelligence, Hangzhou, China; Zhejiang Laboratory, Institute of Artificial Intelligence, Hangzhou, China; Google Inc., Mountain View, CA, USA; Zhejiang Laboratory, Institute of Artificial Intelligence, Hangzhou, China",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"20 Sep 2024","2024","32","","3496","3505","Affective data is the basis of emotion recognition, which is mainly acquired through extrinsic elicitation. To investigate the enhancing effects of multi-sensory stimuli on emotion elicitation and emotion recognition, we designed an experimental paradigm involving visual, auditory, and olfactory senses. A multimodal emotional dataset (OVPD-II) that employed the video-only or video-odor patterns as the stimuli materials, and recorded the electroencephalogram (EEG) and electrooculogram (EOG) signals, was created. The feedback results reported by subjects after each trial demonstrated that the video-odor pattern outperformed the video-only pattern in evoking individuals’ emotions. To further validate the efficiency of the video-odor pattern, the transformer was employed to perform the emotion recognition task, where the highest accuracy reached 86.65% (66.12%) for EEG (EOG) modality with the video-odor pattern, which improved by 1.42% (3.43%) compared with the video-only pattern. What’s more, the hybrid fusion (HF) method combined with the transformer and joint training was developed to improve the performance of the emotion recognition task, which achieved classify accuracies of 89.50% and 88.47% for the video-odor and video-only patterns, respectively.","1558-0210","","10.1109/TNSRE.2024.3457580","National Natural Science Foundation of China(grant numbers:62476004); Excellent Youth Foundation of Anhui Scientific Committee(grant numbers:2208085J05); National Key Research and Development Program of China(grant numbers:2021ZD0201502); Special Fund for Key Program of Science and Technology of Anhui Province(grant numbers:202203a07020008); Natural Science Foundation of Anhui Province(grant numbers:2108085MF207); Open Research Projects of Zhejiang Laboratory(grant numbers:2021KH0AB06); Open Projects Program of National Laboratory of Pattern Recognition(grant numbers:202200014); Open Fund Project of Key Laboratory of Civil Aviation Flight Technology and Flight Safety(grant numbers:FZ2022KF15); Cloud Ginger XR-1(grant numbers:FZ2022KF15); Cloud Ginger(grant numbers:XR-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10672559","Electroencephalogram (EEG);electrooculogram (EOG);emotion recognition;video-odor stimuli;multi-modal fusion","Electroencephalography;Videos;Emotion recognition;Electrooculography;Physiology;Feature extraction;Electrodes","Humans;Electroencephalography;Emotions;Male;Female;Young Adult;Electrooculography;Adult;Odorants;Algorithms;Video Recording;Photic Stimulation;Reproducibility of Results;Healthy Volunteers","2","","45","CCBYNCND","10 Sep 2024","","","IEEE","IEEE Journals"
"Affective Brain-Computer Interfaces: The Significance of P300 Components in Emotion Detection and Classification","C. Cheng; Y. Liu; C. Liao","Xi'an Shiyou University, Xi'an, China; Xi'an Shiyou University, Xi'an, China; School of Computer Science, Xi'an Shiyou University, Xi'an, China",2023 2nd International Conference on Artificial Intelligence and Intelligent Information Processing (AIIIP),"6 Feb 2024","2023","","","357","361","This paper provides an in-depth analysis around the application of P300 EEG signals in EEG emotion recognition. The P300 components in the SEED dataset are extracted by peak detection method and the 4D-CRNN model is improved, which confirms the effectiveness of the P300 components in emotion recognition. The improved model has high accuracy and good generalization ability in the emotion classification task. The model not only adapts to the characteristics of P300 signals, but also shows good performance in the emotion classification task. This study reinforces the importance of the P300 component in emotion recognition, contributes new value to emotion learning datasets in the field of emotional brain-computer interfaces and provides new perspectives and clues for subsequent research in related fields.","","979-8-3503-7145-1","10.1109/AIIIP61647.2023.00075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10417638","emotion recognition;affective brain-computer interface;P300 component","Training;Emotion recognition;Adaptation models;Brain modeling;Electroencephalography;Brain-computer interfaces;Task analysis","","","","10","IEEE","6 Feb 2024","","","IEEE","IEEE Conferences"
"MASTF-net: An EEG Emotion Recognition Network Based on Multi-Source Domain Adaptive Method Based on Spatio-Temporal Image and Frequency Domain Information","H. Xu; Z. Pei; Q. Han; M. Hou; X. Qian; T. Weng; Y. Tian; Z. Qiu; B. Zhou","School of Intelligent Technology and Engineering, Chongqing University of Science and Technology, Chongqing, China; School of Materials Science and Engineering, Chongqing University of Arts and Sciences, Chongqing, China; School of Intelligent Technology and Engineering, Chongqing University of Science and Technology, Chongqing, China; School of Intelligent Technology and Engineering, Chongqing University of Science and Technology, Chongqing, China; School of Intelligent Technology and Engineering, Chongqing University of Science and Technology, Chongqing, China; School of Electrical Engineering, Chongqing University of Science and Technology, Chongqing, China; School of Intelligent Technology and Engineering, Chongqing University of Science and Technology, Chongqing, China; School of Intelligent Technology and Engineering, Chongqing University of Science and Technology, Chongqing, China; College of Information Engineering, Tarim University, Alar, China",IEEE Access,"19 Jan 2024","2024","12","","8485","8501","In the field of neuroscience, the electroencephalogram (EEG) is a crucial indicator of emotion. The EEG emotion recognition method based on domain adaptation (DA) has good objectivity and high time resolution and is the preferred method to study the brain’s response to emotional stimuli. However, due to the obvious instability of EEG emotion characteristics, it is difficult to predict the emotion corresponding to EEG signals of cross-subjects by a model that combines all source domains into a single source. In order to solve the problem of cross-subject emotion analysis, we propose an EEG emotion recognition net with a cross-subject multi-source adaptive method (MASTF-net), where EEG features of different subjects are regarded as different domains. Through analyzing the invariance of the target domain and the uniqueness of the source domain, this method realizes the emotional analysis of different objects according to the spatio-temporal images and frequency domain information. First, features of EEG image are extracted from frequency and time dimensions. Secondly, combined with the serialized EEG frequency characteristics of local brain regions, independent classification module are established for different domains to recognize the emotion feature distribution of different subjects. In addition, a feature extraction method of differential entropy(DE) data of EEG is proposed based on frequency band division, which can provide stable feature input for our network structure. Finally, experiments are conducted on the SEED dataset. The experimental results show that our method has better classification accuracy in the experiment on the problem of cross multiple subjects. MASTF-net is superior to other relevant methods and models in multi-source domain. On the issue of cross subject emotion analysis, the highest accuracy of our method can reach  $88.19\%$ .","2169-3536","","10.1109/ACCESS.2024.3349552","West Light Foundation of the Chinese Academy of Sciences; Research Foundation of the Natural Foundation of Chongqing City(grant numbers:cstc2021jcyj-msxmX0146,cstc2021jcyj-msxmX1212); Scientific and Technological Research Program of the Chongqing Municipal Education Commission(grant numbers:KJQN202301517,HZ2021015,KJZD-K202100104,KJQN202301543); Chongqing Science and Technology Military-Civilian Integration Innovation Project, in 2022; Bingtuan Science and Technology Program in China(grant numbers:2021AB026); Shanxi Province Applied Basic Research Program, China(grant numbers:202203021211116); Oil and Gas Production Safety and Risk Control Key Laboratory of Chongqing Open Fund(grant numbers:cqsrc202110); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10380564","Cross-subject;domain adaptation;electroencephalogram;emotional stimuli;spatiotemporal image","Electroencephalography;Feature extraction;Emotion recognition;Brain modeling;Adaptive systems;Time-frequency analysis;Motion pictures","","1","","44","CCBY","4 Jan 2024","","","IEEE","IEEE Journals"
"Research on the dynamic changes of drivers' emotion in long tunnel base on EEG","J. Yan; P. Tao; P. Shao; W. Xiu; L. Wang","School of Electrical and Control Engineering North China University of Technology, Beijing, China; School of Electrical and Control Engineering North China University of Technology, Beijing, China; School of Electrical and Control Engineering North China University of Technology, Beijing, China; School of Electrical and Control Engineering North China University of Technology, Beijing, China; School of Electrical and Control Engineering North China University of Technology, Beijing, China",2017 Chinese Automation Congress (CAC),"1 Jan 2018","2017","","","6943","6946","Electroencephalogram (EEG) is a widely used experimental tool in psychological research. In this study, we used EEG to research the driving safety by measuring the dynamic changes of drivers' emotions in a long tunnel. Through the study whether there was a tunnel, and whether there was a large amount of traffic flow in the tunnel, we found a long tunnel only makes a slight negative effect on driver's emotion, but a large amount of traffic flow could make an obvious negative effect on driver's emotion. As driver's negative emotions could lower the driving safety in the tunnel, we should control the traffic flow in the tunnel to reduce the possibility of congestion.","","978-1-5386-3524-7","10.1109/CAC.2017.8244029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8244029","EEG;long tunnel;emotion;driving safety","Electroencephalography;Vehicles;Accidents;Safety;Physiology;Roads;Control engineering","","3","","20","IEEE","1 Jan 2018","","","IEEE","IEEE Conferences"
"Sex Difference in Emotion Recognition under Sleep Deprivation: Evidence from EEG and Eye-tracking","R. -X. Ma; X. Yan; Y. -Z. Liu; H. -L. Li; B. -L. Lu","Center for Brain-Like Computing and Machine Intelligence, Department of Computer Science and Engineering, the Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, the Brain Science and Technology Research Center, and Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China; Department of Linguistics, University of Washington, Seattle, WA, USA; Key Laboratory of Occupational Health and Safety of Guangdong Power Grid Co., Ltd, Electric Power Research Institute of Guangdong Power Grid Co.,Ltd., Guangzhou, China; Key Laboratory of Occupational Health and Safety of Guangdong Power Grid Co., Ltd, Electric Power Research Institute of Guangdong Power Grid Co.,Ltd., Guangzhou, China; Center for Brain-Like Computing and Machine Intelligence, Department of Computer Science and Engineering, the Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, the Brain Science and Technology Research Center, and Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China",2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"9 Dec 2021","2021","","","6449","6452","Many psychiatric disorders are accompanied with sleep abnormalities, having significant influence on emotions which might worsen the disorder conditions. Previous studies discovered that the emotion recognition task with objective physiological signals, such as electroencephalography (EEG) and eye movements, provides a reliable way to figure out the complicated relationship between emotion and sleep. However, both of the emotion and EEG signals are affected by sex. This study aims to investigate how sex differences influence emotion recognition under three different sleep conditions. We firstly developed a four-class emotion recognition task based on various sleep conditions to augment the existing dataset. Then we improved the current state-of-the-art deep-learning model with the attention mechanism. It outperforms the best model with higher accuracy about 91.3% and more stabilization. After that, we compared the results of the male and the female group given by this model. The classification accuracy of happy emotion obviously decreases under sleep deprivation for both males and females, which indicates that sleep deprivation impairs the stimulation of happy emotion. Sleep deprivation also notably weakens the discrimination ability of sad emotion for males while females maintain the same as under common sleep. Our study is instructively beneficial to the real application of emotion recognition in disorder diagnosis.","2694-0604","978-1-7281-1179-7","10.1109/EMBC46164.2021.9630808","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; China Southern Power Grid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630808","","Emotion recognition;Correlation;Sleep;Brain modeling;Electroencephalography;Physiology;Reliability","Electroencephalography;Emotions;Eye-Tracking Technology;Female;Humans;Male;Sex Characteristics;Sleep Deprivation","1","","14","IEEE","9 Dec 2021","","","IEEE","IEEE Conferences"
"EEG-based Pilot Competency Level Evaluation in Full Flight Simulator Training about Abnormal Events","Z. Cui; D. Chen; D. Wu","College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of General Aviation and Flight, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China",2021 IEEE 3rd International Conference on Civil Aviation Safety and Information Technology (ICCASIT),"10 Dec 2021","2021","","","495","500","If an abnormal event in flight is not handled properly by the pilot, the aircraft may lose control. Therefore, the competency of the pilot dealing with unexpected abnormal events needs applicable evaluations. But currently, almost all studies about pilots’ competency evaluation are under expected flight conditions, while ignoring pilots’ performance under unexpected abnormal conditions. Meanwhile the existing evaluation methods are too subjective, an objective and accurate evaluation method is necessary. Compared with EMG, ECG and EOG, the EEG signals have better resolution in time domain and can reflect the emotion of the pilot well. For this reason, experiments under abnormal events have been conducted in a full flight simulator to collect EEG data of pilots. The energy characteristics of the four frequency bands of the EEG signal are extracted to construct a dataset which is sent to the algorithm for building the classifier. We finally prove that the constructed random forest classifier has the best classification effect among common EEG signal classification models with accuracy 88.5% and F1-Score 84.2%. It is verified that the EEG signal can be used for pilots’ competency evaluation in full flight simulator training.","","978-1-6654-2518-6","10.1109/ICCASIT53235.2021.9633467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633467","EEG signal;competency;abnormal event;full flight simulator;random forest","Training;Brain modeling;Wavelet analysis;Electroencephalography;Wavelet packets;Safety;Resource management","","1","","25","IEEE","10 Dec 2021","","","IEEE","IEEE Conferences"
"An Investigation of Olfactory-Enhanced Video on EEG-Based Emotion Recognition","M. Wu; W. Teng; C. Fan; S. Pei; P. Li; Z. Lv","Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation and the School of Computer Science and Technology, Anhui University, Hefei, China",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"13 Mar 2023","2023","31","","1602","1613","Collecting emotional physiological signals is significant in building affective Human-Computer Interactions (HCI). However, how to evoke subjects’ emotions efficiently in EEG-related emotional experiments is still a challenge. In this work, we developed a novel experimental paradigm that allows odors dynamically participate in different stages of video-evoked emotions, to investigate the efficiency of olfactory-enhanced videos in inducing subjects’ emotions; According to the period that the odors participated in, the stimuli were divided into four patterns, i.e., the olfactory-enhanced video in early/later stimulus periods (OVEP/OVLP), and the traditional videos in early/later stimulus periods (TVEP/TVLP). The differential entropy (DE) feature and four classifiers were employed to test the efficiency of emotion recognition. The best average accuracies of the OVEP, OVLP, TVEP, and TVLP were 50.54%, 51.49%, 40.22%, and 57.55%, respectively. The experimental results indicated that the OVEP significantly outperformed the TVEP on classification performance, while there was no significant difference between the OVLP and TVLP. Besides, olfactory-enhanced videos achieved higher efficiency in evoking negative emotions than traditional videos. Moreover, we found that the neural patterns in response to emotions under different stimulus methods were stable, and for Fp1, FP2, and F7, there existed significant differences in whether adopt the odors.","1558-0210","","10.1109/TNSRE.2023.3253866","National Natural Science Foundation of China (NSFC)(grant numbers:61972437); Excellent Youth Foundation of Anhui Scientific Committee(grant numbers:2208085J05); National Key Research and Development Program of China(grant numbers:2021ZD0201502); Special Fund for Key Program of Science and Technology of Anhui Province(grant numbers:202203a07020008); Natural Science Foundation of Anhui Province(grant numbers:2108085MF207); Open Research Projects of Zhejiang Laboratory(grant numbers:2021KH0AB06); Open Projects Program of National Laboratory of Pattern Recognition(grant numbers:202200014); Open Fund Project of Key Laboratory of Civil Aviation Flight Technology and Flight Safety(grant numbers:FZ2022KF15); Cloud Ginger XR-1; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10063978","Electroencephalogram (EEG);emotion recognition;human–computer interface (HCI);olfactory-enhanced video;neural pattern","Electroencephalography;Emotion recognition;Brain;Human computer interaction;Physiology;Visualization;Olfactory","Humans;Electroencephalography;Emotions;Recognition, Psychology;Entropy","30","","50","CCBYNCND","8 Mar 2023","","","IEEE","IEEE Journals"
"Enhancing emotion recognition with attention-augmented EEG models","Y. Zeng; H. Cui; C. Liu; S. Li; A. Xu; K. Yang","College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, People's Republic of China; College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, People's Republic of China; College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, People's Republic of China; College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, People's Republic of China; Shenzhen Key Leboratory of Nuclear and Radiation Safety, Institute for Advanced Study in Nuclear Energy & Safety, College of Physics and Optoelectronic Engineering, Shenzhen University, Shenzhen, People's Republic of China; Pennsylvania State University, Pennsylvania, America","14th International Conference on Quality, Reliability, Risk, Maintenance, and Safety Engineering (QR2MSE 2024)","28 Jan 2025","2024","2024","","386","391","The analysis of human reliability in the context of nuclear power is profoundly influenced by the role of emotions. In this paper, we utilize electroencephalogram (EEG) signals for emotion recognition, employing the SJTU Emotion EEG Dataset (SEED) alongside a Graph-based Multi-task Self-Supervised Learning model (GMSS) enhanced with attention-activated convolutional networks. Experimental validation revealed that the accuracy of the model improved fro m 91.49% before the introduction of the networks to 92.51% afterward, marking an increase of 1.02%. These results demonstrate that the enhanced framework proposed in this paper is capable of effectively recognizing emotions, and the incorporation of attent ion-augmented convolutional networks has the potential to further enhance the model's recognition efficacy.","","978-1-83724-195-8","10.1049/icp.2024.3462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10855981","","","","","","","","28 Jan 2025","","","IET","IET Conferences"
"BrainNets: Human Emotion Recognition Using an Internet of Brian Things Platform","H. Lu; H. Kim; Y. Li; Y. Zhang","Dept. of Mech. And Control Engineering, Kyushu Institute of Technology, Kitakyushu, Japan; Dept. of Mech. And Control Engineering, Kyushu Institute of Technology, Kitakyushu, Japan; Faculty of Engineering, Fukuoka University, Fukuoka, Japan; School of Information and Safety Engineering, Zhongnan University of Economics and Law, Wuhan, China",2018 14th International Wireless Communications & Mobile Computing Conference (IWCMC),"30 Aug 2018","2018","","","1313","1316","Human wearable helmet is a useful tool for monitoring the status of miners in the mining industry. However, there is little research regarding human emotion recognition in an extreme environment. In this paper, an emotional state evoked paradigm is designed to identify the brain area where the emotion feature is most evident. Next, the correct electrode position is determined for the collection of the negative emotion by the electroencephalograph (EEG) based on the international 10-20 system of electrode placement. And then, a fusion algorithm of the anxiety level is proposed to evaluate the person's mental state using the θ, α, and β rhythms of an EEG. Experiments demonstrate that the position Fp2 is the best electrode position for obtaining the anxiety level parameter. The most visible EEG changes appear within the first two seconds following stimulation. The amplitudes of the θ rhythm increase most significantly in the negative emotional state.","2376-6506","978-1-5386-2070-0","10.1109/IWCMC.2018.8450382","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8450382","Emotion recognition;EEG;Cloud computing;Internet of Things","Electroencephalography;Emotion recognition;Electrodes;Frequency-domain analysis;Feature extraction;Time-domain analysis;Fatigue","","3","","20","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"EEG-Based Emotion Detection Using Roberts Similarity and PSO Feature Selection","M. Hussein Mohammed; M. Noaman Kadhim; D. Al-Shammary; A. Ibaida","Computer Techniques Engineering Department, Al-Mustaqbal University, Babylon, Iraq; College of Computer Science and Information Technology, University of Al-Qadisiyah, Al Dewaniyah, Iraq; College of Computer Science and Information Technology, University of Al-Qadisiyah, Al Dewaniyah, Iraq; Intelligent Technology Innovation Laboratory, Victoria University, Melbourne, VIC, Australia",IEEE Access,"8 May 2025","2025","13","","79353","79366","In this paper, a novel classifier based on Robert’s similarity measure is introduced for emotion detection using electroencephalogram (EEG) signals. Traditional machine learning classifiers machine learning such as k-Nearest Neighbors (KNN), Support Vector Machine (SVM), Decision Tree (DT), Logistic Regression (LR), and Random Forest (RF), often struggle to accurately capture both linear and nonlinear patterns in EEG signals and face limitations in handling high-dimensional datasets. The proposed classifier addresses these challenges by segmenting EEG signals into block sizes categorized as small (1 to 10 samples), medium (20 to 100 samples), and large (200 to 1,000 samples), demonstrating particularly strong performance with medium and large block sizes to capture essential features. Integration of Particle Swarm Optimization (PSO) for feature selection, with Robert’s similarity as the fitness function, effectively refines the feature set, boosting classification accuracy and computational efficiency. Evaluation on an EEG brainwave dataset demonstrated that the method achieved an accuracy of 98.75% with feature selection, compared to 94.04% without it in emotional state detection. The results demonstrate that the proposed classifier is a valuable tool for diverse fields, including healthcare by detecting patient stress, education by assessing student engagement, customer service by monitoring satisfaction, and smart environments by enabling adaptive responses. Furthermore, the classifier has potential for broader industrial applications, such as improving workplace productivity by monitoring employee stress and enhancing safety in autonomous vehicle systems, making it a versatile solution for emotionally-aware systems across multiple domains.","2169-3536","","10.1109/ACCESS.2025.3555526","Al-Mustaqbal University, Babylon, Iraq, and Victoria University, Australia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10943121","Roberts similarity;electroencephalography (EEG) signal;emotion recognition;particle swarm optimization (PSO);machine learning classifiers","Electroencephalography;Feature extraction;Emotion recognition;Accuracy;Brain modeling;Machine learning;Support vector machines;Nearest neighbor methods;Long short term memory;Adaptation models","","","","35","CCBY","28 Mar 2025","","","IEEE","IEEE Journals"
"A Novel Experiment Setting for Cross-subject Emotion Recognition","H. -Y. Hu; L. -M. Zhao; Y. -Z. Liu; H. -L. Li; B. -L. Lu","Center for Brain-Like Computing and Machine Intelligence, Department of Computer Science and Engineering, the Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, the Brain Science and Technology Research Center, and Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China; Center for Brain-Like Computing and Machine Intelligence, Department of Computer Science and Engineering, the Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, the Brain Science and Technology Research Center, and Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China; Key Laboratory of Occupational Health and Safety of Guangdong, Power Grid Co., Ltd, Electric Power Research Institute of Guangdong Power Grid Co., Ltd, Guangzhou, China; Key Laboratory of Occupational Health and Safety of Guangdong, Power Grid Co., Ltd, Electric Power Research Institute of Guangdong Power Grid Co., Ltd, Guangzhou, China; Center for Brain-Like Computing and Machine Intelligence, Department of Computer Science and Engineering, the Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, the Brain Science and Technology Research Center, and Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China",2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"9 Dec 2021","2021","","","6416","6419","Recently, cross-subject emotion recognition attracts widespread attention. The current emotional experiments mainly use video clips of different emotions as stimulus materials, but the videos watched by different subjects are the same, which may introduce the same noise pattern in the collected data. However, the traditional experiment settings for cross-subject emotion recognition models couldn’t eliminate the impact of same video clips on recognition results, which may lead to a bias on classification. In this paper, we propose a novel experiment setting for cross-subject emotion recognition. We evaluate different experiment settings on four public emotion datasets, DEAP, SEED, SEED-IV and SEED-V. The experimental results demonstrate the deficiencies of the traditional experiment settings and the advantages of our proposed experiment setting.","2694-0604","978-1-7281-1179-7","10.1109/EMBC46164.2021.9630314","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; China Southern Power Grid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630314","","Training;Emotion recognition;Biology","Electroencephalography;Emotions;Humans","","","22","IEEE","9 Dec 2021","","","IEEE","IEEE Conferences"
"A Multimodal-Driven Fusion Data Augmentation Framework for Emotion Recognition","A. Li; M. Wu; R. Ouyang; Y. Wang; F. Li; Z. Lv","Anhui Province Key Laboratory of Multimodal Cognitive Computation, School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation, School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation, School of Computer Science and Technology, Anhui University, Hefei, China; Anhui Province Key Laboratory of Multimodal Cognitive Computation, School of Computer Science and Technology, Anhui University, Hefei, China; Key Laboratory of Flight Techniques and Flight Safety, CAAC; Anhui Province Key Laboratory of Multimodal Cognitive Computation, School of Computer Science and Technology, Anhui University, Hefei, China",IEEE Transactions on Artificial Intelligence,"","2025","PP","99","1","16","The pursuit of imbuing computers with emotional intelligence has driven extensive research into physiological signal analysis for emotion recognition. Deep learning techniques offer promising avenues for analyzing physiological signals in this domain. Despite numerous studies on emotion recognition using various physiological signals, challenges persist in classifying multimodal physiological signals due to data scarcity. Current research lacks focus on addressing data insufficiency for multimodal physiological signals. This paper proposes an innovative method to address this issue and improve the effect of emotion recognition using multimodal physiological signal data. Our model comprises a physiological signal encoder, a multimodal data generator, and a multimodal emotion recognizer. Specifically, we introduce a customized ConvNeXt-Attention fusion model (CNXAF) to fuse diverse physiological signals, generating fused multimodal data. The multimodal data generator employs a conditional Self-Attention Generative Adversarial Network (c-SAGAN) to synthesize additional data across different categories, augmenting original datasets. Finally, the multimodal emotion recognizer utilizes the ConvNeXt-t classifier for emotion recognition on the extended dataset. Through extensive experimentation, our model achieves accuracies of 96.06% on the DEAP dataset and 95.70% on the WESAD dataset, demonstrating the effectiveness of our approach in accurately recognizing emotions. Experimental results underscore the superior performance of our method compared to existing approaches in multimodal emotion recognition research. Our code is publicly available at https://github.com/suprola1017/Multimodal-Data-Enhance-Framework-for-Emotion-Recognation.","2691-4581","","10.1109/TAI.2025.3537965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10896942","Multimodal Emotion Recognition;Data Fusion;Data Augmentation;Physiological Signals;Deep Learning","Emotion recognition;Physiology;Brain modeling;Data models;Electroencephalography;Artificial intelligence;Generators;Data augmentation;Training;Accuracy","","","","","IEEE","20 Feb 2025","","","IEEE","IEEE Early Access Articles"
"Automatic Emotion Recognition Using Temporal Multimodal Deep Learning","B. Nakisa; M. N. Rastgoo; A. Rakotonirainy; F. Maire; V. Chandran","School of Information Technology, Deakin University, Geelong, VIC, Australia; School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane, QLD, Australia; Centre for Accident Research and Road Safety-Queensland, Queensland University of Technology, Brisbane, QLD, Australia; School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane, QLD, Australia; School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane, QLD, Australia",IEEE Access,"24 Dec 2020","2020","8","","225463","225474","Emotion recognition using miniaturised wearable physiological sensors has emerged as a revolutionary technology in various applications. However, detecting emotions using the fusion of multiple physiological signals remains a complex and challenging task. When fusing physiological signals, it is essential to consider the ability of different fusion approaches to capture the emotional information contained within and across modalities. Moreover, since physiological signals consist of time-series data, it becomes imperative to consider their temporal structures in the fusion process. In this study, we propose a temporal multimodal fusion approach with a deep learning model to capture the non-linear emotional correlation within and across electroencephalography (EEG) and blood volume pulse (BVP) signals and to improve the performance of emotion classification. The performance of the proposed model is evaluated using two different fusion approaches - early fusion and late fusion. Specifically, we use a convolutional neural network (ConvNet) long short-term memory (LSTM) model to fuse the EEG and BVP signals to jointly learn and explore the highly correlated representation of emotions across modalities, after learning each modality with a single deep network. The performance of the temporal multimodal deep learning model is validated on our dataset collected from smart wearable sensors and is also compared with results of recent studies. The experimental results show that the temporal multimodal deep learning models, based on early and late fusion approaches, successfully classified human emotions into one of four quadrants of dimensional emotions with an accuracy of 71.61% and 70.17%, respectively.","2169-3536","","10.1109/ACCESS.2020.3027026","Queensland University of Technology (QUT) through the Centre for Robotics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206543","Emotion recognition;electroencephalography;blood volume pulse;convolutional neural network;long short-term memory;temporal multimodal fusion","Feature extraction;Brain modeling;Electroencephalography;Physiology;Emotion recognition;Deep learning;Sensors","","49","","41","CCBY","28 Sep 2020","","","IEEE","IEEE Journals"
"S3LRR: A Unified Model for Joint Discriminative Subspace Identification and Semisupervised EEG Emotion Recognition","Y. Peng; Y. Zhang; W. Kong; F. Nie; B. -L. Lu; A. Cichocki","School of Computer Science and Technology and the Zhejiang Key Laboratory of Brain-Machine Collaborative Intelligence, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology and the Zhejiang Key Laboratory of Brain-Machine Collaborative Intelligence, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology and the Zhejiang Key Laboratory of Brain-Machine Collaborative Intelligence, Hangzhou Dianzi University, Hangzhou, China; School of Artificial Intelligence, OPtics and ElectroNics (iOPEN), Northwestern Polytechnical University, Xi’an, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Center for Computational and Data-Intensive Science and Engineering, Skolkovo Institute of Science and Technology, Moscow, Russia",IEEE Transactions on Instrumentation and Measurement,"20 Apr 2022","2022","71","","1","13","Emotion recognition from electroencephalogram (EEG) data has been a research spotlight in both academic and industrial communities, which lays a solid foundation to achieve harmonic human–machine interaction. However, most of the existing studies either directly performed classification on primary EEG features or employed a two-stage paradigm of “feature transformation plus classification” for emotion recognition. The former usually cannot obtain promising performance, while the latter inevitably breaks the connection between feature transformation and recognition. In this article, we propose a simple yet effective model named semisupervised sparse low-rank regression (S3LRR) to unify the discriminative subspace identification and semisupervised emotion recognition together. Specifically, S3LRR is formulated by decomposing the projection matrix in least square regression (LSR) into two factor matrices, which complete the discriminative subspace identification and connect the subspace EEG data representation with emotional states. Experimental studies on the benchmark SEED_V dataset show that the emotion recognition performance is greatly improved by the joint learning mechanism of S3LRR. Furthermore, S3LRR exhibits additional abilities in affective activation patterns exploration and EEG feature selection.","1557-9662","","10.1109/TIM.2022.3165741","National Key Research and Development Program of China(grant numbers:2017YFE0116800); National Natural Science Foundation of China(grant numbers:61971173,U20B2074); Natural Science Foundation of Zhejiang Province(grant numbers:LY21F030005); Fundamental Research Funds for the Provincial Universities of Zhejiang(grant numbers:GK209907299001-008); CAAC Key Laboratory of Flight Techniques and Flight Safety(grant numbers:FZ2021KF16); Guangxi Key Laboratory of Optoelectronic Information Processing (Guilin University of Electronic Technology)(grant numbers:GD21202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751614","Discriminative subspace identification;electroencephalogram (EEG);emotion recognition;low-rank regression;semisupervised classification","Electroencephalography;Emotion recognition;Brain modeling;Feature extraction;Sparse matrices;Data models;Time-domain analysis","","4","","44","IEEE","8 Apr 2022","","","IEEE","IEEE Journals"
"A Comparative Research on the Influence of Commercial Complex Waterscape Atrium on Human Emotion Based on Computer Visual Attention and EEG Data","Y. Sun; S. Chen","School of Urban Construction and Safety Engineering Shanghai Institute of Technology, Shanghai, China; School of Urban Construction and Safety Engineering Shanghai Institute of Technology, Shanghai, China",2020 IEEE 20th International Conference on Communication Technology (ICCT),"24 Dec 2020","2020","","","1461","1464","With the rapid development of computer physiological measurement technology, more and more computer technology has been applied to the design. In this paper, a wearable EEG acquisition system based on computer vision measurement was used to test the concentration and meditation degree of computer image vision and the proportion of dominant brain waves in commercial complex with and without waterscape atrium. By comparing the average value index of concentration, meditation degree, mind α wave and β wave as dominant brain wave, the main factors influencing human emotion change were analyzed, and the influence law of atrium space with waterscape and atrium without waterscape on human emotion change was summarized from the perspective of physiological measurement. The results showed that the time and effect of mind α wave on human brain were significantly increased (P <; 0.01), while the time and effect of β wave on human brain were weakened. The average value of concentration had an increasing trend, but the total value did not increase significantly, and the average value of meditation degree showed a significant increase (P <; 0.01), indicating that compared with the atrium without waterscape, the waterscape atrium can make people relax and calm without weakening their mental attention.","2576-7828","978-1-7281-8141-7","10.1109/ICCT50939.2020.9295947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9295947","computer vision concentration and meditation;dominant brain wave;wearable technology;atrium landscape space;emotion","Electroencephalography;Physiology;Visualization;Headphones;Market research;Wearable computers;Urban areas","","","","11","IEEE","24 Dec 2020","","","IEEE","IEEE Conferences"
"Intelligent Wearable System With Motion and Emotion Recognition Based on Digital Twin Technology","F. Yu; C. Yu; Z. Tian; X. Liu; J. Cao; L. Liu; C. Du; M. Jiang","School of Computer Science and Artificial Intelligence and the Engineering Research Center of Hubei Province for Clothing Information, Wuhan Textile University, Wuhan, Hubei, China; School of Computer Science and Artificial Intelligence, Wuhan Textile University, Wuhan, Hubei, China; School of Computer Science and Artificial Intelligence, Wuhan Textile University, Wuhan, Hubei, China; School of Computer Science and Artificial Intelligence, Wuhan Textile University, Wuhan, Hubei, China; School of Computer Science and Artificial Intelligence, Wuhan Textile University, Wuhan, Hubei, China; School of Computer Science and Artificial Intelligence, Wuhan Textile University, Wuhan, Hubei, China; School of Computer Science and Artificial Intelligence, Wuhan Textile University, Wuhan, Hubei, China; School of Computer Science and Artificial Intelligence and the Engineering Research Center of Hubei Province for Clothing Information, Wuhan Textile University, Wuhan, Hubei, China",IEEE Internet of Things Journal,"23 Jul 2024","2024","11","15","26314","26328","Intelligent wearable systems have been widely used in health monitoring, motion tracking, and engineering safety. However, the single function of current wearable systems cannot satisfy the requirements of complex scenarios, and the wearable systems cannot establish a relationship with the virtual 3-D visualization platform. To address these issues, this article proposes a novel intelligent wearable system with motion and emotion recognition. Multiple sensors are integrated into the system to collect motion and emotion information. In order to achieve accurate classification and recognition of multiple sensor information, we propose a novel human action recognition network called the three-branch spatial–temporal feature extraction network (TB-SFENet), which can obtain more robust features and achieve an accuracy of 97.04% on the UCI-HAR data set and 92.68% on the UniMiB SHAR data set. To establish the relationship between the real entity and virtual space, we use digital twin (DT) technology to establish the 3-D display DT platform. The platform enables real-time information interaction, such as activity, emotion, location, and monitoring information. Additionally, we establish the TGAM electroencephalogram emotion classification (TEEC) data set, which contains 120 000 pieces of data, for the proposed system. Experimental results indicate that the proposed system realizes virtual reality (VR) information interaction between the personal digital human and actual person based on the intelligent wearable system, which has great potential for applications in intelligent healthcare, VR, and other fields.","2327-4662","","10.1109/JIOT.2024.3394244","National Natural Science Foundation of China(grant numbers:62202346); Research on the Key Technology of Flexible Intelligent Manufacturing of Clothing Based on Digital Twin of Hubei Key Research and Development Program(grant numbers:2021BAA042); Hubei Science and Technology Project of Safe Production Special Fund (Scene control platform based on proprioception information computing of artificial intelligence); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10509598","Digital twin (DT);electroencephalogram (EEG);emotion recognition;intelligent wearable system;motion recognition","Biomedical monitoring;Emotion recognition;Three-dimensional displays;Sensors;Intelligent sensors;Safety;Monitoring","","11","","55","IEEE","26 Apr 2024","","","IEEE","IEEE Journals"
"AeroNeuro-GlobalNet: Leveraging LEO Satellite Constellations and 5G/6G Networks for Real- Time Emotional Monitoring of Transport Operators","A. Bostani; B. Albousabih; F. Kalloush","Department of Engineering and Applied Sciences, American University of Kuwait, Salmiya, Kuwait; Department of Arts and Sciences, American University of Kuwait, Salmiya, Kuwait; Department of Engineering and Applied Sciences, American University of Kuwait, Salmiya, Kuwait",2024 IEEE Global Conference on Artificial Intelligence and Internet of Things (GCAIoT),"14 Jan 2025","2024","","","1","6","In the pursuit of enhanced transport safety, the integration of advanced Low Earth Orbit (LEO) satellite constellations with next-generation 5G and 6G networks presents a transformative solution for real-time monitoring of emotional states in high-risk transport operators, including truck drivers and airplane pilots. This study introduces AeroNeuro-GlobalNet, a pioneering approach that leverages deep learning architectures, specifically a multi-head attention based long short-term memory (MHA-LSTM) model, to process and analyze EEG signals for emotion detection. The system aims to identify critical emotional states that could compromise safety, such as stress or fatigue, thus providing a novel form of preventive safety measure in the transportation sector. Utilizing the ubiquitous coverage and high-speed capabilities of integrated LEO satellite and terrestrial networks, AeroNeuro-GlobalNet ensures consistent, global monitoring capabilities, crucial for applications where traditional communication systems falter, such as remote air routes and cross-country trucking paths. This paper outlines the development and implementation of the emotion detection system, addresses the challenges of real-time data processing and privacy concerns, and discusses the system's integration with existing transport communication infrastructures. By facilitating continuous monitoring and immediate response capabilities, AeroNeuro-GlobalNet aims to prevent potential accidents and enhance the overall safety of transport operations, reflecting a significant step forward in the application of AI and satellite technology in critical real-world applications. The proposed framework not only enhances transport safety but also sets a foundation for future research in the integration of biometric monitoring technologies with global network infrastructures, offering a scalable solution to a wide array of safety-critical applications in various sectors.","","979-8-3315-2941-3","10.1109/GCAIoT63427.2024.10833530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10833530","Emotional detection;LEO satellite;5G;6G;EEG;DLED-EEGSP;technological advancement","Satellite constellations;Emotion recognition;Satellites;Low earth orbit satellites;Transportation;Fatigue;Real-time systems;Electroencephalography;Safety;Monitoring","","","","9","IEEE","14 Jan 2025","","","IEEE","IEEE Conferences"
"Long Short Term Memory Hyperparameter Optimization for a Neural Network Based Emotion Recognition Framework","B. Nakisa; M. N. Rastgoo; A. Rakotonirainy; F. Maire; V. Chandran","Centre for Accident Research and Road Safety—Queensland, Queensland University of Technology, Brisbane, Australia; Centre for Accident Research and Road Safety—Queensland, Queensland University of Technology, Brisbane, Australia; Centre for Accident Research and Road Safety—Queensland, Queensland University of Technology, Brisbane, Australia; School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, Australia; School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, Australia",IEEE Access,"27 Sep 2018","2018","6","","49325","49338","Recently, emotion recognition using low-cost wearable sensors based on electroencephalogram and blood volume pulse has received much attention. Long short-term memory (LSTM) networks, a special type of recurrent neural networks, have been applied successfully to emotion classification. However, the performance of these sequence classifiers depends heavily on their hyperparameter values, and it is important to adopt an efficient method to ensure the optimal values. To address this problem, we propose a new framework to automatically optimize LSTM hyperparameters using differential evolution (DE). This is the first systematic study of hyperparameter optimization in the context of emotion classification. In this paper, we evaluate and compare the proposed framework with other state-of-the-art hyperparameter optimization methods (particle swarm optimization, simulated annealing, random search, and tree of Parzen estimators) using a new dataset collected from wearable sensors. Experimental results demonstrate that optimizing LSTM hyperparameters significantly improve the recognition rate of four-quadrant dimensional emotions with a 14% increase in accuracy. The best model based on the optimized LSTM classifier using the DE algorithm achieved 77.68% accuracy. The results also showed that evolutionary computation algorithms, particularly DE, are competitive for ensuring optimized LSTM hyperparameter values. Although DE algorithm is computationally expensive, it is less complex and offers higher diversity in finding optimal solutions.","2169-3536","","10.1109/ACCESS.2018.2868361","QUT International Postgraduate Research Scholarship (IPRS); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453798","Differential evolution;emotion recognition;hyperparameter optimization;long short term memory;wearable physiological sensors","Emotion recognition;Optimization;Electroencephalography;Brain modeling;Classification algorithms;Sensors;Physiology","","95","","78","OAPA","2 Sep 2018","","","IEEE","IEEE Journals"
"Enhanced Feature Extraction with Superlet Transformation for EEG Emotion Classification","Q. Guan; L. Zou; Z. Hao; J. Li; X. Qian; L. Zhang; H. Zhou","School of Automation, Nanjing University of Science and Technology, China; School of Automation, Nanjing University of Science and Technology, China; School of Automation, Nanjing University of Science and Technology, China; School of Automation, Nanjing University of Science and Technology, China; School of Automation, Nanjing University of Science and Technology, China; Department of Rehabilitation, Jiangsu province official hospital; School of Automation, Nanjing University of Science and Technology, China",2024 17th International Convention on Rehabilitation Engineering and Assistive Technology (i-CREATe),"11 Dec 2024","2024","","","1","5","In the field of emotion recognition, electroencephalography(EEG) technology can accurately capture emotion, and has been widely used in psychology, public safety and other fields. In order to improve the accuracy and efficiency of emotion recognition, a new feature extraction method based on Superlets (SL) is developed in this paper. We designed an emotional experimental paradigm to induce positive, neutral and negative emotions. Further more, we extracted features using Superlets from the F7, F8, T7 and Pz electrode channels and classified three emotion states with SVM and DNN classifiers. In order to validate the performance of the proposed model, the collected EEG data set from our lab and SEED data set were used in this study. With SL features and DNN model, the average recognition accuracy from the 11 subjects was 85.75%, and the average recognition accuracy of SEED data set was 85.67%. The experiment results show that superlet transform could be used as a reliable feature extraction method in emotion recognition from EEG signal.","","979-8-3503-5515-4","10.1109/i-CREATe62067.2024.10776343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10776343","","Support vector machines;Emotion recognition;Time-frequency analysis;Accuracy;Transforms;Feature extraction;Brain modeling;Electroencephalography;Data models;Reliability","","","","19","IEEE","11 Dec 2024","","","IEEE","IEEE Conferences"
"Surprise Emotion Recognition of Pilots inside the Simulator Based on Multi-view Learning","J. Zhang; D. Wu; D. Chen; Y. Shang; W. Zhang; F. Wei","College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of General Aviation and Flight, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; China Simulation Science Co. Ltd., Shanghai, China; China Simulation Science Co. Ltd., Shanghai, China",2022 IEEE 4th International Conference on Civil Aviation Safety and Information Technology (ICCASIT),"27 Dec 2022","2022","","","587","592","This study investigates whether the unexpected events will surprise or frighten the pilots by recording vital signs, fuse the EEG and ECG signals through the multi-view learning method, and then use the support vector machine to classify the pilots' surprise and calm emotions. A good recognition effect has been achieved.","","978-1-6654-6766-7","10.1109/ICCASIT55263.2022.9986697","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9986697","EEG;ECG;Upset Prevention and Recovery Training;multi-view learning;SVM","Support vector machines;Learning systems;Emotion recognition;Fuses;Electrocardiography;Electroencephalography;Safety","","1","","19","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"A review on human factors in maritime transportation using seafarers' physiological data","S. Fan; X. Yan; J. Zhang; J. Wang","School of Energy and Power Engineering, National Engineering Research Centre for Water Transport Safety, Wuhan, China; Intelligent Transport Systems Research Centre, Wuhan University of Technology National Engineering Research Center for Water Transport Safety, Wuhan, China; Intelligent Transport Systems Research Centre, Wuhan University of Technology National Engineering Research Centre for Water Transport Safety, Wuhan, China; Department of Maritime and Mechanical Engineering, Liverpool John Moores University Liverpool, United Kingdom",2017 4th International Conference on Transportation Information and Safety (ICTIS),"21 Sep 2017","2017","","","104","110","Human failure is one of the dominant causes of maritime accidents. However, the relationship between seafarers' operations and mental workload remains largely unclear. It is meaningful to investigate it based on the analysis of seafarers' physiological data when on duty. For this purpose, a preliminary study on this subject is carried out. Research techniques of human factors related to neurophysiological measurements are analyzed in the context of ship operators' behaviors. It suggests that a coherent sequence of changes on Electroencephalogram (EEG) and Near-Infrared Spectroscopy (NIFS) signals exists during the transition from different sorts of human factor concepts. The objective of the review is to summarise human factors in maritime, and on how particular neurophysiological features could be utilized in human factor concepts of “mental workload”, “attention”, “fatigue”, etc. Operators' performance can be evaluated based on the fluctuations in physiological data. By these findings, future research on human factors in maritime would focus on quantitative methods to mine physiological data collected by devices, to optimise the crew training system based on simulators. One of the most important subjects is to identify the human failures, to optimize mission assignment, and to reduce the possibility of maritime accidents with seafarers' physiological data.","","978-1-5386-0437-3","10.1109/ICTIS.2017.8047751","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8047751","maritime transportation;human factors;mental workload;physiological state","Human factors;Safety;Accidents;Physiology;Electroencephalography;Transportation;Biomedical monitoring","","8","","38","IEEE","21 Sep 2017","","","IEEE","IEEE Conferences"
"Brain Map Data Based Aggressive Driving Detection Method","V. B. Yashin","Moscow Automobile and Road Construction State Technical University (MADI);, Moscow Technical University of Communications and Informatics, Moscow, Russia",2021 Systems of Signals Generating and Processing in the Field of on Board Communications,"7 May 2021","2021","","","1","4","Zero-collision program in traffic has become an important target for many metropolises and regions. Among the wide range of traffic accidents reasons the human factor plays one of the most significant roles. Monitoring, analysis and control of driver's behavior is the way to drastically improve the traffic safety. The driver's biological responses and parameters control combined with the modern driving assistance technologies provides a great opportunity to decrease human error. This paper proposes a system, which is based on EEG (electroencephalogram) recording and predicts emotion fluctuations which can cause the dramatic decision making.","","978-1-6654-1548-4","10.1109/IEEECONF51389.2021.9416080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416080","traffic safety;driver behavior;aggressive driving;dangerous driving;EEG;human error;emotion fluctuations","Fluctuations;Decision making;Human factors;Electroencephalography;Biology;Safety;Monitoring","","1","","28","IEEE","7 May 2021","","","IEEE","IEEE Conferences"
"Brain Activity Patterns of Pilot Cognitive Process: An EEG Microstate Analysis Study","Y. Zeng; Y. Sun; J. Yang; Z. Zeng","College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; China Academy of Launch Vehicle Technology, Centre of Research and Development, Beijing, China; College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China",2024 10th International Conference on Systems and Informatics (ICSAI),"26 Feb 2025","2024","","","1","6","Cognitive errors made by pilots during flight missions may lead to decision-making mistakes, potentially causing safety accidents. Understanding the neural mechanisms underlying pilot cognition is crucial for enhancing flight safety. This study analyzes the brain activity patterns at the micro-time scale during the cognitive process of pilots. Specifically, participants were asked to perform a task involving interface reading and select the correct answer based on the displayed content. A data-adaptive clustering method was used to extract Electroencephalogram (EEG) microstates, and changes in these microstates were analyzed in relation to correct and incorrect responses. The results show that when cognitive errors occur, the transition probability of microstates associated with the attention network increases by 86%, while the transition probability of microstates related to the language-visual network increases by 68%. This suggests that, in the case of cognitive errors, the brain activates the attention and language-visual networks to enhance the evaluation of the situation and external information, as well as the processing of language and visual inputs, in order to better correct errors and adjust cognitive strategies. These findings provide reference biomarkers for identifying cognitive errors in pilots.","2689-7148","979-8-3315-1013-8","10.1109/ICSAI65059.2024.10893731","Joint Fund of National Natural Science Foundation of China and Civil Aviation Administration of China(grant numbers:U2033202,U1333119); National Natural Science Foundation of China(grant numbers:52172387); Fundamental Research Funds for the Central Universities(grant numbers:ILA22032-1A); Aeronautical Science Foundation of China(grant numbers:2022Z071052001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893731","EEG;Microstate;Cognitive error","Training;Brain;Visualization;Cognitive processes;Heuristic algorithms;Clustering methods;Biomarkers;Electroencephalography;Robustness;Safety","","","","15","IEEE","26 Feb 2025","","","IEEE","IEEE Conferences"
"EEG-Based Fatigue Detection Using PLI Brain Network and Relief Algorithm","Y. He; Z. Wang; Y. Zhao","Shaanxi Key Laboratory of Network Data Analysis and Intelligent Processing, Xi'an Key Laboratory of Big Data and Intelligent Computing, Xi'an University of Posts and Telecommunications, Xi'an, Shaanxi, China; Shaanxi Key Laboratory of Network Data Analysis and Intelligent Processing, Xi'an Key Laboratory of Big Data and Intelligent Computing, Xi'an University of Posts and Telecommunications, Xi'an, Shaanxi, China; School of Computer Science and Technology, Xi'an University of Posts and Telecommunications, Xi'an, Shaanxi, China",2022 International Conference on Networking and Network Applications (NaNA),"30 Dec 2022","2022","","","300","305","EEG-based fatigue driving monitoring has important application value in road traffic safety, and the ultimate goal of the research is the development and use of wearable devices, and too many EEG channels in practical application scenarios is detrimental to device portability, and it will lead to problems such as large amount of data, complex calculation and long processing time, so it is especially important to study how to select the EEG channels highly correlated with fatigue. In this paper, a PLI-Relief-based channel selection algorithm by combining the PLI functional connectivity and the weighting idea of Relief algorithm is proposed, and it is applied to the channel selection of fatigue driving EEG. First, the PLI functional connectivity matrix is constructed for the EEG signals after preprocessing, and the binarized PLI matrix is mapped into a brain functional network, and the prime channels are selected by the degree property of the brain network. Then, the power spectral density features are extracted from the EEG signals of the prime channels, and the weights of each prime channel are obtained using the relief algorithm, then the number and the names of optimal channels are determined according to the recognition accuracy of different channel combinations. The proposed method was validated on the publicly available SEED-VIG dataset, and the data of the seven optimal channels is finally selected and obtains a classification accuracy of 81.25%. The framework proposed in this paper takes into account both the correlation between channels and the characteristics of the channel signals themselves in channel selection, which is a reference value for the development and application of wearable devices.","","978-1-6654-6131-3","10.1109/NaNA56854.2022.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9985056","Brain network;fatigue driving;phase lag index;channel selection","Performance evaluation;Wearable computers;Roads;Diversity reception;Fatigue;Feature extraction;Electroencephalography","","1","","20","IEEE","30 Dec 2022","","","IEEE","IEEE Conferences"
"Hybrid Wheelchair control method with EEG signal and facial Expression","L. Zaway; N. B. Amor; M. Jallouli; L. Chrifi-Alaoui; L. Delahoche","CES-Laboratory, National School of Engineering of Sfax, ENIS, University of Sfax, Tunisia; CES-Laboratory, National School of Engineering of Sfax, ENIS, University of Sfax, Tunisia; CES-Laboratory, National School of Engineering of Sfax, ENIS, University of Sfax, Tunisia; Laboratory LTI, University of Picardie Jules Verne, France; Laboratory LTI, University of Picardie Jules Verne, France","2023 20th International Multi-Conference on Systems, Signals & Devices (SSD)","6 Feb 2024","2023","","","893","897","While degrading their mobility, one of the major concerns of elderly/disabled people is affecting their ability to live independently. Assistive technologies for mobility are now designed to improve people’s living conditions. However, improvements are needed to existing mobility assist devices. This article explores the design and control of a smart wheelchair with two sources of control to improve wheelchair user safety. To improve user involvement and safety, the proposed system includes control interfaces with the EEG signal processing application using the EMOTIV Insight EEG headset in addition to facial expressions using a webcam, at the same time defining the state of the user.","2474-0446","979-8-3503-3256-8","10.1109/SSD58187.2023.10411223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10411223","Electroencephalogram (EEG);electric-powered wheelchair (EPW);hybrid Wheelchair control;facial Expression;Mindset EMOTIV Insight","Headphones;Webcams;Wheelchairs;Signal processing;Electroencephalography;Safety;Planning","","1","","15","IEEE","6 Feb 2024","","","IEEE","IEEE Conferences"
"Understanding Drivers’ Emotion Variations During NDRTs in Conditional Automated Driving Using EEG Data","W. Guo; H. Zhang; N. Ding; Y. Liu","Intelligent Transportation Systems Research Center, Wuhan University of Technology, Wuhan, Hubei, China; Intelligent Transportation Systems Research Center, Wuhan University of Technology, Wuhan, Hubei, China; Intelligent Transportation Systems Research Center, Wuhan University of Technology, Wuhan, Hubei, China; Intelligent Transportation Systems Research Center, Wuhan University of Technology, Wuhan, Hubei, China",2023 7th International Conference on Transportation Information and Safety (ICTIS),"15 Sep 2023","2023","","","1289","1294","Drivers’ emotion is one of the key factors affecting driving behavior, negative emotion would be harmful to safe driving. In conditional automated driving, drivers would devote the majority of the time to Non-Driving Related Tasks (NDRTs), and varying NDRTs may lead to variations in drivers’ emotions. In this study, a series of conditional automated driving simulation experiments considering four typical NDRTs was conducted, and the electroencephalogram (EEG) signals were detected to identify and characterize drivers’ emotions by the valence-arousal (V-A) model, where in valence ranges from displeasure to pleasure and arousal ranges from relaxation to excitement. The results show that 1) the drivers’ emotion, as measured by the valence and arousal, was significantly affected by the rest and reading tasks during conditional automated driving, but not influenced by the monitoring vehicle operation and watching video tasks; 2) the V-A model revealed that the drivers were prone to keep alert in automated driving while showing increased stress in the rest state. The findings of this study contribute to a better understanding of drivers’ emotions and NDRTs in conditional automated driving.","2832-899X","979-8-3503-0853-2","10.1109/ICTIS60134.2023.10243901","Research and Development; Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10243901","emotion;EEG;conditional automated driving;NDRT;valence;arousal","Mood;Human factors;Brain modeling;Electroencephalography;Safety;Reliability;Task analysis","","","","25","IEEE","15 Sep 2023","","","IEEE","IEEE Conferences"
"Fusing Frequency-Domain Features and Brain Connectivity Features for Cross-Subject Emotion Recognition","C. Chen; Z. Li; F. Wan; L. Xu; A. Bezerianos; H. Wang","Faculty of Intelligent Manufacturing, Wuyi University, Jiangmen, China; Faculty of Intelligent Manufacturing, Wuyi University, Jiangmen, China; Department of Electrical and Computer Engineering, Faculty of Science and Technology, and the Centre for Cognitive and Brain Sciences, Institute of Collaborative Innovation, University of Macau, Macau; Faculty of Intelligent Manufacturing, Wuyi University, Jiangmen, China; Hellenic Institute of Transport (HIT), Centre for Research and Technology Hellas (CERTH), Thessaloniki, Greece; Faculty of Intelligent Manufacturing, Wuyi University, Jiangmen, China",IEEE Transactions on Instrumentation and Measurement,"3 May 2022","2022","71","","1","15","Frequency-domain (FD) features reveal the activated patterns of individual local brain regions responding to different emotions, whereas brain connectivity (BC) features involve the coordination of multiple brain regions for generating emotional responses; these two types of features are complementary to each other. To date, the fusion of these two types of features for electroencephalography (EEG)-based cross-subject emotion recognition remains to be fully investigated due to the intersubject variability in EEG signals. In this article, we first attempt to investigate these fused features for cross-subject emotion recognition from multiple perspectives, including critical frequency bands, complementary characteristics for each emotional state, critical channels, and crucial connections, using a fast and robust approximate empirical kernel map-fusion-based support vector machine (AEKM-Fusion-SVM) method. The experimental results on the SJTU emotion EEG dataset (SEED), BCI2020-A, and BCI2020-B datasets reveal that: 1) the AEKM-fusion method improves the effectiveness and efficiency of the fusion of features of different dimensions; 2) the recognition accuracy of the fused features outperforms each individual feature, and this outperformance is more significant in the high-frequency bands (i.e., the beta and gamma bands); 3) the fused features significantly enhance the classification performance for negative emotion; and 4) the fused features built with 27 selected channels achieve comparable performance to that of the fused features built with the full number of channels (i.e., 62 channels), allowing for easier establishment of brain–computer interface (BCI) systems in real-world scenarios. Our study enriches the research of emotion-related brain mechanisms and provides new insight into affective computing.","1557-9662","","10.1109/TIM.2022.3168927","Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2020A1515111154); Special Projects in Key Fields Supported by the Technology Development Project of Guangdong Province(grant numbers:2020ZDZX3018); Special Fund for Science and Technology of Guangdong Province(grant numbers:2020182); Educational Commission of Guangdong Province(grant numbers:2021KTSCX136); Wuyi University and Hong Kong and Macao Joint Research Project(grant numbers:2019WGALH16); Jiangmen Science and Technology Project(grant numbers:2021030100050004285); European Union’s Horizon 2020 Research and Innovation Program [Proactive Safety Systems and Tools for a Constantly Upgrading Road Environment (SAFE_UP)](grant numbers:031019); Science and Technology Development Fund, Macau(grant numbers:0045/2019/AFJ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760385","Approximate empirical kernel map (AEKM);brain connectivity (BC) features;cross-subject emotion recognition;frequency-domain (FD) features;fused features","Feature extraction;Emotion recognition;Electroencephalography;Frequency-domain analysis;Support vector machines;Motion pictures;Kernel","","26","","48","IEEE","20 Apr 2022","","","IEEE","IEEE Journals"
"Level of Pilot Fear on Maneuvering based Brain Wave Using Naïve Bayes Method","A. Turnip; E. F. Athalla; D. D. Rumani; A. Setiawan; D. E. Kusumandari; N. S. Syafei","Department of Electrical Engineering, Universitas Padjadjaran, Sumedang, Indonesia; Department of Electrical Engineering, Universitas Padjadjaran, Sumedang, Indonesia; Akademi Penerbangan Indonesia Banyuwangi, Banyuwangi, Indonesia; Akademi Penerbangan Indonesia Banyuwangi, Banyuwangi, Indonesia; Badan Riset dan Inovasi Nasional (BRIN), Indonesia; Department of Electrical Engineering, Universitas Padjadjaran, Sumedang, Indonesia",2024 IEEE International Conference on Artificial Intelligence and Mechatronics Systems (AIMS),"10 May 2024","2024","","","1","6","In aviation, safety is a top priority. To maintain the stability of airline performance and minimize accidents due to emotional responses from pilots, preventive measures are needed. The study focused on identifying pilots' fear responses when at a certain altitude. To detect fear, this study used Electroencephalography (EEG) with the Naïve Bayes method because this method was able to classify responses with high accuracy that could reach 95.0%. This signifies the potential of technology to understand pilots' emotional responses and enable appropriate preventive action to be taken. Thus, the use of EEG contributes significantly to the development of pilot decision support systems to improve flight welfare and safety. This research will help future improvements to the safety of aviation industry because this can determine the classification of the level of pilot fear when maneuvering. Although this method has a high accuracy percentage, there will be a lot of distortion if the signals isn't applied with filtration.","","979-8-3503-5052-4","10.1109/AIMS61812.2024.10513244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10513244","Electroencephalography;Naive Bayes;Pilot","Training;Mechatronics;Electroencephalography;Stability analysis;Safety;Bayes methods;Emotional responses","","2","","21","IEEE","10 May 2024","","","IEEE","IEEE Conferences"
"Boosting Weak Learners With Multi-Agent Reinforcement Learning for Enhanced Stacking Models: An Application on Driver Emotion Classification","S. -H. Kim; E. Jung; H. Shin; I. -B. Yang; J. Woo","Asan Medical Center, Seoul, South Korea; Department of ICT Convergence, Soonchunhyang University, Asan, South Korea; Department of ICT Convergence, Soonchunhyang University, Asan, South Korea; Department of Smart Automobile, Soonchunhyang University, Asan, South Korea; Department of AI and Big Data, Soonchunhyang University, Asan, South Korea",IEEE Transactions on Intelligent Transportation Systems,"27 Nov 2024","2024","25","12","20478","20492","Recently, there has been an increasing interest in the effects of stress and negative emotions on driving performance and road safety. As a consequence, there is a growing interest in studies that employ biometric signals to categorize the emotions of drivers, and driver state monitoring technologies are assuming a greater level of significance within the automotive sector. The objective of this study is to develop a lightweight stacking model that classifies drivers’ emotions into seven distinct categories by combining statistical electroencephalography data, psychological survey data, and driver behavior data. Our objective is to effectively combine individual machine learning models using reinforcement learning, and achieve optimal performance by combining strong and weak learners. To overcome the drawbacks of previous works that select individual models arbitrarily and optimize the weight in assemble model, we propose a multi-agent reinforcement learning based model selection for stacking. The proposed model introduces a novel feature by providing varying rewards based on the contribution of individual model to the overall performance, with the aim of enhancing the weaker model selection. The final results show that the meta-model achieves the highest performance when using a decision tree, with an accuracy of 0.8543 and an F1-score of 0.8462, which is an improvement of 0.266 and 0.2875 compared to before applying reinforcement learning, respectively. Experimental findings validate that our method can contribute to the improvement of road safety through the identification of emotional shifts in drivers and the development of appropriate interventions.","1558-0016","","10.1109/TITS.2024.3478212","Regional Innovation Strategy (RIS) through by the National Research Foundation of Korea (NRF) by the Ministry of Education (MOE)(grant numbers:2021RIS-004); Soonchunhyang University Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10736950","Multi-agent reinforcement learning;stacking model;ensemble model;driver emotion detection","Brain modeling;Vehicles;Biological system modeling;Reinforcement learning;Stacking;Electroencephalography;Data models;Accuracy;Predictive models;Feature extraction","","","","63","IEEE","28 Oct 2024","","","IEEE","IEEE Journals"
"Review of Drowsiness Detection Machine-Learning Methods Applicable for Non-Invasive Brain-Computer Interfaces","M. Gusev; N. Ackovska; V. Zdraveski; E. Stankov; M. Jovanov; M. Dinev; D. Spasov; X. Gui; Y. Zhang; L. Geng; X. Zhou","Faculty of Computer Sciences and Engineering, Sts Cyril and Methodius University in Skopje, North Macedonia; Faculty of Computer Sciences and Engineering, Sts Cyril and Methodius University in Skopje, North Macedonia; Faculty of Computer Sciences and Engineering, Sts Cyril and Methodius University in Skopje, North Macedonia; Faculty of Computer Sciences and Engineering, Sts Cyril and Methodius University in Skopje, North Macedonia; Faculty of Computer Sciences and Engineering, Sts Cyril and Methodius University in Skopje, North Macedonia; Faculty of Computer Sciences and Engineering, Sts Cyril and Methodius University in Skopje, North Macedonia; Faculty of Computer Sciences and Engineering, Sts Cyril and Methodius University in Skopje, North Macedonia; School of Electronics and Information Engineering, Xian Jiaotong University, Xian, China; School of Electronics and Information Engineering, Xian Jiaotong University, Xian, China; School of Electronics and Information Engineering, Xian Jiaotong University, Xian, China; School of Electronics and Information Engineering, Xian Jiaotong University, Xian, China",2021 29th Telecommunications Forum (TELFOR),"29 Dec 2021","2021","","","1","4","This review focuses on the analysis of non-invasive Brain-Computer Interface methods, and in particular in the state-of-the-art machine learning-based methods for Electroencephalography (EEG) acquisition. EEG as a tool can be used to detect various states concerning human health, but it can also be used to detect the human’s states such as alertness, interest and even drowsiness. In this paper we focus on this important issue and present some of the ML techniques that can be used, as well as the methodology for noise detection and elimination while using EEG.","","978-1-6654-2585-8","10.1109/TELFOR52709.2021.9653239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9653239","EEG;Brain-Computer Interfaces;Noise elimination","Training;Learning systems;Machine learning;Electroencephalography;Brain-computer interfaces;Telecommunications;Safety","","","","50","IEEE","29 Dec 2021","","","IEEE","IEEE Conferences"
"Emotion Analysis Architecture Based on Face and Physiological Sensing Applied with Flight Simulator","V. C. C. Roza; O. Postolache","Instituto Universitário de Lisboa, ISCTE-IUL & IT-IUL Universidade Federal do Rio G. do Norte, UFRN, Lisboa, Portugal; Instituto Universitário de Lisboa, ISCTE-IUL Instituto de Telecomunicações, IT-IUL, Lisboa, Portugal",2018 International Conference and Exposition on Electrical And Power Engineering (EPE),"6 Dec 2018","2018","","","1036","1040","This work presents an architecture as an important contribution regarding to emotional events along tasks based on flight simulations. This architecture considered eight beginner users of flight simulator (n = 8) while they execute a simulated flight according with the basic concepts of visual flight rules (VFR). The acquired physiological sensing were: heart rate (HR), electroencephalography (EEG) and galvanic skin response (GSR). One small camera was also used to record the users' face in order to extract, after the post-processing, the emotions of the user during the flight. The considered emotions were: happy, sad, angry, surprised, scared and disgust. Initial analysis of the GSR signals shown that the takeoff task presented 13% more variability (or emotional events) between the climb and approach tasks together; and in the same way, the landing task presented 16% more variability between the climb and approach tasks together, what shows the importance of these researches in flight safety context, mainly in these critical phases.","","978-1-5386-5062-2","10.1109/ICEPE.2018.8559732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8559732","emotion analysis architecture;flight simulator;physiological sensing;aviation safety;human error prevention","Heart rate;Visualization;Power engineering;Physiology;Electroencephalography;Skin;Sensors","","3","","11","IEEE","6 Dec 2018","","","IEEE","IEEE Conferences"
"EEG-based Cadets Training and Performance Assessment System in Maritime Virtual Simulator","Y. Liu; Z. Lan; O. Sourina; H. P. Liew; G. Krishnan; D. Konovessis; H. E. Ang","Fraunhofer Singapore, Singapore; Fraunhofer Singapore, Singapore; Fraunhofer Singapore, Singapore; Maritime Institute @ Singapore Polytechnic, Singapore; Maritime Institute @ Singapore Polytechnic, Singapore; Dimitrios Konovessis Singapore Institute of Technology, Singapore; Hock Eng Ang School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore",2018 International Conference on Cyberworlds (CW),"27 Dec 2018","2018","","","214","220","Deep investment in the maritime industries has led to many cutting edge technological advances in shipping navigation and operational safety to ensure safe and efficient logistical transportations. However, even with the best technology equipped onboard, maritime accidents are still occurring with at least three quarters of them attributed to human errors. Due to the rising need to address the human factors in shipping operations, various human factors studies are conducted in maritime domain. In this paper, an Electroencephalogram (EEG)-based cadets training and performance assessment system is proposed and implemented that could be used in the maritime virtual simulator. The system includes an EEG processing and analyses part and an evaluation part. It could recognize the brain states such as mental workload, emotions, and stress from raw EEG signal recorded during the exercises in the simulator and then give an indicative recommendation on ""pass"", ""retrain"", or ""fail"" of the cadet based on the EEG recognition results and input of the level of the task difficulty performed.","","978-1-5386-7315-7","10.1109/CW.2018.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590042","EEG;human factors;maritime simulator;assessment;maritime training","Electroencephalography;Stress;Task analysis;Emotion recognition;Support vector machines;Feature extraction;Training","","4","","18","IEEE","27 Dec 2018","","","IEEE","IEEE Conferences"
"Research on Internet of things control system based on EEG signal","Y. Liu; S. Chu; P. Xie; Y. Zhang","School of Information Science and Engineering, Nanjing University Jinling College, Nanjing, China; School of Information Science and Engineering, Nanjing University Jinling College, Nanjing, China; School of Information Science and Engineering, Nanjing University Jinling College, Nanjing, China; School of Information Science and Engineering, Nanjing University Jinling College, Nanjing, China",2022 IEEE 4th International Conference on Civil Aviation Safety and Information Technology (ICCASIT),"27 Dec 2022","2022","","","35","39","The brain computer interface technology using EEG signals is widely used in the fields of emotion recognition, state monitoring, medical rehabilitation, etc. The brain computer interface technology which ""builds a bridge between the human brain and the outside world"" fits perfectly with the Internet of things control system. In this paper, the TGAM module is used as the acquisition module, and the EEG signal acquisition system integrating acquisition, transmission and storage is built by using Bluetooth technology and MATLAB; EMD and ICA technologies are selected to construct the noise reduction system in the collected original signals; Based on SVM (support vector machine), EMD algorithm is used to extract data features and build classification system; Finally, based on STM32, Bluetooth technology is used to realize the connection between the upper and lower computers, the lower computers and the controlled objects, and the Internet of things control system based on motion imagination and using brain computer interface technology is realized.","","978-1-6654-6766-7","10.1109/ICCASIT55263.2022.9987147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9987147","Brain computer interface;Internet of things;EEG signal","Electrodes;Computers;Support vector machines;Noise reduction;Control systems;Feature extraction;Electroencephalography","","","","4","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"Measuring Driver's Emotion","J. Luo; Y. Okaniwa; Y. Hiramatsu; A. Ito; M. Hasegawa","Department of Engineering, Utsunomiya University, Tochigi, Japan; Faculty of Economics, Chuo University, Tokyo, Japan; Faculty of Economics, Chuo University, Tokyo, Japan; Faculty of Economics, Chuo University, Tokyo, Japan; Department of Engineering, Utsunomiya University, Tochigi, Japan",2023 Eleventh International Symposium on Computing and Networking Workshops (CANDARW),"5 Feb 2024","2023","","","1","6","Despite rapid advancements in the automotive industry, traffic safety risks persist. Addressing this challenge requires innovative driver assistance technologies. Common accidents result from driver inattention, fatigue, and stress, leading to issues like falling asleep at the wheel and improper acceleration and braking. In this paper, we developed a sensor network using EEG and eye trackers to measure drivers' emotions, exploring the relationship between emotional states and driving behavior. Our study aims to contribute to advanced driver assistance systems that adapt to drivers' emotional needs, ultimately enhancing road safety.","2832-1324","979-8-3503-0694-1","10.1109/CANDARW60564.2023.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10409818","driving support system;emotion estimation;EEG;eye tracking;sensor network","Wearable Health Monitoring Systems;Wheels;Electroencephalography;Automobiles;Wearable sensors;Vehicles;Accidents","","","","24","IEEE","5 Feb 2024","","","IEEE","IEEE Conferences"
"Fatigue EEG signal detection based on Ensemble learning","J. Chen; J. Liu","School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China",2024 IEEE 4th International Conference on Digital Twins and Parallel Intelligence (DTPI),"12 Dec 2024","2024","","","737","740","In recent years, researchers have proposed a variety of machine learning and deep learning-based techniques to process EEG signals, such as support vector machines, deep learning algorithms, and graph neural networks (GNNs). Particularly, graph neural networks can effectively learn the spatial connectivity relationships between different channels in EEG signals, thereby enhancing the accuracy and robustness of fatigue driving detection. This paper introduces an integrated architecture that combines an information-enhanced network (IENet) with a graph convolutional network (GCN) to augment feature extraction capabilities and improve model classification performance. Through preprocessing EEG data and computing brain connectivity metrics, we trained the graph neural network and validated the method’s superior performance in fatigue driving detection. This research introduces novel methods and concepts aimed at advancing road traffic safety, particularly in mitigating the risks associated with fatigued driving.","","979-8-3503-4925-2","10.1109/DTPI61353.2024.10778733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10778733","EEG;fatigue driving detection;convolutional neural network;Graph Neural Network;Ensemble Learning;Contrastive Learning","Support vector machines;Accuracy;Fatigue;Feature extraction;Brain modeling;Electroencephalography;Stability analysis;Biological neural networks;Signal detection;Vehicles","","","","17","IEEE","12 Dec 2024","","","IEEE","IEEE Conferences"
"EEG-based emotion recognition for high-voltage safety operating procedures","H. Li; P. Wang; Y. Ma; Y. Yang; Y. Zhang; T. Liu","Yunnan Dianneng Smart Energy Co. Ltd., 1302 Dianchi Rd, Kunming, People's Republic of China; Yunnan Diantou Green Energy Technology Co. Ltd., 1302 Dianchi Rd, Kunming, People's Republic of China; Yunnan Dianneng Smart Energy Co. Ltd., 1302 Dianchi Rd, Kunming, People's Republic of China; Yunnan Dianneng Smart Energy Co. Ltd., 1302 Dianchi Rd, Kunming, People's Republic of China; Shanghai Jiao Tong University, 800 Dongchuan Rd, Shanghai, People's Republic of China; Shanghai Jiao Tong University, 800 Dongchuan Rd, Shanghai, People's Republic of China",4th Energy Conversion and Economics Annual Forum (ECE Forum 2024),"21 Mar 2025","2025","2024","","943","947","The safety of high-voltage operating procedures is paramount in the power industry, where emotional stress, fatigue, and cognitive strain can severely impact an operator’s performance, attention, and decision-making. Traditional safety monitoring systems largely overlook these psychological dimensions, focusing instead on physical safety measures. This paper presents an innovative EEG-based emotion recognition framework designed specifically for high-voltage safety operations, addressing this critical gap by providing continuous, real-time assessment of operators' emotional states. The proposed system integrates EEG data with multi-sensor physiological and psychological metrics, enabling real-time monitoring, in-depth analysis, and proactive alerts for pre-, during-, and post-operation phases. Advanced machine learning techniques are employed to extract meaningful patterns from EEG signals, allowing for the early detection of emotional states and cognitive risks. This approach facilitates data-driven decision-making and adaptive interventions to enhance operational safety and reduce error rates in high- stakes environments. The framework’s novelty lies in its continuous, dynamic assessment of cognitive load and emotional state, offering a scientifically grounded, practical tool to improve safety and efficiency in high-voltage operations.","","978-1-83724-292-4","10.1049/icp.2025.0653","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10936127","","","","","","","","21 Mar 2025","","","IET","IET Conferences"
"Survey on Signal Processing and Classification Algorithms for Depression Using Electroencephalogram Signals","S. N; U. A","Department of Electronics and Communication Engineering, PSG College of Technology, Coimbatore, India; Department of Electronics and Communication Engineering, PSG College of Technology, Coimbatore, India","2024 International Conference on Smart Systems for Electrical, Electronics, Communication and Computer Engineering (ICSSEECC)","3 Sep 2024","2024","","","489","494","This survey paper presents various functional neuro-imaging techniques, revealing the excellence of EEG signals in terms of high temporal resolution, expensiveness, non-invasive, ease of use, flexibility, safety and portable when compared to position emission tomography, magneto encephalogram, functional MRI and transcranial magnetic stimulation methods. It also delves into different frequency bands present in EEG signals. The primary objective of this survey paper is to examine findings, related to depression using EEG signals. Subsequently, it discusses preprocessing methods, extraction of features from the preprocessed signal, post processing and result investigation utilizing classification algorithms and statistical testing methods. Finally it identifies research gaps and outlines, potential future findings in depression-related studies.","","979-8-3503-7817-7","10.1109/ICSSEECC61126.2024.10649522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10649522","EEG;Functional neuro-imaging techniques;Signal processing;Survey;Investigation;Classification;Research gap;Depression","Surveys;Magnetic resonance imaging;Machine learning;Feature extraction;Depression;Brain modeling;Electroencephalography","","","","24","IEEE","3 Sep 2024","","","IEEE","IEEE Conferences"
"Effect of Music Intervention Strategies on Mitigating Drivers’ Negative Emotion in Post-congestion Driving","D. Ouyang; G. Li; Q. Li; X. Sui; X. Qu; G. Guo","Institute of Human Factors and Ergonomics, Shenzhen University, Shenzhen, China; College of Mechanical and Vehicle Engineering, Chongqing University, Chongqing, China; School of Vehicle and Mobility, Tsinghua University, Beijing, China; Institute of Human Factors and Ergonomics, Shenzhen University, Shenzhen, China; Institute of Human Factors and Ergonomics, Shenzhen University, Shenzhen, China; College of Mechanical and Vehicle Engineering, Chongqing University, Chongqing, China",2023 IEEE Intelligent Vehicles Symposium (IV),"27 Jul 2023","2023","","","1","6","Traffic congestion is a common phenomenon in city traffic, which may cause drivers' negative emotion to degrade driving safety. It has been reported that music can regulate human emotion and the influence of negative emotion continuously challenges driving safety in post-congestion traffic. Therefore, this study aims to examine the effect of different music intervention strategies on mitigating drivers' negative emotion in post-congestion driving. Three experiments (i.e., driving with soft music, driving with disco jockey (DJ) music, and driving without music) are designed to collect drivers' driving performance measures, eye movement and electroencephalogram (EEG) responses in post-congestion driving. The results show that the music intervention strategies influence drivers' eye movement and EEG responses to varying degrees but do not have distinct effect in driving performance measures. These obtained results indicate that designing personalized music intervention strategies might help mitigate drivers' negative emotion to increase driving safety and comfort.","2642-7214","979-8-3503-4691-6","10.1109/IV55152.2023.10186669","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10186669","music intervention;traffic congestion;driving performance;eye movement;EEG","Electrodes;Intelligent vehicles;Urban areas;Electroencephalography;Safety;Multiple signal classification;Behavioral sciences","","3","","38","IEEE","27 Jul 2023","","","IEEE","IEEE Conferences"
"Investigating the Influence of Driving on Brain Connectivity Networks and Emotion Processing Mechanism Based on EEG Signals","G. Li; L. Zhang; C. Li; Z. Li; F. Gao; L. Zheng; P. Green","College of Mechanical and Vehicle Engineering, Chongqing University, Chongqing, China; Institute of Human Factors and Ergonomics, College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, China; National Elite Institute of Engineering, Chongqing University, Chongqing, China; State Key Laboratory of Internet of Things for Smart City, University of Macau, Macau, China; College of Mechanical and Vehicle Engineering, Chongqing University, Chongqing, China; College of Mechanical and Vehicle Engineering, Chongqing University, Chongqing, China; University of Michigan Transportation Research Institute (UMTRI), Ann Arbor, MI, USA",IEEE Sensors Journal,"31 Oct 2024","2024","24","21","35333","35345","Humans are frequently driving with different emotions, but how driving affects the human brain information processing mechanism in different emotional states is still unknown. In this study, we investigate the effects of driving on brain functional connectivity networks across different emotions based on electroencephalogram (EEG) signals. We utilize the phase lag index (PLI) to measure the degree of phase synchronization among electrode channels and visualize the functional connectivity networks. We also employ graph theory to analyze the functional connectivity networks. Our findings indicate that the strength of functional connectivity among brain regions under different emotions significantly increased after involving in driving, with more efficient and rapid information transmission in the functional connectivity networks. This enhancement is particularly evident in the frontal and parietal lobes, with 507 enhanced connections related to the frontal lobe and 300 related to the parietal lobe, accounting for 41.94% and 24.81% of the total enhanced connections, respectively. These results offer valuable insights into the understanding of how human drives, holding potential for the development of interventions and technologies to improve emotional regulation and driving safety technologies.","1558-1748","","10.1109/JSEN.2024.3466124","Natural Science Foundation of Chongqing(grant numbers:CSTB2023NSCQ-MSX0985); National Natural Science Foundation of China(grant numbers:52272421); State Key Laboratory of Intelligent Green Vehicle and Mobility(grant numbers:KFZ2409); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10697352","Electroencephalography;functional connectivity;graph theory","Electroencephalography;Electrodes;Sensors;Feature extraction;Synchronization;Emotion recognition;Accuracy;Phase measurement;Fatigue;Brain modeling","","1","","42","IEEE","27 Sep 2024","","","IEEE","IEEE Journals"
"Edge Computing With Complementary Capsule Networks for Mental State Detection in Underground Mining Industry","M. Wang; J. Wang; Y. Li; H. Lu","Xi'an University of Science and Technology, Xian, China; Ebm-papst Ventilator (Xi'an) Co., Ltd, Xian, China; Xi'an University of Science and Technology, Xian, China; Kyushu Institute of Technology, Kyushu, Japan",IEEE Transactions on Industrial Informatics,"21 Jun 2023","2023","19","7","8508","8517","Most safety accidents are caused by human factor in underground resource mining industry. This is because the nonuniform lighted and noisy and dangerous environment easily evokes the negative mental state and causes the nonstandard production operation. Aiming at the difficult problem to be solved urgently, this article proposes an edge computing mental state framework of the Internet of Things in the underground mining industry. Moreover, a filtering algorithm using a defined threshold function is developed. Furthermore, an complemented capsule network model is constructed by using two residual modules. Specially, a two-stage mental state fusion algorithm is proposed with electrocardiogram signals and facial expression. Finally, the mental state variation characteristics are explored with the underground illuminating and coloring. Experiments show that the mental state detection accuracy is increased by 2.6%. The higher mental arousal is at the illumination between 320 Lx and 330 Lx.","1941-0050","","10.1109/TII.2022.3218839","Science and Technology Innovation 2030- “New generation of artificial intelligence” Major Project of China(grant numbers:2022ZD0119000); Natural Science Foundation Key Project of China(grant numbers:61834005); Chinese Society of Academic Degrees and Graduate Education(grant numbers:B-2017Y0002-170); Shaanxi Province Key Research and Development Project(grant numbers:2016GY-040); Yulin City Science and Technology Project(grant numbers:CXY-2020-026); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9935298","Capsule network (CapsNet);edge computing;electrocardiogram (EEG) signals;environmental evocation;mental state detection;mining industry","Electroencephalography;Edge computing;Mining industry;Brain modeling;Safety;Informatics;Wavelet packets","","7","","30","IEEE","2 Nov 2022","","","IEEE","IEEE Journals"
"Electroencephalogram-Based Driver Emotional State Detection with Manifold Learning","W. Zhang; Y. Qin; S. Zhang; X. Tao","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Digital Media Institute, Peking University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China",2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC),"13 Feb 2024","2023","","","3329","3334","The detection of the driver emotional state is very important as it is closely related to driving safety. With the development of electroencephalogram (EEG) signal processing and deep learning, researchers are now studying emotional states through EEG signals. However, currently related studies focus less on specific driving tasks, and the model frequently adopted are relatively simple, having limited feature extraction abilities. This paper is dedicated to the study of detecting driver emotional states based on EEG, focusing on a task containing seven categories of driver emotional states, which is relatively complex. We propose a manifold learning model that incorporates feature extraction of symmetric positive definite (SPD) matrix manifold. Experimental results demonstrate that our method outperforms the baselines in detecting various emotional states during driving. This study is useful for detecting human factors in driver emotional state and also helps to prevent traffic accidents caused by negative emotions, thus contributing to the intelligent traffic safety systems.","2153-0017","979-8-3503-9946-2","10.1109/ITSC57777.2023.10422309","National Natural Science Foundation of China(grant numbers:62227801,61925105); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10422309","","Manifolds;Feature extraction;Brain modeling;Electroencephalography;Manifold learning;Safety;Task analysis","","","","26","IEEE","13 Feb 2024","","","IEEE","IEEE Conferences"
"Brain-in-Car: A Brain Activity-based Emotion Recognition Embedded System for Automotive","A. El-Amin; A. Attia; O. Hammad; O. Nasr; O. Ghozlan; R. Raouf; A. M. Hamed; H. Eldawlatly; M. El-Moursy; S. Eldawlatly","Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt; Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt; Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt; Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt; Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt; Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt; A Siemens Business, Cairo, Egypt; A Siemens Business, Cairo, Egypt; A Siemens Business, Cairo, Egypt; Faculty of Media Engineering and Technology, German University in Cairo",2019 IEEE International Conference on Vehicular Electronics and Safety (ICVES),"21 Nov 2019","2019","","","1","5","Emotional distress during driving can greatly affect the safety and comfort of the driver. Being able to detect and react to the emotions of the driver would greatly improve in-car safety. It could also be utilized in a variety of different applications to improve the driving experience. In this paper, we introduce a brain signal-operated emotion recognition system that is specifically tailored for the Automotive Open System Architecture (AUTOSAR) framework. The proposed system acquires brain electroencephalography (EEG) signals of the driver, identifies the underlying emotion using machine learning techniques, and feeds that emotion into the car system where different car components can react to that input. Our results demonstrate the ability of the system to recognize two emotions, namely sadness versus happiness, from the recorded EEG with a mean accuracy of 89.7% across three examined subjects using subject-dependent data. Moreover, when training the system using data recorded from multiple subjects, a mean accuracy of 91.7% is achieved. Taken together, these results indicate the ability of the proposed approach to discriminate between sadness and happiness whose extreme expression could have a significant impact on driving behavior.","2643-9751","978-1-7281-3473-4","10.1109/ICVES.2019.8906392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906392","Electroencephalography;Machine Learning;AUTOSAR","","","6","","12","IEEE","21 Nov 2019","","","IEEE","IEEE Conferences"
"Driver Cognitive Architecture Based on EEG Signals: A Review","P. Mi; L. Yan; Y. Cheng; Y. Liu; J. Wang; M. U. Shoukat; F. Yan; G. Qin; P. Han; Y. Zhai","School of Automotive Engineering, Wuhan University of Technology, Wuhan, China; School of Automotive Engineering, Wuhan University of Technology, Wuhan, China; School of Automotive Engineering, Wuhan University of Technology, Wuhan, China; School of Automotive Engineering, Wuhan University of Technology, Wuhan, China; School of Automotive Engineering, Wuhan University of Technology, Wuhan, China; School of Automotive Engineering, Wuhan University of Technology, Wuhan, China; School of Automotive Engineering, Wuhan University of Technology, Wuhan, China; Teachers College for Vocational and Education, Guangxi Normal University, Guilin, China; Xiangyang DAAN Automobile Test Center Corporation Ltd., Xiangyang, China; Xiangyang DAAN Automobile Test Center Corporation Ltd., Xiangyang, China",IEEE Sensors Journal,"13 Nov 2024","2024","24","22","36261","36286","To improve the driving performance of vehicles, it is of great significance to study the changes in the driver’s brain cognition during driving and to establish an intelligent driving computational framework based on the cognitive process. Electroencephalogram (EEG) is an effective means to study driver cognition because of its low cost, high temporal resolution, and different cognitive state information. The application of brain-computer interface (BCI) technology based on EEG signals to driver assistance systems has the potential to transform the way humans interact with vehicles. It can also help intelligent vehicles to understand and predict driver’s behavior and to enhance the cognitive ability of vehicles. This article reviews the research on theorizing and modeling driver cognitive processes based on cognitive architectures (e.g., adaptive control for thoughtful rationality (ACT-R), queuing network (QN), and Soar) and proposes an EEG-based driver cognitive architecture. Then, according to the relationship between the modules of this proposed driver cognitive architecture, the driver’s perception of stationary and hazardous scenarios in the driving environment, the understanding of the driver’s intention to control the longitudinal and lateral movements of the vehicle, and the influence of driver’s working memory as well as human factors, such as fatigue, distraction, and emotion on driving performance based on EEG signals, are reviewed. The integration of EEG signals with cognitive modeling has the potential to improve the accuracy of driver perception, intention, and cognitive state prediction, thereby enhancing vehicle safety.","1558-1748","","10.1109/JSEN.2024.3471699","Key Research and Development Program of Hubei Province(grant numbers:2022AAA001); Project for Enhancing Young and Middle-Aged Teacher’s Research Basic Ability in Colleges of Guangxi(grant numbers:2023KY0061); Natural Science Foundation of China(grant numbers:61876137); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10706793","Cognitive architecture;driver cognition;electroencephalogram;intelligent vehicle","Brain modeling;Vehicles;Cognition;Process control;Electroencephalography;Analytical models;Visualization;Psychology;Predictive models;Memory management","","1","","204","IEEE","7 Oct 2024","","","IEEE","IEEE Journals"
"Real Environment Warning Model for Visually Impaired People in Trouble on the Blind Roads Based on Wavelet Scattering Network","Z. Yu; M. Hu","Guangdong Peizheng College, Guangzhou, China; Guangdong Peizheng College, Guangzhou, China",IEEE Access,"14 Jun 2024","2024","12","","82156","82167","When the visually impaired walk on the blind road, once they encounter obstacles to block the road, it will bring panic and even safety risks to the visually impaired. To solve this problem, based on the wavelet scattering network (WSN), this study proposes a real environment warning mode for visually impaired people when they are in trouble on the blind road. When the blind road is interrupted or obstructed, visually impaired people will experience tension or anxiety. In this study, Based on electroencephalogram (EEG) signals, this study uses the WSN method to identify the emotional state of visually impaired people, and then determine whether they need assistance. The wavelet scattering coefficients of EEG signals are extracted using the WSN method, resulting in the formation of a feature matrix. Subsequently, a support vector machine is employed for the purposes of classification and recognition. The results show that the recognition accuracy of this method reaches 95.11% in the three states of normal emotional state, general nervous state, and very nervous state of the created datasets. The classification accuracy on the SEED-IV dataset is 86.14%. The WSN method suggested in this study exhibits superior recognition accuracy and the quickest algorithm execution time when compared to previous emotion identification methods. In addition, compared with the no-warning model, the warning model proposed in this study can greatly reduce the time it takes for visually impaired people to wait for help. The WSN-based warning mode provides more reliable travel assistance for visually impaired people and reduces the risk of accidental injury.","2169-3536","","10.1109/ACCESS.2024.3412328","Project of Guangdong Provincial Department of Education(grant numbers:2023KTSCX186); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10552699","Visually impaired people;EEG;WSN;blind road;early warning mode","Electroencephalography;Wireless sensor networks;Emotion recognition;Brain modeling;Scattering;Visual impairment;Alarm systems","","1","","38","CCBYNCND","11 Jun 2024","","","IEEE","IEEE Journals"
"AI Driven Psychological Pattern Analysis through Deep Learning-Enhanced Wearable Monitoring Systems","M. Abed Jawad; M. A. Mohammed; A. Al-Hilali; F. H. Taha Hussain","Al-Nisour University College, Baghdad, Iraq; Department of Computer Engineering, College of Engineering, Knowledge University, Erbil, Iraq; Department of Medical Instruments Engineering Techniques, Al-Farahidi University, Baghdad, Iraq; Department of Medical Engineering, Al Kitab University, Kirkuk, Iraq",2024 International Conference on Emerging Research in Computational Science (ICERCS),"27 Feb 2025","2024","","","1","5","Quantitative research on tension environments has mostly used mobile assessment experiments in standardized settings. Recently, sensors and eye-tracking glasses have dedicated resources to future technologies, including multisensory monitoring systems that contain psychophysiological data in daily circumstances. This research proposes a Deep Learning aided wearable monitoring system (DLWMS) for psychological pattern analysis and mobile phone stress monitoring. Such systems must analyze stress states in mobile situations and look for tension parameter fluctuations. Using advanced quantitative monitoring system devices to collect physiological data on customers may help researchers study information systems (IS), which conventional treatments do not use. Participants demonstrate the possibility and acceptability of using m-Health technologies for psychophysiological health education. This approach helps prospective studies evaluate these technologies for optimizing safety in this sensitive population.","","979-8-3315-3496-7","10.1109/ICERCS63125.2024.10895927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895927","Wearable Sensor;Information System;Healthcare","Accuracy;Computational modeling;Human factors;Brain modeling;Data models;Sensors;Psychophysics;Biomedical monitoring;Pattern analysis;Monitoring","","","","22","IEEE","27 Feb 2025","","","IEEE","IEEE Conferences"
"Modulation of Driver's Emotional States by Manipulating In-Vehicle Environment: Validation With Biosignals Recorded in An Actual Car Environment","H. Kim; S. Kim; H. Kim; Y. Ji; C. -H. Im","Department of Biomedical Engineering and the Department of Electronic Engineering, Hanyang University, Seoul, Republic of Korea; Department of Biomedical Engineering and the Department of Electronic Engineering, Hanyang University, Seoul, Republic of Korea; Hyundai Motor Company, Hwaseong, Republic of Korea; Hyundai Motor Company, Hwaseong, Republic of Korea; Department of Biomedical Engineering and the Department of Electronic Engineering, Hanyang University, Seoul, Republic of Korea",IEEE Transactions on Affective Computing,"28 Nov 2022","2022","13","4","1783","1792","A driver's emotional state can affect driving performance. According to the studies on the driving performance based on the circumplex (arousal-valence) model of affect, negative emotions such as anger and sadness can severely hinder safe driving. In this study, we developed a system to modulate drivers’ emotions to designated emotional states by manipulating in-vehicle environments, such as ambient lighting, background music, scent, ventilation, and rear curtains. The proposed system, named the “mood-modulator” system, consists of four different modes, designed to induce different emotional states. The feasibility of the “mood-modulator” system was evaluated using electroencephalogram (EEG) and photoplethysmogram (PPG) signals recorded from 48 drivers in an actual car environment. In the experiments, negative emotions were induced for each participant using short movie clips. Then, one of the four modes (different in-vehicle environments) was executed, during which both EEG and PPG data were acquired. We quantitatively evaluated whether each mode could effectively induce targeted emotional valence using machine learning classifier models, individually constructed from EEG data recorded during calibration sessions. The modulation of emotional arousal by each mode was also assessed using heart rate and respiration rate extracted from the PPG data. Our results demonstrated that the four modes could effectively increase the participant's emotional valence and modulate emotional arousal state to the intended direction. To the best of our knowledge, this is the first study to quantitatively evaluate a system that modulates a driver's emotional state using biosignals recorded in an actual car.","1949-3045","","10.1109/TAFFC.2022.3206222","Hyundai Motor Company; Kia corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889224","Driving safety;Emotion;Machine learning;electroencephalogram (EEG);photoplethysmogram (PPG)","Vehicles;Color;Lighting;Ventilation;Electroencephalography;Automobiles;Music","","6","","43","IEEE","13 Sep 2022","","","IEEE","IEEE Journals"
"5 Neurophysiological Driver Behavior Analysis","N. Kamaruddin; A. Wahab; K. F. Alarabi; H. Abut",NA; NA; NA; NA,"Vehicles, Drivers, and Safety","","2020","","","67","86","People behave differently even under similar situations especially when driving. This is due to their behavior, exposure, experience, and judgment when facing certain phenomena, which in turn affect their driving capability. Each individual has a set of unique patterns of personality traits that derive and influence the behavior. With the advancement of technology, personality traits have become measurable. Therefore, driver behavior can be predicted to a certain degree through the assessment of driver personality. Personality is determined by means of interviews or self-reported questionnaires. However, these approaches are very much dependent on the truthfulness and honesty of the participants when answering the questionnaires, as they may have the tendency to exaggerate or suppress the answers. Hence, an alternative approach of using input without biasness of participants is needed. In this work, we employed neurophysiological input from brain signals captured from electroencephalograms (EEG) to measure emotion and link this to the understanding of personality. This is to study the correlation between the behavior and emotion based on the hypotheses that emotion influences on behavior and personality are affected by behavior. Experimental results indicate that emotion can be measured using the proposed approach, with accuracy ranging from 60% to 99% for happiness, fear, sadness, and calmness. The conscientiousness in personality traits is then measured and analyzed. It is found that there is a negative correlation between the conscientiousness and valence for fear, making it possible to detect this trait. These findings can be extended to understand driver behavior, which potentially could lead to safer driving and avoiding accidents.","","9783110666571","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10788986.pdf&bkn=10783076&pdfType=chapter","","Vehicles;Human factors;Accidents;Particle measurements;Electroencephalography;Correlation;Atmospheric measurements;Emotion recognition;Drugs;Anxiety disorders","","","","","","16 Jan 2025","","","De Gruyter","De Gruyter eBook Chapters"
"A Radical Approach To Depression Detection","S. Md; H. Sathish; K. S. Koulini; A. Inamdar; U. Ananthanagu","Dept. of Computer Science Engg., PES University; Dept. of Computer Science Engg., PES University; Dept. of Computer Science Engg., PES University; Dept. of Computer Science Engg., PES University; PES University",2022 IEEE 7th International conference for Convergence in Technology (I2CT),"18 Jul 2022","2022","","","1","6","Early identification of depression is at the forefront of mental health awareness and treatment improvement. The rapid advancement of technology can be used to enhance therapeutic approaches. The current and popular detection approaches are insufficiently tailored, relying mostly on professional expertise and knowledge. Previously conducted experiments, such as those based solely on speech, facial expressions, and other indicators, can be affected by the respondents' current state or mood. Others, such as EEG, have access and equipment concerns. The methodology proposed uses an ensemble of inputs, consisting of the user's speech and text, to predict the severity of depression. When these inputs are provided via a chatbot, the user is more likely to respond honestly. The audio samples in the AVEC dataset are labeled with the PHQ-8 score and a binary representation of depressed or not depressed. Spectral features are extracted from these samples and are passed as arrays through neural network models. A transformer-based machine learning model is used to classify text-based responses into one of five emotions: sadness, rage, joy, fear, and neutral. Speech and text classification accuracies were calculated, and their scores were finally aggregated. Since many do not seek help due to socio-economic barriers, the proposed method can readily be integrated into a virtual platform to overcome such obstacles. We believe that this method can serve as a radical approach to detecting depression. It would serve as a platform for level-one screening, enabling individuals to gauge the severity of their condition from the safety of a screen.","","978-1-6654-2168-3","10.1109/I2CT54291.2022.9825306","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825306","Mental Health;Depression;PHQ8;Deep Learning;Convolutional Neural Network (CNN);Machine Learning;Random Forest;Mel Frequency Cepstral Coefficients (MFCC);BERT;Artificial Intelligence;Natural Language Processing (NLP)","Mood;Neural networks;Text categorization;Mental health;Machine learning;Depression;Feature extraction","","1","","14","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Construction of Data Intelligent Evaluation System for Children's Sense of Humor based on the Fusion of Facial Expression Recognition and Blink Frequency Recognition Algorithms","G. Guo","South China Business College Guangdong University of Foreign Studies, Guangzhou, China",2022 3rd International Conference on Electronics and Sustainable Communication Systems (ICESC),"19 Sep 2022","2022","","","1453","1456","Based on the relationship analysis of the subjects' left forehead EEG signal fusion expression recognition and blink frequency recognition algorithms and Blink data, the optimal window width and classification algorithm were screened respectively, and a humor detection algorithm suitable for wearable devices was designed. , and then construct a data intelligent evaluation system of children's sense of humor through Bayesian network based on student information and contextual information of teaching activities. The sense of humor in the kindergarten is mainly for viewing; the sense of humor focuses on education; the safety guarantee pays attention to the feedback of space, and the evaluation form of sports space in kindergarten is obtained according to the system.","","978-1-6654-7971-4","10.1109/ICESC54411.2022.9885443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9885443","Data Intelligent Evaluation;Children's Sense;Humor;Facial Expression Recognition;Blink Frequency Recognition Algorithms","Training;Forehead;Face recognition;Wearable computers;Electroencephalography;Classification algorithms;Windows","","","","22","IEEE","19 Sep 2022","","","IEEE","IEEE Conferences"
"Integrated Approach for Cross-Modal Brain Activity Classification Through Manual Feature Extraction","P. Zhang; X. Zou","School of Information Engineering, Chang'an University, Xi'an, China; College of Urban Transportation and Logistics, Shenzhen Technology University, Shenzhen, China","2024 3rd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR)","30 Apr 2025","2024","","","49","55","Effective classification of brain activity is crucial in the process of human-computer interaction. For different data sources., such as EEG signals and fNIRS signals., specific analysis models have been designed according to their respective advantages., but there is a lack of a lightweight and efficient general framework for the analysis of brain activity signals across modal data to achieve the classification task of different timing signals. In this paper., a general brain activity recognition framework with cross-modal capability is proposed. By combining artificial feature extraction with deep learning., the framework can process signals from different data modes and capture potential associations between data through a unified data analysis process. The framework was validated using four open datasets from EEG and fNIRS., a variety of brain activity collected during various inter-active tasks. This approach ensures reliable evaluation acro-ss multiple models. This study provides theoretical and pra-ctical advancements for Bel research., particularly in deve-Ioping more robust., interpretable., and efficient models for brain activity recognition. The universal cross-modal frame-work can be applied to a wide range of interaction tasks., contributing to improved cognitive load assessment., emotion recognition., and overall human-computer interaction safety and performance.","","979-8-3315-3403-5","10.1109/AIHCIR65563.2024.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10974263","Cross-modal;Human-computer interaction;Artificial feature extraction;Deep learning","Human computer interaction;Deep learning;Activity recognition;Brain modeling;Feature extraction;Electroencephalography;Safety;Functional near-infrared spectroscopy;Load modeling;Overfitting","","","","40","IEEE","30 Apr 2025","","","IEEE","IEEE Conferences"
"Affective Driver State Monitoring for Personalized, Adaptive ADAS","V. Govindarajan; K. Driggs-Campbell; R. Bajcsy","Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA",2018 21st International Conference on Intelligent Transportation Systems (ITSC),"9 Dec 2018","2018","","","1017","1022","We seek to improve vehicle automation by using the state of the driver to develop an adaptive assistance system. We focus on the problem of measuring the driver state under varying levels of cognitive workload using affective (i.e. emotion) sensing, including thermal facial analysis and electroencephalography (EEG). This information is then used in sensor fusion and machine learning algorithms to help predict the brake reaction time of the driver, a key input in forward collision warning systems. We demonstrate the results in a pilot study, which highlights the benefits of the personalized, adaptive reaction time estimation in collision warning alert performance. A 40-50% improvement in alert precision is observed with the adaptive approach. We conclude with improvements to further strengthen the quality of the reaction time estimation and improve alert performance.","2153-0017","978-1-7281-0323-5","10.1109/ITSC.2018.8569585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8569585","","Vehicles;Task analysis;Electroencephalography;Monitoring;Brakes;Sensors;Safety","","9","","42","IEEE","9 Dec 2018","","","IEEE","IEEE Conferences"
