"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Single-trial ERP detecting for emotion recognition","J. Jiang; Y. Zeng; L. Tong; C. Zhang; B. Yan","National Digital Switching System Engineering & Technological R&D Center, Zhengzhou, China; National Digital Switching System Engineering & Technological R&D Center, Zhengzhou, China; National Digital Switching System Engineering & Technological R&D Center, Zhengzhou, China; National Digital Switching System Engineering & Technological R&D Center, Zhengzhou, China; National Digital Switching System Engineering & Technological R&D Center, Zhengzhou, China","2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","21 Jul 2016","2016","","","105","108","Emotion recognition, as an important part of human-computer interaction, has been extensively researched. Various studies have already verified the relationship between emotion and the event-related potentials (ERPs). In this paper, a new methodology for emotion recognition is investigated by detecting single-trial ERPs related to some specific level of emotions. First, a spatial filter is constructed to estimate the ERP components. Then the most discriminative spatial and temporal features of the entire ERP waveform are extracted with linear discriminant analysis. The performance of this method is tested by classifying the emotional valence on three levels, the extremely negative, the moderately negative and the neutral, with the support vector machine (SVM). The result shows that the proposed method is effective.","","978-1-5090-2239-7","10.1109/SNPD.2016.7515886","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515886","emotion recognition;EEG;ERP;single-trial;spatial-temporal feature","Emotion recognition;Spatial filters;Electroencephalography;Classification algorithms;Support vector machines;Covariance matrices;Training","","7","","11","IEEE","21 Jul 2016","","","IEEE","IEEE Conferences"
"Single-trial event-related potential emotional classification based on compressed sensing","X. Zhang; F. Li; J. Chang; L. Huang; Y. Sun; S. Duan","College of Information Engineering, Taiyuan University of Technology Taiyuan, China; College of Information Engineering, Taiyuan University of Technology Taiyuan, China; College of Information Engineering, Taiyuan University of Technology Taiyuan, China; College of Information Engineering, Taiyuan University of Technology Taiyuan, China; College of Information Engineering, Taiyuan University of Technology Taiyuan, China; College of Information Engineering, Taiyuan University of Technology Taiyuan, China",2017 International Conference on Orange Technologies (ICOT),"12 Apr 2018","2017","","","172","175","In this study, a robust classification method for emotional speech single-trial event-related potential (ERP) signal was developed. The classification method based on compression sensing (CS) theory. First, we use CS theory to reduce the dimensionality of the ERP signal. Second, the ERP signal was reconstructed by using K-SVD method to construct the over-complete redundant dictionary. Finally, the ERP signal was classified by calculating the residuals between the reconstructed samples and the test samples. The experimental results show that the proposed algorithm can effectively classify the noisy ERP signal and avoid the feature extraction process in the signal recognition.","","978-1-5386-3276-5","10.1109/ICOT.2017.8336115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8336115","Compression Sensing;EEG;Event-related Potential;Signal Classification","Dictionaries;Electroencephalography;Classification algorithms;Matching pursuit algorithms;Pattern classification;Training;Electronic mail","","1","","8","IEEE","12 Apr 2018","","","IEEE","IEEE Conferences"
"Stimulus Inversion and Emotional Expressions Independently Affect Face and Body Perception: An ERP Study","F. Bossi; P. Ricciardelli; D. Rivolta","Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Psychology, University of Milano–Bicocca, Milan, Italy; School of Psychology, University of East London (UEL), London, U.K.",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"14 Aug 2024","2024","32","","2914","2927","Faces and bodies provide critical cues for social interaction and communication. Their structural encoding depends on configural processing, as suggested by the detrimental effect of stimulus inversion for both faces (i.e., face inversion effect - FIE) and bodies (body inversion effect - BIE). An occipito-temporal negative event-related potential (ERP) component peaking around 170 ms after stimulus onset (N170) is consistently elicited by human faces and bodies and is affected by the inversion of these stimuli. Albeit it is known that emotional expressions can boost structural encoding (resulting in larger N170 components for emotional than for neutral faces), little is known about body emotional expressions. Thus, the current study investigated the effects of different emotional expressions on structural encoding in combination with FIE and BIE. Three ERP components (P1, N170, P2) were recorded using a 128-channel electroencephalogram (EEG) when participants were presented with (upright and inverted) faces and bodies conveying four possible emotions (happiness, sadness, anger, fear) or no emotion (neutral). Results demonstrated that inversion and emotional expressions independently affected the Accuracy and amplitude of all ERP components (P1, N170, P2). In particular, faces showed specific effects of emotional expressions during the structural encoding stage (N170), while P2 amplitude (representing top-down conceptualisation) was modified by emotional body perception. Moreover, the task performed by participants (i.e., implicit vs. explicit processing of emotional information) differently influenced Accuracy and ERP components. These results support integrated theories of visual perception, thus speaking in favour of the functional independence of the two neurocognitive pathways (one for structural encoding and one for emotional expression analysis) involved in social stimuli processing. Results are discussed highlighting the neurocognitive and computational advantages of the independence between the two pathways.","1558-0210","","10.1109/TNSRE.2024.3439129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10623496","ERP;N170;body perception;inversion effect;emotional expression;face perception;mixed models","Faces;Encoding;Face recognition;Emotion recognition;Electroencephalography;Brain modeling;Analytical models","Humans;Male;Emotions;Female;Electroencephalography;Young Adult;Facial Expression;Adult;Evoked Potentials;Facial Recognition;Photic Stimulation;Visual Perception;Kinesics","1","","64","CCBY","5 Aug 2024","","","IEEE","IEEE Journals"
"Recognition and analyses of EEG & ERP signals related to emotion: from the perspective of psychology","Yang Yuankui; Zhou Jianzhong","Research Center for Learning Science, South-East University, Nanjing, China; Research Center for Learning Science, South-East University, Nanjing, China","Proceedings. 2005 First International Conference on Neural Interface and Control, 2005.","29 Aug 2005","2005","","","96","99","Electroencephalography (EEG) is widely used to record activities of human brain in the area of psychology for many years. With the development of technology, neural basis of functional areas of emotion processing is revealed gradually. In order to extract the useful information of emotion from the background of EEG signals and noise, we propose to combine methods of psychology and the technology of signal processing such as pattern recognition, etc. In this paper, we first review the psychological methods and signal processing technology in the field of emotion research, and point out the junctions of these two approaches. Secondly, we introduce a method to evaluate emotion competence objectively, which involves the analyses of frequency fluctuations of EEG signals and frontal EEG asymmetry. Then, we take an example of event-related potentials (ERP) study about the face recognition task and the discrimination of sad/happy/neutral emotional facial expressions task. Finally, we indicate the present difficulties in this research area, and advance the possible solution to resolve these problems.","","0-7803-8902-6","10.1109/ICNIC.2005.1499851","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1499851","","Emotion recognition;Signal analysis;Electroencephalography;Enterprise resource planning;Psychology;Signal processing;Humans;Data mining;Background noise;Pattern recognition","","6","","5","IEEE","29 Aug 2005","","","IEEE","IEEE Conferences"
"Children Emotion Regulation: Development of Neural Marker by Investigating Human Brain Signals","R. M. Mehmood; H. -J. Yang; S. -H. Kim","Information and Communication Technology Department, School of Electrical and Computer Engineering, Xiamen University Malaysia, Sepang, Malaysia; Department of Computer Science, Chonnam National University, Gwangju, South Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea",IEEE Transactions on Instrumentation and Measurement,"18 Nov 2020","2021","70","","1","11","Affects recognition and regulation has become an interesting research topic given the noninvasive application of electroencephalography (EEG). EEG patterns are generated through electrical activity over the human scalp, but the collected data from these sensors are quite complex due to noise and artifacts. Given the complex nature of human brain signals, emotion recognition and regulation are still challenging problems. By emphasizing and aiming to improve the human living, how could be possible to prevent emotional or behavioral disorder in children in their early age? Therefore, it is essential to investigate the children’s emotions. In this study, we present a mechanism to regulate children’s emotions. Over 40 subjects’ EEG data were collected and performed a late-positive-potential (LPP) analysis in EEGLAB. By investigating late positive potential during emotion regulatory analysis, we find a significant difference in modulation and amplitude between control/special subjects that may help in early detection of mood disruption problems.","1557-9662","","10.1109/TIM.2020.3011817","National Research Foundation of Korea (NRF) Grant; Korea Government (MSIT)(grant numbers:NRF-2018R1A2B6006046); Korea University Grant; Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education(grant numbers:NRF-2017R1A4A1015559); Xiamen University Malaysia Research Fund (XMUMRF)(grant numbers:XMUMRF/2019-C3/IECE/0007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146936","Children’s emotions;electroencephalography (EEG);emotion regulation;event-related potential (ERP);late-positive-potential (LPP);mood disruption","Electroencephalography;Emotion recognition;Physiology;Brain modeling;Visualization;Electrodes;Mood","","15","","74","IEEE","24 Jul 2020","","","IEEE","IEEE Journals"
"Precedence of Emotional Features in Emotional Prosody Processing: Behavioral and ERP Evidence","X. Chen; Y. Yang","State Key Laboratory of Brain and Cognitive Science,Institute of Psychology, Chinese Academy and Sciences, Beijing, China; State Key Laboratory of Brain and Cognitive Science,Institute of Psychology, Chinese Academy and Sciences, Beijing, China",2010 International Conference on Asian Language Processing,"6 Jan 2011","2010","","","323","326","To test whether emotional feature has precedence in emotional prosody processing, the present study asks subjects to determine the change of the sentence via emotional feature or intensity while Event-related potentials (ERPs) were recorded. The result indicated that listeners are more accurate and faster at determining the changes of emotional feature than intensity, and the changes of emotional feature can be detected and integrated irrespective of attention allocation while the changes of intensity can only be detected with focus attention. These findings suggest that low level acoustic decoding is more interfered by high level emotional feature in emotional prosody processing, implying that emotional feature has precedence over single acoustic cue in vocal emotion perception.","","978-1-4244-9063-9","10.1109/IALP.2010.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681577","emotional prosody;ERP;intensity;gloabal precedenc","Acoustics;Psychology;Electroencephalography;Analysis of variance;Error analysis;Visualization;Humans","","","","17","IEEE","6 Jan 2011","","","IEEE","IEEE Conferences"
"Detection and Analysis of ERPs for Social Cognition Evaluation","Y. Cabarcas-Mena; K. Gutierrez-Ruiz; K. C. Campo-Landines; S. H. Contreras-Ortiz","Biomedical Engineering Program, Universidad Tecnológica de Bolívar, Cartagena de Indias, Colombia; Psychology Program, Universidad Tecnológica de Bolívar, Cartagena de Indias, Colombia; Psychology Program, Universidad Tecnológica de Bolívar, Cartagena de Indias, Colombia; Biomedical Engineering Program, Universidad Tecnológica de Bolívar, Cartagena de Indias, Colombia",2022 IEEE ANDESCON,"28 Dec 2022","2022","","","1","6","This paper describes an approach for elicitation, acquisition, and analysis of event-related potentials (ERPs) for social cognition evaluation. We used images of emotional content that were classified into three groups according to their valence: pleasant, unpleasant, and neutral. An application for stimuli generation based on the emotional oddball paradigm (EOP) was developed, and a commercial wireless EEG headset was used for signal acquisition. The ERPs of 13 volunteers for the three types of stimuli were obtained and analyzed to extract the N100 and P300 components. The results show increased amplitudes in ERP components due to unpleasant stimuli and longer latencies observed in neutral stimuli.","","978-1-6654-8854-9","10.1109/ANDESCON56260.2022.9989524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9989524","ERP components;EEG;wavelet filtering;social cognition;affective computing","Headphones;Wireless communication;Emotion recognition;Psychology;Cognition;Electroencephalography","","","","33","IEEE","28 Dec 2022","","","IEEE","IEEE Conferences"
"Classifying human emotional states using wireless EEG based ERP and functional connectivity measures","V. Bono; D. Biswas; S. Das; K. Maharatna","Electronics and Computer Science, University of Southampton, Hampshire, UK; Electronics and Computer Science, University of Southampton, Hampshire, UK; Electronics and Computer Science, University of Southampton, Hampshire, UK; Electronics and Computer Science, University of Southampton, Hampshire, UK",2016 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI),"21 Apr 2016","2016","","","200","203","In this paper we present a systematic exploration to determine several EEG based features for classifying three emotional states (happy, fearful and neutral) pertaining to face perception. EEG data were acquired through a 19-channel wireless system from eight adults under two conditions - in a constrained position and involving head-body movements. The movement EEG data was pre-processed using an artifact reduction algorithm and both datasets were processed to extract neurophysiological features - ERP components and from functional connectivity measures. The functional connectivity measures were processed using a brain connectivity toolbox and gray level co-occurrence matrices to generate a total of 463 features. The feature set was split into: training dataset comprising of constrained and movement EEG data and test dataset comprising of only movement EEG data. A retrospective cross-validation approach was run on the training dataset in conjunction with two classifiers (LDA and SVM) and the ranked feature set, to select the best features using a sequential forward selection algorithm. The best features were further used to prospectively classify the three emotions in the test dataset. Our results show that we can successfully classify the emotions using LDA with an accuracy of 89% and using top 17 ranked features.","2168-2208","978-1-5090-2455-1","10.1109/BHI.2016.7455869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7455869","","Electroencephalography;Feature extraction;Face;Training;Correlation;Wireless communication;Emotion recognition","","8","","16","IEEE","21 Apr 2016","","","IEEE","IEEE Conferences"
"Experimental Comparison of Geometric, Arithmetic and Harmonic Means for EEG Event Related Potential Detection","J. M. A. Tanskanen; X. Z. Gao; J. Wang; P. Guo; J. A. K. Hyttinen; V. S. Dimitrov","Department of Biomedical Engineering, Tampere University of Technology, and BioMediTech, Finland; College of Information Engineering, Shanghai Maritime University, China; Laboratory of Image Processing and Pattern Recognition, Beijing Normal University, Beijing, China; Laboratory of Image Processing and Pattern Recognition, Beijing Normal University, Beijing, China; Department of Biomedical Engineering, Tampere University of Technology, and BioMediTech, Finland; ATIPS Laboratory, University of Calgary, AB, Canada",2012 Eighth International Conference on Computational Intelligence and Security,"10 Jan 2013","2012","","","112","116","In this paper, we experimentally evaluate three different averaging methods for processing of electroencephalogram (EEG) event related potentials (ERPs) measured from scalp in response to repeated stimulus. In ERP applications, arithmetic mean (AM) is normally employed in processing the ERPs prior to ERP detection, whereas also other averaging methods might have beneficial properties. Fast ERP detection is essential, for example, in brain computer interfaces and during spine surgery. Thus, it is of interest to search for methods to aid in detecting ERPs with as few stimulus repetitions as possible. Here, noise reduction properties of AM, geometric mean (GM), and harmonic mean (HM) are demonstrated with simulations, and ERP processing by the three methods is illustrated by processing real visual evoked potentials (VEPs).","","978-1-4673-4725-9","10.1109/CIS.2012.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405878","electroencephalogram;EEG;medical signal detection;event related potential;ERP;averaging;ensemble averaging;arithmetic mean;geometric mean;harmonic mean","Electroencephalography;Gaussian noise;Educational institutions;Electrodes;Visualization;Harmonic analysis","","2","","17","IEEE","10 Jan 2013","","","IEEE","IEEE Conferences"
"On the Classification of Emotional Biosignals Evoked While Viewing Affective Pictures: An Integrated Data-Mining-Based Approach for Healthcare Applications","C. A. Frantzidis; C. Bratsas; M. A. Klados; E. Konstantinidis; C. D. Lithari; A. B. Vivas; C. L. Papadelis; E. Kaldoudi; C. Pappas; P. D. Bamidis","Laboratory of Medical Informatics, Medical School, Aristotle University of Thessaloniki, Thessaloniki, Greece; Laboratory of Medical Informatics, Medical School, Aristotle University of Thessaloniki, Thessaloniki, Greece; Laboratory of Medical Informatics, Medical School, Aristotle University of Thessaloniki, Thessaloniki, Greece; Laboratory of Medical Informatics, Medical School, Aristotle University of Thessaloniki, Thessaloniki, Greece; Laboratory of Medical Informatics, Medical School, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Psychology,CITY Liberal Studies Affiliated Institute, University of Sheffield, Thessaloniki, Greece; Center for Mind/Brain Sciences (CIMeC), University of Trento, Trento, Italy; Medical School, Democritus University of Thrace, Alexandroupolis, Greece; Laboratory of Medical Informatics, Medical School, Aristotle University of Thessaloniki, Thessaloniki, Greece; Laboratory of Medical Informatics, Medical School, Aristotle University of Thessaloniki, Thessaloniki, Greece",IEEE Transactions on Information Technology in Biomedicine,"15 Mar 2010","2010","14","2","309","318","Recent neuroscience findings demonstrate the fundamental role of emotion in the maintenance of physical and mental health. In the present study, a novel architecture is proposed for the robust discrimination of emotional physiological signals evoked upon viewing pictures selected from the International Affective Picture System (IAPS). Biosignals are multichannel recordings from both the central and the autonomic nervous systems. Following the bidirectional emotion theory model, IAPS pictures are rated along two dimensions, namely, their valence and arousal. Following this model, biosignals in this paper are initially differentiated according to their valence dimension by means of a data mining approach, which is the C4.5 decision tree algorithm. Then, the valence and the gender information serve as an input to a Mahalanobis distance classifier, which dissects the data into high and low arousing. Results are described in Extensible Markup Language (XML) format, thereby accounting for platform independency, easy interconnectivity, and information exchange. The average recognition (success) rate was 77.68% for the discrimination of four emotional states, differing both in their arousal and valence dimension. It is, therefore, envisaged that the proposed approach holds promise for the efficient discrimination of negative and positive emotions, and it is hereby discussed how future developments may be steered to serve for affective healthcare applications, such as the monitoring of the elderly or chronically ill people.","1558-0032","","10.1109/TITB.2009.2038481","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5373931","Affective computing;data mining;decision tree;EEG;emotion theory;evoked potential response;healthcare remote monitoring;International Affective Picture System (IAPS);Mahalanobis distance","Medical services;XML;Neuroscience;Robustness;Biomedical monitoring;Autonomic nervous system;Data mining;Decision trees;LAN interconnection;Emotion recognition","Adult;Algorithms;Autonomic Nervous System;Central Nervous System;Data Mining;Electroencephalography;Emotions;Evoked Potentials;Female;Galvanic Skin Response;Humans;Male;Monitoring, Physiologic;Pattern Recognition, Automated;Recognition (Psychology);Reproducibility of Results;Signal Processing, Computer-Assisted","126","","40","IEEE","8 Jan 2010","","","IEEE","IEEE Journals"
"Emotive Response to a Hybrid-Face Robot and Translation to Consumer Social Robots","M. Wairagkar; M. R. Lima; D. Bazo; R. Craig; H. Weissbart; A. C. Etoundi; T. Reichenbach; P. Iyengar; S. Vaswani; C. James; P. Barnaghi; C. Melhuish; R. Vaidyanathan","Department of Mechanical Engineering, Dementia Research Institute Care Research and Technology Centre, Imperial College London, London, U.K; Department of Mechanical Engineering, Dementia Research Institute Care Research and Technology Centre, Imperial College London, London, U.K; Department of Media Arts, University of California at Santa Barbara, Santa Barbara, CA, USA; Cyber and Psychology Group, Frazer-Nash Consultancy, Dorking, U.K; Donders Institute, Radboud University, Nijmegen, GL, The Netherlands; Bristol Robotics Laboratory, University of West England/University of Bristol, Bristol, U.K; Department of Artificial Intelligence in Biomedical Engineering, Friedrich-Alexander-University Erlangen–Nürnberg, Erlangen, Germany; Miko, Mumbai, India; Miko, Mumbai, India; Department of Biomedical Engineering, University of Warwick, Coventry, U.K; Department of Brain Sciences, Dementia Research Institute Care Research and Technology Centre, Imperial College London, London, U.K; Bristol Robotics Laboratory, University of West England/University of Bristol, Bristol, U.K; Department of Mechanical Engineering, Dementia Research Institute Care Research and Technology Centre, Imperial College London, London, U.K",IEEE Internet of Things Journal,"21 Feb 2022","2022","9","5","3174","3188","We present the conceptual formulation, design, fabrication, control, and commercial translation of an Internet of Things (IoT)-enabled social robot as mapped through validation of human emotional response to its affective interactions. The robot design centers on a humanoid hybrid face that integrates a rigid faceplate with a digital display to simplify conveyance of complex facial movements while providing the impression of 3-D depth. We map the emotions of the robot to specific facial feature parameters, characterize recognisability of archetypical facial expressions, and introduce pupil dilation as an additional degree of freedom for emotion conveyance. Human interaction experiments demonstrate the ability to effectively convey emotion from the hybrid-robot face to humans. Conveyance is quantified by studying neurophysiological electroencephalography (EEG) response to perceived emotional information as well as through qualitative interviews. The results demonstrate core hybrid-face robotic expressions can be discriminated by humans (80%+recognition) and invoke face-sensitive neurophysiological event-related potentials, such as N170 and vertex positive potentials in EEG. The hybrid-face robot concept has been modified, implemented, and released in the commercial IoT robotic platform Miko (“My Companion”), an affective robot currently in use for human–robot interaction with children. We demonstrate that human EEG responses to Miko emotions are comparative to that of the hybrid-face robot validating design modifications implemented for large-scale distribution. Finally, interviews show above 90% expression recognition rates in our commercial robot. We conclude that simplified hybrid-face abstraction conveys emotions effectively and enhances human–robot interaction.","2327-4662","","10.1109/JIOT.2021.3097592","RN Chidakashi Technologies Pvt Ltd; European Commission(grant numbers:CHRIS FP7-215805); U.K. Dementia Research Institute Care Research and Technology Centre (DRI-CRT)(grant numbers:EP/F01869X/1); U.K. Research and Innovation Global Challenges Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9486848","Affective robot;brain–robot interface;emotional response;event-related potential (ERP);facial expression;human–robot interaction","Robots;Robot sensing systems;Face recognition;Faces;Human-robot interaction;Electroencephalography;Internet of Things","","10","","75","CCBY","15 Jul 2021","","","IEEE","IEEE Journals"
"Brain emotional oscillatory activity during the different affective picture and sound experience","R. Du; H. J. Lee; R. Wei","Smart Health Big Data Analysis and Location Services Engineering Lab of Jiangsu Province Nanjing, China; Center for Advanced Image & Information Technology, Chonbuk National University, Jeonju, Korea; Tianjin Key Laboratory of Optoelectronic Detection Technology and Systems, Tianjin, China","2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","26 Feb 2018","2017","","","1","6","Good mood state is an important indicator of good healthy life, while the bad emotional state could give rise to some social or mental state health issues. To properly manage the psychological and emotional health caused by negative emotions in our daily life, we need to recognize the various emotional states firstly. In order to find out the special cognitive emotional characteristics to reach high emotional identification accuracy, the aim of this paper is to explore the brain emotional oscillatory activity induced by visual and audio stimuli from IAPS and IADS databases in the amplitude measurement. Event related potential (ERP) analysis is used to find out the pronounced emotional characteristics in the emotion recognition. Thirty subjects are employed in the visual and audio experiments. A significance level of p <; 0.01 is combined with ERP to analyze the brain signal data in order to discover significant effects. The results show that, two narrow time ranges (650-750ms and 800-900ms) in the late positive potential (LPP) are come up with five emotional states in the several brain regions for the visual induced emotion state changes. Six narrow time ranges from 0 to 1s of ERP are proposed to study potential various with three emotional states in the several brain regions for the audio induced emotion state changes. The results provide preliminary evidence for narrowing the time range of ERP in the emotion recognition research.","","978-1-5386-1937-7","10.1109/CISP-BMEI.2017.8302298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302298","EEG;Late positive potential (LPP);Human emotion;Event related potential (ERP);IAPS;IADS;ANOVA","Visualization;Electroencephalography;Analysis of variance;Emotion recognition;Brain modeling;Electrodes;Timing","","1","","58","IEEE","26 Feb 2018","","","IEEE","IEEE Conferences"
"Valence-Arousal Disentangled Representation Learning for Emotion Recognition in SSVEP-Based BCIs","Y. Du; J. Chen; Z. Liu; N. Wong; C. Zhang; Z. Ding; J. Liu; E. C. H. Ngai","Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong, China; University of Science and Technology Beijing, Beijing, China; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong, China; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong, China; The First Medical Center, Chinese PLA General Hospital; The Sixth Medical Center, Chinese PLA General Hospital; National Clinical Research Center for Otolaryngologic Diseases; State Key Laboratory of Hearing and Balance Science; ZhanTan Temple Clinic, Beijing Central Medical District, Chinese PLA General Hospital, University of Science and Technology Beijing, Beijing, China; The Sixth Medical Center, Chinese PLA General Hospital; National Clinical Research Center for Otolaryngologic Diseases; State Key Laboratory of Hearing and Balance Science, University of Science and Technology Beijing, Beijing, China; University of Science and Technology Beijing, Beijing, China; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong, China",IEEE Journal of Biomedical and Health Informatics,"","2025","PP","99","1","13","Steady state visually evoked potential (SSVEP)-based brain-computer interfaces (BCIs), which are widely used in rehabilitation and disability assistance, can benefit from real-time emotion recognition to enhance human–machine interaction. However, the learned discriminative latent representations in SSVEP-BCIs may generalize in an unintended direction, which can lead to reduced accuracy in detecting emotional states. In this paper, we introduce a Valence-Arousal Disentangled Representation Learning (VADL) method, drawing inspiration from the classical two-dimensional emotional model, to enhance the performance and generalization of emotion recognition within SSVEP-BCIs. VADL distinctly disentangles the latent variables of valence and arousal information to improve accuracy. It utilizes the structured state space duality model to thoroughly extract global emotional features. Additionally, we propose a Multisubject Gradient Blending training strategy that individually tailors the learning pace of reconstruction and discrimination tasks within VADL on-the-fly. To verify the feasibility of our method, we have developed a comprehensive database comprising 23 subjects, in which both the emotional states and SSVEPs were effectively elicited. Experimental results indicate that VADL surpasses existing state-of-the-art benchmark algorithms.","2168-2208","","10.1109/JBHI.2025.3549727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10918984","Steady state visually evoked potential;emotion recognition;brain-computer interface;disentangled representation learning;gradient blending","Emotion recognition;Brain modeling;Accuracy;Training;Electroencephalography;Deep learning;Feature extraction;Computational modeling;Disentangled representation learning;Mobile robots","","","","","IEEE","11 Mar 2025","","","IEEE","IEEE Early Access Articles"
"Analysis of EEG Signals during Visual Processing: An ERP Study","F. Tenssay; H. Wang","School of Sino-Duch Biomedical and Information, Northeastern University, Shenyang, China; School of Mechanical Engineering and Automation, Northeastern University, Shenyang, China","2019 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","16 Jan 2020","2019","","","1","5","Emotion is a complex, systematic and physiological behavior of the mental state. Brain function is related to perceptual processing of emotional stimuli. The current EEG study evaluated the contextual effect of the positive and negative valence emotional stimuli processing on neural oscillations by examining the neurological activities. EEG data were collected from eighteen individuals based on the international 10-20 system with a sampling rate of 1000Hz. Electrodes from the visual cortex were selected for analysis (O1, Oz and O2). Pre-processing and filtering of the raw data were done with an independent-component analysis (ICA) and time-frequency decomposition functions included in EEGLAB and ERPLAB toolbox. The ERP result confirmed that there is a difference in the reaction time between the negative and positive valences emotional stimuli when participants were experiencing different affective state. Positively valence stimuli react faster than negatively valence emotional stimuli. Three time windows, P2 (125-230ms), EPN (120-200ms) and P3 (300-650ms) were obtained and differences in amplitude and latencies were analyzed. A higher P2 amplitude and a remarkable decrease on P3 amplitude were observed at the visual cortex. The spectral power analysis shows a higher reactivity of alpha band than theta and beta bands. Nonetheless, we found a remarkable decrease in beta power for the given condition. However, beta and theta band showed a spectral change appeared laterally. As enlightened by different scholars, alpha oscillations are associated with the top-down control of visual cortex and play an important role for perception and involved in information processing during periodic cycle of the sensory information.","","978-1-7281-1708-9","10.1109/ICSPCC46631.2019.8960831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8960831","Alpha oscillation;Early Posterior Negativity (EPN);Emotion;Event-related potential (ERP);Visual stimuli","","","4","","15","IEEE","16 Jan 2020","","","IEEE","IEEE Conferences"
"Auditory Event-Related Potential Features as Underwater Target Recognition Assessment","M. Guo; Y. Bai; Z. Xu; S. Han; G. Ni","Department of Biomedical Engineering, College of Precision Instruments and Optoelectronics Engineering, Tianjin University, Tianjin, China; Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, China; Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, China; Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, China; Department of Biomedical Engineering, College of Precision Instruments and Optoelectronics Engineering, Tianjin University, Tianjin, China",2022 16th ICME International Conference on Complex Medical Engineering (CME),"13 Mar 2023","2022","","","362","365","Ocean exploration demands increasing accuracy of underwater target recognition. However, subjective factors like experience or emotion are often not included in the recognition process. Auditory event-related potential (AERP) induced by underwater sound stimuli might reflect objective and subjective factors. Electrophysiological data were analyzed to examine the effects of stimulus type on AERP waveforms, power spectral density, and coherence. In the resultant waveforms, non-target-stimulus evoked negative deflection and forward shift of N1 and P2 components. Furthermore, the target-stimulus evoked P3 component. Different stimuli induced significant differences in the beta and gamma band spectral and connectivity parameters. This study demonstrates that AERP features can be the assessment for underwater acoustic target recognition.","","978-1-6654-9699-5","10.1109/CME55444.2022.10063255","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10063255","auditory event-related potential;underwater target recognition;EEG;beta oscillation;gamma oscillation","Target recognition;Oceans;Coherence;Electroencephalography;Underwater acoustics;Task analysis;Signal analysis","","1","","22","IEEE","13 Mar 2023","","","IEEE","IEEE Conferences"
"Assessment of human response to robot facial expressions through visual evoked potentials","R. Craig; R. Vaidyanathan; C. James; C. Melhuish","Bristol Robotics Laboratory, Department of Mechanical Engineering, University of Bristol, Bristol, UK; Department of Systems Engineering, US Naval Postgraduate School, Monterrey, CA, USA; Digital Medicine Laboratory, University of Warwick, Warwick, UK; Bristol Robotics Laboratory, Department of Mechanical Engineering, University of Bristol, Bristol, UK",2010 10th IEEE-RAS International Conference on Humanoid Robots,"13 Jan 2011","2010","","","647","652","The focus of this work is to investigate and quantify the ability of a humanoid `hybrid face' robot to effectively convey emotion to a human observer by mapping their physiological (EEG) response to perceived emotional information. Specifically, we examine the event related response during two implicit emotion recognition experiments to determine the modulation of the face-specific N170 brain response component to robot facial expressions. EEG recordings were taken from a range of test subjects observing the BERT2 robot cycle through a range of facial emotions in each emotion recognition experiment. Results from both experiments demonstrate that the stimuli evoke the N170 component and that digital facial expressions with high correlations can be discriminated. Emotional expressions evoke a larger response relative to neutral stimuli, with negative evoking an increased amplitude and latency to positive emotions, and demonstrate that the response to robot facial expressions evoke similar brain activity to that of a human emotions. This study is the first of its nature to investigate and quantify the human physiological response to digital facial expressions as conveyed in real-time by a humanoid robot.","2164-0580","978-1-4244-8690-8","10.1109/ICHR.2010.5686272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5686272","","Humans;Face;Electroencephalography;Face recognition;Humanoid robots;Emotion recognition","","7","","27","IEEE","13 Jan 2011","","","IEEE","IEEE Conferences"
"EEG Face Oddball Paradigm as the Test for Emotional Reaction","A. Grankina; E. Pomelova; D. Bredikhin; M. Koriakina; A. N. Shestakova; E. Blagovechtchenski","Centre for Cognition and Decision Making, Institute for Cognitive Neuroscience National Research University Higher School of Economics, Moscow, Russia; Centre for Cognition and Decision Making, Institute for Cognitive Neuroscience National Research University Higher School of Economics, Moscow, Russia; Centre for Cognition and Decision Making, Institute for Cognitive Neuroscience National Research University Higher School of Economics, Moscow, Russia; Centre for Cognition and Decision Making, Institute for Cognitive Neuroscience National Research University Higher School of Economics, Moscow, Russia; Centre for Cognition and Decision Making, Institute for Cognitive Neuroscience National Research University Higher School of Economics, Moscow, Russia; Centre for Cognition and Decision Making, Institute for Cognitive Neuroscience National Research University Higher School of Economics, Moscow, Russia",2024 Sixth International Conference Neurotechnologies and Neurointerfaces (CNN),"9 Oct 2024","2024","","","34","37","One method for assessing human emotional reactions is considered paradigms involving the presentation of affective images, including facial expressions, which are among the most familiar and noticeable stimuli in our visual environment. Electroencephalography event-related potentials (ERP) to various stimuli are used as sensitive tests for determining categorical perception of specific stimulus modalities. The oddball ERP paradigm, presenting angry and happy faces, could be a test for determining a person's emotional reaction. Our results showed that ERP data revealed major response peaks at 120, 212, and 420 ms (measured by global field power), presumably corresponding to P2, N170, and N400 ERP components. All the peaks exhibited differences in the amplitude of responses to the standard and deviant, suggesting variations in the processing of faces with happy and angry expressions. Cluster analysis showed that at the first peak, there was a cluster of 4 occipital electrodes. At the 2nd peak, there were 3 clusters of 2 electrodes (parietal, frontocentral, parietalocentral) and not a single cluster was found at the 3rd peak.","","979-8-3503-9092-6","10.1109/CNN63506.2024.10705866","“Mirror Laboratories” HSE University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10705866","oddball paradigm;emotional reactions;electroencephalography;facial expressions;ERP","Electrodes;Visualization;Sensitivity;Power measurement;Electroencephalography;Emotional responses;Reliability;Faces;Standards;Neurotechnology","","","","25","IEEE","9 Oct 2024","","","IEEE","IEEE Conferences"
"Source activation during facial emotion perception correlates with positive and negative symptoms scores of schizophrenia","D. -W. Kim; S. -H. Lee; C. -H. Im","Department of Biomedical Engineering, Hanyang University, Seoul, South Korea; Department of Psychiatry, Inje University Ilsan Paik Hospital, Goyang, Gyeonggi, South Korea; Department of Biomedical Engineering, Hanyang University, Seoul, South Korea",2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"26 Sep 2013","2013","","","6325","6328","Schizophrenia is one of the most devastating of all mental illnesses, and has dimensional characteristics that include both positive and negative symptoms. One problem reported in schizophrenia patients is that they tend to show deficits in face emotion processing, on which negative symptoms are thought to have stronger influence. In this study, four event-related potential (ERP) components (P100, N170, N250, and P300) and their source activities were analyzed using EEG data acquired from 23 schizophrenia patients while they were presented with facial emotion picture stimuli. Correlations between positive and negative syndrome scale (PANSS) scores and source activations during facial emotion processing were calculated to identify the brain areas affected by symptom scores. Our analysis demonstrates that PANSS positive scores are negatively correlated with major areas of the left temporal lobule for early ERP components (P100, N170) and with the right middle frontal lobule for a later component (N250), which indicates that positive symptoms affect both early face processing and facial emotion processing. On the other hand, PANSS negative scores are negatively correlated with several clustered regions, including the left fusiform gyrus (at P100), most of which are not overlapped with regions showing correlations with PANSS positive scores. Our results suggest that positive and negative symptoms affect independent brain regions during facial emotion processing, which may help to explain the heterogeneous characteristics of schizophrenia.","1558-4615","978-1-4577-0216-7","10.1109/EMBC.2013.6611000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6611000","","Correlation;Barium;Face;Electroencephalography;Electrodes;Psychiatry;Imaging","Adult;Brain Mapping;Electroencephalography;Emotions;Evoked Potentials;Facial Expression;Female;Humans;Male;Middle Aged;Schizophrenia;Visual Perception","1","","14","IEEE","26 Sep 2013","","","IEEE","IEEE Conferences"
"An Affective Brain-Computer Interface Based on a Transfer Learning Method","W. Huang; Z. Guan; K. Li; Y. Zhou; Y. Li","Research Center for Brain-Computer Interface, Pazhou Lab, Guangzhou, China; Research Center for Brain-Computer Interface, Pazhou Lab, Guangzhou, China; Research Center for Brain-Computer Interface, Pazhou Lab, Guangzhou, China; Research Center for Brain-Computer Interface, Pazhou Lab, Guangzhou, China; Research Center for Brain-Computer Interface, Pazhou Lab, Guangzhou, China",IEEE Transactions on Affective Computing,"5 Sep 2024","2024","15","3","929","941","An affective brain-computer interface (aBCI) can detect affective states based on brain signals and might assist people in improving their emotion regulation abilities. However, individual differences in emotional brain patterns make cross-subject emotion identification extremely challenging. Traditional supervised single-subject classification schemes require considerable calibration samples from new individuals to train subject-dependent models. Individuals are easily fatigued with long-term EEG collection processes, which may affect performance in subsequent online experiments. In this study, we propose a real-time aBCI system using domain-fusion-based multisource style transfer mapping (DF-MS-STM) to detect positive, neutral, and negative emotional states without the need for additional training sessions. Sixteen subjects participated in our online experiments to test the performance of our aBCI system and an average online prediction accuracy of 72.17±12.25% was obtained for three-class emotion recognition tasks in the last three experimental sessions. Our proposed algorithm significantly outperformed numerous baseline methods in terms of cross-subject emotion classification. In addition, we identified distinct brain patterns in response to different emotional stimuli based on the results of event-related spectral perturbation (ERSP) analyses. These neural patterns might provide new insights for emotional brain mechanistic studies and related aBCIs.","1949-3045","","10.1109/TAFFC.2023.3305982","STI 2030–Major Projects(grant numbers:2022ZD0208900); Key Realm R&D Program of Guangzhou, China(grant numbers:202007030007); Key R&D Program of Guangdong Province, China(grant numbers:2018B030339001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10223292","Affective brain-computer interface (aBCI);electroencephalogram (EEG);emotion recognition;transfer learning;neural pattern","Electroencephalography;Emotion recognition;Brain modeling;Real-time systems;Transfer learning;Task analysis;Calibration","","4","","52","CCBYNCND","17 Aug 2023","","","IEEE","IEEE Journals"
"Prediction of Scalp EEG Waveforms from Forehead Electrodes Using Convolutional Neural Networks to Improve Signal-to-Noise Ratio","K. Yamawaki; H. Watanabe; Y. Naruse","Center for Information and Neural Networks (CiNet), National Institute of Information and Communications Technology, Osaka University, Kobe, Japan; Center for Information and Neural Networks (CiNet), National Institute of Information and Communications Technology, Osaka University, Kobe, Japan; Center for Information and Neural Networks (CiNet), National Institute of Information and Communications Technology, Osaka University, Kobe, Japan","2022 IEEE International Conference on Metrology for Extended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)","5 Dec 2022","2022","","","382","387","The electroencephalogram (EEG) is a non-invasive method for measuring brain activity, and event-related potentials (ERPs)—EEG responses observed to be time-locked to events—have been used for brain-computer interfaces (BCI) in real-world environments. An EEG is generally measured from electrodes placed on the scalp. However, it is not suitable for daily use because the preparation time is relatively long, and the electrodes are likely to cause discomfort to the user. EEG measurements from disposable electrodes placed on the forehead (forehead EEG) have been used to mitigate this disadvantage. However, because many ERP components used in BCI show the maximal voltage on the scalp, the signal-to-noise ratio (SNR) of ERPs obtained from a forehead EEG is low, which may affect the reliability of a BCI system. To address this shortcoming, we propose convolutional neural networks that predict the EEG signal measured from electrodes placed on the scalp (scalp EEG) from forehead EEG. In the study, we focused on predicting the mismatch negativity (MMN) responses, and single-trial scalp EEG at Fz was predicted from three forehead EEG measures (Fpz, horizontal, and vertical electrooculograms). Data were measured while nine subjects performed a passive auditory oddball task. To evaluate the proposed model, the mean squared error (MSE) between the observed single-trial EEG at Fz and the predicted single-trial EEG from three forehead EEG measures was calculated, as well as the MSE between the observed ERP difference wave (deviant – standard) at Fz and the difference wave predicted from three forehead EEG measures within the time window in which MMN was observed. The result showed that within the time window in which MMN was observed, the MSE between the ERP difference wave at Fz and the ERP difference wave predicted from three forehead EEG measures was significantly smaller than the MSE between the ERP difference wave at Fz and the ERP difference wave at the forehead (Fpz). This indicates that the proposed neural network improved the SNR of the forehead EEG for predicting ERP responses at the scalp and could lead to enhancing the usefulness of forehead EEG for BCI use in daily life.","","978-1-6654-8574-6","10.1109/MetroXRAINE54828.2022.9967638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9967638","electroencephalogram (EEG);convolutional neural networks;forehead EEG;mismatch negativity (MMN);event-related potential (ERP)","Electrodes;Electric potential;Forehead;Scalp;Measurement uncertainty;Electroencephalography;Time measurement","","","","17","IEEE","5 Dec 2022","","","IEEE","IEEE Conferences"
"Single-trial ERP classification of emotional processing","N. G. Mathieu; S. Bonnet; S. Harquel; E. Gentaz; A. Campagne","LPNC CNRS, Grenoble, (FRANCE); CEA Leti, MINATEC Campus DTBS, Grenoble, (FRANCE); CNRS, Grenoble, (FRANCE); LPNC CNRS, Grenoble, (FRANCE); LPNC CNRS, Grenoble, (FRANCE)",2013 6th International IEEE/EMBS Conference on Neural Engineering (NER),"2 Jan 2014","2013","","","101","104","This paper investigates human emotion recognition based on event-related potentials (ERPs) in EEG elicited by picture presentation. Emotion is manipulated through arousal and valence with a calibrated picture dataset. A classification framework is designed for single-trial ERP classification. The most discriminative spatio-temporal features of emotional states were selected and fed to a shrinkage linear discriminant classifier. Various binary classifications were tested according to the emotional valence (positive, negative, neutral) and the arousal level (low, high and no excitation). High classification rate (87%) was obtained for the discrimination between the high-arousal (HA) and low-arousal (LA) negative conditions. Relative good performances were also observed for the (extreme) case “HA negative versus neutral conditions” (66%). Our results suggest that the discrimination of emotional states is better when it is mainly based on an arousal difference between stimuli rather than on a valence difference.","1948-3554","978-1-4673-1969-0","10.1109/NER.2013.6695881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6695881","","Electroencephalography;Sensors;Emotion recognition;Electrodes;Spatial filters;Classification algorithms;Brain-computer interfaces","","5","","14","IEEE","2 Jan 2014","","","IEEE","IEEE Conferences"
"How Linguistic and Nonlinguistic Vocalizations Shape the Perception of Emotional Faces—An Electroencephalography Study","J. Liang; M. Zhang; L. Yang; Y. Li; Y. Li; L. Wang; H. Li; J. Chen; W. Luo",South China Normal University; Liaoning Normal University; South China Normal University; Liaoning Normal University; Liaoning Normal University; South China Normal University; Nanzhi Senior High School; South China Normal University; Liaoning Normal University,Journal of Cognitive Neuroscience,"25 Apr 2025","2025","37","5","970","987","Vocal emotions are crucial in guiding visual attention toward emotionally significant environmental events, such as recognizing emotional faces. This study employed continuous EEG recordings to examine the impact of linguistic and nonlinguistic vocalizations on facial emotion processing. Participants completed a facial emotion discrimination task while viewing fearful, happy, and neutral faces. The behavioral and ERP results indicated that fearful nonlinguistic vocalizations accelerated the recognition of fearful faces and elicited a larger P1 amplitude, whereas happy linguistic vocalizations accelerated the recognition of happy faces and similarly induced a greater P1 amplitude. In recognition of fearful faces, a greater N170 component was observed in the right hemisphere when the emotional category of the priming vocalization was consistent with the face stimulus. In contrast, this effect occurred in the left hemisphere while recognizing happy faces. Representational similarity analysis revealed that the temporoparietal regions automatically differentiate between linguistic and nonlinguistic vocalizations early in face processing. In conclusion, these findings enhance our understanding of the interplay between vocalization types and facial emotion recognition, highlighting the importance of cross-modal processing in emotional perception.","0898-929X","","10.1162/jocn_a_02284","National Natural Science Foundation of China(grant numbers:31871106); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10976613","","","","","","","","25 Apr 2025","","","MIT Press","MIT Press Journals"
"Classification of emotions based on ERP feature extraction","M. Goyal; M. Singh; M. Singh","EIED, Thapar University, Patiala, India; EIED, Thapar University, Patiala, India; EIED, Thapar University, Patiala, India",2015 1st International Conference on Next Generation Computing Technologies (NGCT),"11 Jan 2016","2015","","","660","662","Emotions are the feelings that represent the personality of any individual. Thus predicting emotions become necessary to understand the behavior of humans. Emotions can be predicted from gestures, sound processing but emotion recognition using EEG signals is very powerful method to know the internal state of mind accurately. This paper describes the acquisition of EEG signals on frontal electrodes such as F3, F4 and FZ from five subjects for classification of emotions into two classes. The emotions were induced by showing images from International Affective Picture System (IAPS) dataset to the subjects. The event related potential (ERP) features were determined from the processed EEG signals for every class of emotions. The classification was performed using LIBSVM classifier with 3 fold cross validation and RBF kernel to classify emotions into two classes along the arousal axis. It was found that accuracy remained consistently high on F4 electrode. An accuracy of 79.16% was obtained on F4 electrode, 76.19% on F3 electrode and 73.07% on FZ electrode when classifying emotions subject wise.","","978-1-4673-6809-4","10.1109/NGCT.2015.7375203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7375203","EEG;Emotions;Event realted potential(ERP) Library for Support vector machines(LIBSVM)","Electroencephalography;Electrodes;Emotion recognition;Biomedical imaging;MATLAB;Libraries","","8","","15","IEEE","11 Jan 2016","","","IEEE","IEEE Conferences"
"Siam-GCAN: A Siamese Graph Convolutional Attention Network for EEG Emotion Recognition","H. Zeng; Q. Wu; Y. Jin; H. Zheng; M. Li; Y. Zhao; H. Hu; W. Kong","School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China",IEEE Transactions on Instrumentation and Measurement,"14 Nov 2022","2022","71","","1","9","The graph convolutional network (GCN) shows effective performance in electroencephalogram (EEG) emotion recognition owing to the ability to capture brain connectivity. However, the depth information cannot be extracted only through the GCN structure, and the learning process of the GCN model ignores the intraclass and the interclass information. Regarding the above problems, we propose a Siamese graph convolutional attention network, named Siam-GCAN, which mainly considers the following two aspects: on the one hand, we use a deep attention layer implemented by a multihead attention mechanism to abstract deeper and valuable features rather than stacking graph convolution layers. On the other hand, we employ the Siamese network to cluster the outputs of GCNs based on Euclidean distance to ensure the learned information has a certain class separability. Experimental results on two public emotional datasets, the Shanghai Jiao Tong University (SJTU) emotion EEG dataset and the SJTU emotion EEG dataset-IV, demonstrate that Siam-GCAN outperforms the state-of-the-art baselines in EEG emotion recognition.","1557-9662","","10.1109/TIM.2022.3216829","National Key Research and Development Program of China(grant numbers:2017YFE0116800); National Natural Science Foundation of China(grant numbers:U20B2074,U1909202); NSFC(grant numbers:62076083); National International Joint Research Center for Brain-Machine Collaborative Intelligence(grant numbers:2017B01020); Key Laboratory of Brain Machine Collaborative Intelligence of Zhejiang Province(grant numbers:2020E10010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931735","Attention mechanism;electroencephalogram (EEG);emotion recognition;graph convolutional network (GCN);Siamese network","Convolution;Electroencephalography;Emotion recognition;Network architecture;Feature extraction;Brain modeling;Frequency-domain analysis","","25","","48","IEEE","28 Oct 2022","","","IEEE","IEEE Journals"
"Brain Computer Interface based EEG for Emotion Recognition System: A Systematic Review","P. R. Bhise; S. B. Kulkarni; T. A. Aldhaheri","Department of Computer Science and Information Technology, Dr.Babasaheb Ambedkar Marathwada University, Aurangabad, Maharashtra, India; Department of Computer Science and Information Technology, Dr.Babasaheb Ambedkar Marathwada University, Aurangabad, Maharashtra, India; Department of Computer Science and Information Technology, Dr.Babasaheb Ambedkar Marathwada University, Aurangabad, Maharashtra, India",2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA),"23 Apr 2020","2020","","","327","334","Currently the Brain-Compute Interface (BCI) is an outstanding research area where the goal is to create an interaction channel between system and person brain. It provides direct way to transform brainwaves into physical effects without using muscles. It presents an auspicious technology which granting individuals to deal with extraneous instruments through managing their brain signals. In this technology the noninvasive BCI technique that is electroencephalography plays a vital role for acquisition of brain signals and developing Emotion Recognition System. The Emotions are very important in our life for interaction, decision handling and cognitive process. This paper contains types of BCI system, it also explored to neuro imaging techniques for acquisition of brain signals, basic functioning of brain and comprehensive survey on EEG-Based BCI system for human emotion recognition. Various classification techniques are available for emotion classifications but among these support vector machine classification techniques is most preferred by the various researchers for analyzing the emotions.","","978-1-7281-4167-1","10.1109/ICIMIA48430.2020.9074921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074921","Brain computer interface;EEG (Electro Encephalogram);emotion;ERP;ERD","Electroencephalography;Feature extraction;Support vector machines;Imaging;Brain modeling;Brain-computer interfaces","","19","","46","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Neural Mechanisms of Social Emotion Perception: An EEG Hyper-Scanning Study","L. Zhu; F. Lotte; G. Cui; J. Li; C. Zhou; A. Cichocki","Cognitive Science Department, Xiamen University, Xiamen, China; Inria/LaBRI, (CNRS, univ Bordeaux, Bordeaux INP), Bordeaux, France; Electronics Engineering Department, Saitama Institute of Technology, Fukaya, Japan; Singapore Institute for Neurotechnology (SINAPSE), National University of Singapore, Singapore, Singapore; Cognitive Science Department, Xiamen University, Xiamen, China; Department of Informatics, Nicolaus Copernicus University, Torun, Poland",2018 International Conference on Cyberworlds (CW),"27 Dec 2018","2018","","","199","206","EEG-based hyper-scanning refers to two or more subjects engaged in a task together or performing the same action together while neurophysiological signals are simultaneously recorded from them. This is one of the manners for investigating between-subject neural activities involved in social interactions. Emotion perception plays an important role in human social interactions. Interaction and emotional state influence each other. In this study, we aim to investigate how between-subject interaction modulates emotion perception based on event related potentials (ERPs), connectivity analysis and classification analysis. We found that there are distinct differences appearing between paired subjects who performed the task together, which are early ERP components (N250 and N400), late ERP components (P1500 and N1500), and the greater amplitude in N250 for the seconding responding subject compared to the first one. In the exploration of connectivity using phase locking value (PLV), we found that there are significant differences among different frequency bands for each subject under positive and negative stimuli and the significant difference of hyper-connectivity existed in the gamma frequency band between positive and negative stimulus trials. In the classification analysis, we compared the hyper-features for two individual subjects separately, the performance was improved when hyper-features of the PLV was employed compared to the features of power spectrum density.","","978-1-5386-7315-7","10.1109/CW.2018.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590040","Social emotion;Hyper scanning;Hyper connectivity;Classification","Electroencephalography;Synchronization;Task analysis;Brain;Support vector machines;Videos;Cognitive science","","8","","46","IEEE","27 Dec 2018","","","IEEE","IEEE Conferences"
"Comparison of Different Methods for Emotion Classification","M. Molavi; J. b. Yunus; E. Akbari","Faculty of Health Science and Biomedical Engineering, University TeknologiMalaysia, Johor, Malaysia; Faculty of Health Science and Biomedical Engineering, University Teknology Malaysia, Johor, Malaysia; Faculty of Health Science and Biomedical Engineering, University Teknologi Malaysia, Johor, Malaysia",2012 Sixth Asia Modelling Symposium,"19 Jul 2012","2012","","","50","53","This article proposed emotional features clustering from electroencephalographic (EEG) signals. Facial expression images induce emotional states, which include happy, neutral and sad faces. This paper examined the effect of expression facial stimuli on event-related potential (ERPs). Moreover, It also investigated the frequency band searching by comparison between two methods; the linear support vector machine (LSVM) and the Naive Bayes classifier method. Feature extraction was performed by common spatial patterns (CSP) to reduce the dimensions of data in the frequency domain. The results showed that both methods have an ability to classify the emotional features. LSVM had more accuracy than Naive Bayes classifier. Furthermore , the gamma band was the suitable frequency interval to detect arousal emotions. Nevertheless, the happy versus sad emotional features wereclassified with higher accuracy.","2376-1172","978-1-4673-1957-7","10.1109/AMS.2012.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6243920","common spatial patterns;linear support vector machine;Naive Bayes classifier;emotion","Electroencephalography;Accuracy;Support vector machines;Training;Educational institutions;Emotion recognition;Electrodes","","5","","19","IEEE","19 Jul 2012","","","IEEE","IEEE Conferences"
"A Hybrid Brain–Computer Interface Combining P300 Potentials and Emotion Patterns for Detecting Awareness in Patients With Disorders of Consciousness","J. Pan; L. Wang; H. Huang; J. Xiao; F. Wang; Q. Liang; C. Xu; Y. Li; Q. Xie","School of Software, South China Normal University, Foshan, China; School of Software, South China Normal University, Foshan, China; School of Software, South China Normal University, Foshan, China; School of Automation Science and Engineering, South China University of Technology, Guangzhou, China; School of Software, South China Normal University, Foshan, China; Zhujiang Hospital, Southern Medical University, Guangzhou, China; Zhujiang Hospital, Southern Medical University, Guangzhou, China; School of Automation Science and Engineering, South China University of Technology, Guangzhou, China; Zhujiang Hospital, Southern Medical University, Guangzhou, China",IEEE Transactions on Cognitive and Developmental Systems,"7 Sep 2023","2023","15","3","1386","1395","In this study, a hybrid brain–computer interface (BCI) system combining P300 potential and emotion patterns was proposed to improve the performance of awareness detection. Two video clips were flashed randomly to evoke the P300 potential, while a laughing or crying video clip was used to induce the corresponding emotion pattern. The subjects were asked to concentrate on the laughing or crying video clip cued by the instruction and to count the flashes of the corresponding video clip. Two layers of classification were developed. In the first layer, P300 detection and emotion recognition were performed separately using two support vector machine (SVM) classifiers. Specifically, the activation, spatial, and connection patterns were fused in emotion recognition. In the second layer, the SVM scores of P300 detection and emotion recognition were fed into another SVM classifier to determine which video clip the subjects responded to. Six healthy subjects and eight patients with disorders of consciousness (DOC) were involved in the command-following experiment. The results showed that the accuracy of the hybrid BCI system was better than those of the single-modality systems. Furthermore, three patients were able to perform tasks (66%–72%) using our hybrid BCI, which indicated their residual awareness and emotion-related abilities.","2379-8939","","10.1109/TCDS.2022.3213194","Science and Technology Innovation 2030—“Brain Science and Brain-Like Intelligence Technology” Key Project(grant numbers:2022ZD0208900); National Natural Science Foundation of China(grant numbers:62076103); Guangzhou Science and Technology Plan Project Key Field Research and Development Project(grant numbers:202007030005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9914570","Awareness detection;brain–computer interface (BCI);disorders of consciousness (DOC);emotion pattern;P300","Emotion recognition;Support vector machines;Electroencephalography;Behavioral sciences;Visualization;Graphical user interfaces;Electric potential","","7","","31","IEEE","10 Oct 2022","","","IEEE","IEEE Journals"
"A Review of Non Invasive Methods of Brain Activity Measurements via EEG Signals Analysis","T. Dabbabi; L. Bouafif; A. Cherif","Science Faculty of Tunis, ATSSEE, Tunis, Tunisia; High Institute of Technologies Studies, ISTMT, Av. Zouheir Essafi, Tunis, Tunisia; Science Faculty of Tunis, Tunis, Tunisia",2023 IEEE International Conference on Advanced Systems and Emergent Technologies (IC_ASET),"20 Jun 2023","2023","","","01","06","In neuroscience, electroencephalography (EEG) is a non-invasive method of measuring and monitoring the brain electrical activity by recording the potentials of electrodes placed at standard positions on the scalp. The EEG has become an essential tool for diagnosing and monitoring neurological, cognitive, emotional and even psychological disorders (epilepsy, anesthesia, …). In this paper, we will present an overview of the several methods used for the analysis of EEG signals such as spectral analysis, techniques based on the response to electrical, acoustic or mechanical stimulation, such AEP (Acoustic Evoked Potential) and ERP (Event Related Potential) without forgetting the methods of separation based on independent components analysis (ICA) to identify the different cerebral sources and eliminate the artifacts. Finally, we give an overview on machine learning and artificial intelligence techniques applied to the analysis of EEG signals and Brain computer interface (BCI). To illustrate the results of the EEG analysis, we will present an example of simulation applied to real samples.","","979-8-3503-2102-9","10.1109/IC_ASET58101.2023.10150607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150607","Cerebral activity;electroencephalography (EEG);event-related potential (ERP);Independent Component Analysis (ICA);DL and CNN classification","Neurological diseases;Electric potential;Electroencephalography;Brain-computer interfaces;Acoustics;Timing;Data mining","","3","","21","IEEE","20 Jun 2023","","","IEEE","IEEE Conferences"
"SSVEP-Based Emotion Recognition for IoT via Multiobjective Neural Architecture Search","Y. Du; J. Liu; X. Wang; P. Wang","School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; Information Construction and Management Office, University of Science and Technology Beijing, Beijing, China; Research and Development Department, Beijing Electronic Wise Medical Science and Technology Company Ltd., Beijing, China",IEEE Internet of Things Journal,"21 Oct 2022","2022","9","21","21432","21443","Emotion recognition is one of the significant research areas and applications of electroencephalography (EEG)-based brain–computer interface (BCI), which is widely concerned in the Internet of Things (IoT) framework. Steady-state visual evoked potential (SSVEP) is frequently used in EEG-based BCI (EEG-BCI) due to its high signal-to-noise ratio and short response time. However, there are few related studies and applications on the emotional features of SSVEP. In this article, we build an SSVEP-based BCI (SSVEP-BCI) for affective computing in the IoT system and utilize neural architecture search (NAS) to analyze the emotional information of SSVEP signals. Our proposed NAS is capable of optimizing the classification performance and model size of the deep neural networks simultaneously, thus enhancing the sentiment analysis accuracy for SSVEP and improving the response speed of the actual BCI system for IoT implementation. Furthermore, we employ network morphism and Bayesian optimization in the offspring generation algorithm of the NAS framework to apply knowledge inheritance and performance estimation for the child models, respectively. The experimental results show that the proposed NAS outperforms the baseline models in terms of accuracy and model size for valence and arousal dimensions. Moreover, the offspring generation algorithm is able to promote the search efficiency of NAS.","2327-4662","","10.1109/JIOT.2022.3180215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793561","Brain–computer interface (BCI);emotion recognition;Internet of Things (IoT);neural architecture search (NAS);steady-state visual evoked potential (SSVEP)","Electroencephalography;Brain modeling;Emotion recognition;Feature extraction;Deep learning;Internet of Things;Hidden Markov models","","13","","73","IEEE","10 Jun 2022","","","IEEE","IEEE Journals"
"Emotional responses as independent components in EEG","C. B. Falk Jensen; Michael Kai Petersen; Jakob Eg Larsen","Cognitive Systems, Technical University of Denmark, Kgs. Lyngby; Cognitive Systems, Technical University of Denmark, Kgs. Lyngby; Cognitive Systems, Technical University of Denmark, Kgs. Lyngby",2014 4th International Workshop on Cognitive Information Processing (CIP),"26 Jun 2014","2014","","","1","6","With neuroimaging studies showing promising results for discrimination of affective responses, the perspectives of applying these to create more personalised interfaces that adapt to our preferences in real-time seems within reach. Additionally the emergence of wireless electroencephalograph (EEG) neuroheadsets and smartphone brainscanners widens the possibilities for this to be used in mobile settings on a consumer level. However the neural signatures of emotional responses are characterized by small voltage changes that would be highly susceptible to noise if captured in a mobile context. Hypothesizing that retrieval of emotional responses in mobile usage scenarios could be enhanced through spatial filtering, we compare a standard EEG electrode-based analysis against an approach based on independent component analysis (ICA). By clustering scalp maps and time series responses we identify neural signatures that are differentially modulated when passively viewing neutral, pleasant and unpleasant images. While early responses can be detected from the raw EEG signal, we identify multiple early and late ICA components that are modulated by emotional content. We propose that similar approaches to spatial filtering might allow us to retrieve more robust signals in real-life mobile usage scenarios, and potentially facilitate design of cognitive interfaces that adapt the selection of media to our emotional responses.","2327-1698","978-1-4799-3696-0","10.1109/CIP.2014.6844509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6844509","EEG;ICA;Affective Computing;Affective Response","Electroencephalography;Scalp;Principal component analysis;Mobile communication;Electrodes;Standards;Time series analysis","","","","24","IEEE","26 Jun 2014","","","IEEE","IEEE Conferences"
"Emotional Influence on SSVEP Based BCI","Y. Zhu; X. Tian; G. Wu; G. Gasso; S. Wang; S. Canu","School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; INSA de Rouen, Laboratoire LITIS EA 4108, Rouen, France; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; INSA de Rouen, Laboratoire LITIS EA 4108, Rouen, France; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; INSA de Rouen, Laboratoire LITIS EA 4108, Rouen, France",2013 Humaine Association Conference on Affective Computing and Intelligent Interaction,"12 Dec 2013","2013","","","859","864","The objective of the paper is to investigate the effect of subject's emotional states on Brain Computer Interface (BCI) performance. Two psycho-physiological experiments are designed and implemented. The first one induces subjects' emotion using video clips first, then involves subjects' in SSVEP task. The second one induces subjects' emotions and SSVEP simultaneously by flickering IAPS pictures in four directions. used to recognize the performed BCI tasks. Based on the performances of learned classifiers, we analyzed the influence of emotion using two statistical tests. The McNamara's test serves to assess if emotion has any influences on mental task performing while Wilcox on signed-rank test analyses if emotion has a positive or detrimental effect on ability to achieve a SSVEP task. Obtained results suggest influence of emotional states: the positive and neutral emotions influence BCI performance similarly, while the negative emotion tends to deteriorate classification accuracy.","2156-8111","978-0-7695-5048-0","10.1109/ACII.2013.161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681553","emotinal BCI;SSVEP;McNemar's test;Wilcoxon test","Feature extraction;Electroencephalography;Accuracy;Support vector machines;Electric potential;Analysis of variance;Emotion recognition","","4","","14","IEEE","12 Dec 2013","","","IEEE","IEEE Conferences"
"Application of EEG to Service Value Perception","M. Zhao; N. Ding; J. Wang; G. Zhao","School of Economy and Business Administration, Heilongjiang University, Harbin, China; School of Economics and Management, Beihang University, Beijing, China; School of Economics and Management, Beihang University, Beijing, China; School of Mechanical Engineering and Automation, Beihang University, Beijing, China",2019 16th International Conference on Service Systems and Service Management (ICSSSM),"31 Oct 2019","2019","","","1","4","The research of neuroscience in service management was presented in the doctoral dissertation of Zhao during her study in Beihang University. A number of researches around service science were indicated by the application of EEG experiment, for instance, the value structure of product service system, service value perception, the influence factors of online service purchase decision-making, consumer's cognitive and service purchase decisions, particularly the relationship between product and services in PSS. Event related potential (ERP) is a neuroscience method with the application of the change of EEG recorded by customers' reactions to a particular stimulus. The external stimuli through visual, auditory and other senses may induce relevant potentials and presented in the form of brain waves. Many functions and inducing conditions of ERP have been confirmed in psychological experiments, such as P300, P2, N270, N170, EPN, LPP, which has been currently applied in the research on consumer decision-making, service science and management.","2161-1904","978-1-7281-1941-0","10.1109/ICSSSM.2019.8887660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887660","neuromarketing;event related potential;decision-making;service value","Electroencephalography;Neuroscience;Psychology;Decision making;Cognition;Visualization;Electric potential","","","","17","IEEE","31 Oct 2019","","","IEEE","IEEE Conferences"
"Evaluation of feature extraction techniques in emotional state recognition","T. F. Bastos-Filho; A. Ferreira; A. C. Atencio; S. Arjunan; D. Kumar","Federal University of Espírito Santo, Vitoria, Espirito Santo, Brazil; Federal University of Espírito Santo, Vitoria, Espirito Santo, Brazil; Federal University of Espírito Santo, Vitoria, Espirito Santo, Brazil; RMIT University, Melbourne, Australia; RMIT University, Melbourne, Australia",2012 4th International Conference on Intelligent Human Computer Interaction (IHCI),"21 Mar 2013","2012","","","1","6","We present in this paper a study of three EEG signals feature extraction techniques. These techniques have been widely employed in researches of emotional states recognition: statistical characteristics, features based on PSD (Power Spectral Density) and features based on HOC (High Order Crossings). The validation was performed via classification of emotional states of calm and stress using the K-NN based classifier in off-line mode using EEG signals from available DEAP database. The best results achieved were 70.1%, using the PSD based technique, and 69.59% using the HOC based technique.","","978-1-4673-4369-5","10.1109/IHCI.2012.6481860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6481860","","Electroencephalography;Stress;Feature extraction;Emotion recognition;Databases;Vectors;Brain modeling","","53","","28","IEEE","21 Mar 2013","","","IEEE","IEEE Conferences"
"Trait empathy modulates brain response to empathy for social rejection: Evidence from electrophysiology","D. Tao; Y. Leng; S. Ge; H. Deng","Medical Engineering & Key Laboratory of Child Development and Learning Science, Ministry of Education, School of Biological Science, Southeast University, Nanjing, China; Medical Engineering & Key Laboratory of Child Development and Learning Science, Ministry of Education, School of Biological Science, Southeast University, Nanjing, China; Medical Engineering & Key Laboratory of Child Development and Learning Science, Ministry of Education, School of Biological Science, Southeast University, Nanjing, China; Medical Engineering & Key Laboratory of Child Development and Learning Science, Ministry of Education, School of Biological Science, Southeast University, Nanjing, China",2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"27 Aug 2020","2020","","","1027","1030","Empathy which can understand and respond to the unique affective experiences of others plays an essential role in social interaction. Although many neuroimaging studies have investigated the neural mechanisms underlying empathy for social pain, how its mechanisms are modulated by trait empathy remains unknown. The present event-related potential (ERP) study used Chatroom Interact Task to examine how trait empathy modulates brain response to empathy for social rejection. The behavior results showed that participants were less pleasant when observing rejection compared to observing acceptance in both high- and low-levels empathy groups. The ERP results revealed more negative-going N2 for social acceptance compared to rejection in both groups, but there was no difference in N2 between high- and low- empathy group. However, the late components, i.e., the P3b, N400 and LPP, revealed significant difference between social acceptance and rejection in high empathic participants rather than low empathic participants. These findings suggested that individuals with high empathic traits could devote more attention and mental resources to process observing ostracism.","2694-0604","978-1-7281-1990-8","10.1109/EMBC44109.2020.9175611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175611","","Pain;Task analysis;Electroencephalography;Brain;Electrodes;Analysis of variance;Artificial intelligence","Brain;Electroencephalography;Empathy;Evoked Potentials;Female;Humans;Male;Social Distance","","","22","CCBY","27 Aug 2020","","","IEEE","IEEE Conferences"
"Electroencephalogram and Electrocardiogram in Human-Computer Interaction","P. Li; Y. Qian; N. Si","School of Electronic and Information Engineering,Beihang University, Beijing, China; School of Control Engineering, Northeastern University, Qinhuangdao, Hebei, China; Faculty of Electrical Engineering, Queen's University, Kingston, Ontario, Canada",2022 IEEE 2nd International Conference on Data Science and Computer Application (ICDSCA),"29 Dec 2022","2022","","","646","654","Electroencephalogram (EEG) and Electrocardiogram (ECG) have been widely used in clinical diagnosis and have shown their potential in Human-Computer Interaction (HCI). EEG and ECG contain signals that can directly reveal people's activity neurologically and decode and transfer for further physical monitoring and external control. This paper firstly summarizes heavily used methods of EEG signal process in HCI, which also applies to the ECG process. Then, we reviewed typical applications for EEG in HCI, including the TTD system, P300, and Graz for brain-computer interface and emotion recognition. We conclude ECG classification and acquisition methods and ECG application in HCI, including biometric identification, game input, and medical nursing. Finally, integrating EEG and ECG, there are HCI applications like accurate emotion recognition, physiological monitoring, disease diagnosis, and portable wearable device. In addition, we present the HCI application for Electromyogram (EMG) in gesture, handwriting recognition, and Electrooculogram (EOG) in password security, cursor system, and eye-writing.","","978-1-6654-7200-5","10.1109/ICDSCA56264.2022.9988056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9988056","EEG;ECG;HCI;EMG;EOG","Human computer interaction;Emotion recognition;Electric potential;Video games;Wearable computers;Electrocardiography;Electroencephalography","","","","50","IEEE","29 Dec 2022","","","IEEE","IEEE Conferences"
"Age Effect in Human Brain Responses to Emotion Arousing Images: The EEG 3D-Vector Field Tomography Modeling Approach","C. D. Papadaniil; V. E. Kosmidou; A. C. Tsolaki; L. J. Hadjileontiadis; M. Tsolaki; I. Yiannis Kompatsiaris","Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, GR, Greece; Information Technologies Institute, Centre for Research & Technology Hellas, Thessaloniki, GR, Greece; Medical Physics Laboratory, Medical School, Aristotle University of Thessaloniki, Thessaloniki, GR, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, GR, Greece; 3rd Department of Neurology, Aristotle University of Thessaloniki, Thessaloniki, GR, Greece; Information Technologies Institute, Centre for Research & Technology Hellas, Thessaloniki, GR, Greece",IEEE Transactions on Autonomous Mental Development,"19 May 2017","2015","7","3","223","235","Understanding of the brain responses to emotional stimulation remains a great challenge. Studies on the aging effect in neural activation report controversial results. In this paper, pictures of two classes of facial affect, i.e., anger and fear, were presented to young and elderly participants. High-density 256-channel EEG data were recorded and an innovative methodology was used to map the activated brain state at the N170 event-related potential component. The methodology, namely 3D Vector Field Tomography, reconstructs the electrostatic field within the head volume and requires no prior modeling of the individual's brain. Results showed that the elderly exhibited greater N170 amplitudes, while age-based differences were also observed in the topographic distribution of the EEG recordings at the N170 component. The brain activation analysis was performed by adopting a set of regions of interest. Results on the maximum activation area appeared to be emotion-specific; the anger emotional conditions induced the maximum activation in the inferior frontal gyrus, while fear activated more the superior temporal gyrus. The approach used here shows the potential of the proposed computational model to reveal the age effect on the brain activation upon emotion arousing images, which could be further transferred to the design of assistive clinical applications.","1943-0612","","10.1109/TAMD.2015.2416977","GSRT Research Excellent Grant ARISTEIA within the 4th Strategic Objective of the operational programme Education and Lifelong Learning entitled Supporting the Human Capital in order to Promote Research and Innovation under grant agreement 440 project CBP Cognitive Brain signal Processing lab coordinated by the Information Technologies Institute Centre for Research and Technology Hellas.(grant numbers:440); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072510","Age effect;brain imaging;emotional stimuli;HD EEG;vector field tomography","Electroencephalography;Brain modeling;Tomography;Electric potential","","3","","90","IEEE","30 Mar 2015","","","IEEE","IEEE Journals"
"The Regulation of Automatic Acceptance Priming on Instructed Fear: An ERP Study","R. Sun; J. Yang; Z. Hong; Z. Zhang; L. Zhu; J. Yuan","Institute of Brain and Psychological Sciences, Sichuan Normal University, Chengdu, China; Institute of Brain and Psychological Sciences, Sichuan Normal University, Chengdu, China; Institute of Brain and Psychological Sciences, Sichuan Normal University, Chengdu, China; Institute of Brain and Psychological Sciences, Sichuan Normal University, Chengdu, China; Institute of Brain and Psychological Sciences, Sichuan Normal University, Chengdu, China; Institute of Brain and Psychological Sciences, Sichuan Normal University, Chengdu, China",2024 6th International Conference on Frontier Technologies of Information and Computer (ICFTIC),"13 Mar 2025","2024","","","171","175","Instructed fear is the learning of fear through verbal information, enabling efficient recognition of threat signals, making the decoding and recognition of fear-related electrophysiological signals crucial, and providing potential advancements for affective computing and brain-machine interface applications. Feature extraction of brain signals related to instructed fear has seen considerable progress in electrophysiological research, the neural mechanisms underlying the automatic regulation of fear remain to be explored. In this study, we used a speech transmission fear paradigm to induce fear and applied different automatic emotion regulation paradigms to initiate an acceptance strategy. By combining behavioral and electrophysiological methods, we examined the impact of automatic acceptance on instructed fear. The results showed that the automatic acceptance strategy could partially regulate instructed fear, significantly reducing participants' subjective feelings toward threat stimulus. However, the effects on beliefs and behavior were more limited. From the electrophysiological data, compared to neutral priming, acceptance priming led to smaller EPN and P3b amplitudes, suggesting a reduction in emotional arousal and alertness during the early stages of emotion recognition and attention.","","979-8-3315-4175-0","10.1109/ICFTIC64248.2024.10913111","National Natural Science Foundation of China(grant numbers:NSFC31871103); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10913111","component;instructed fear;atomatic emotion regulation;acceptance;EEG;affective computing","Affective computing;Emotion recognition;Electric shock;Psychology;Electrophysiology;Feature extraction;Regulation;Electroencephalography;Resource management;Investment","","","","15","IEEE","13 Mar 2025","","","IEEE","IEEE Conferences"
"EEG Conformer: Convolutional Transformer for EEG Decoding and Visualization","Y. Song; Q. Zheng; B. Liu; X. Gao","Department of Biomedical Engineering, School of Medicine, Tsinghua University, Beijing, China; Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Department of Biomedical Engineering, School of Medicine, Tsinghua University, Beijing, China; Department of Biomedical Engineering, School of Medicine, Tsinghua University, Beijing, China",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"2 Feb 2023","2023","31","","710","719","Due to the limited perceptual field, convolutional neural networks (CNN) only extract local temporal features and may fail to capture long-term dependencies for EEG decoding. In this paper, we propose a compact Convolutional Transformer, named EEG Conformer, to encapsulate local and global features in a unified EEG classification framework. Specifically, the convolution module learns the low-level local features throughout the one-dimensional temporal and spatial convolution layers. The self-attention module is straightforwardly connected to extract the global correlation within the local temporal features. Subsequently, the simple classifier module based on fully-connected layers is followed to predict the categories for EEG signals. To enhance interpretability, we also devise a visualization strategy to project the class activation mapping onto the brain topography. Finally, we have conducted extensive experiments to evaluate our method on three public datasets in EEG-based motor imagery and emotion recognition paradigms. The experimental results show that our method achieves state-of-the-art performance and has great potential to be a new baseline for general EEG decoding. The code has been released in https://github.com/eeyhsong/EEG-Conformer.","1558-0210","","10.1109/TNSRE.2022.3230250","National Natural Science Foundation of China(grant numbers:U2241208,62206270,62171473); Key Research and Development Program of Ningxia(grant numbers:2022CMG02026); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2021A1515110598); Doctoral Brain+X Seed Grant Program of Tsinghua University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9991178","EEG classification;self-attention;transformer;brain-computer interface (BCI);motor imagery","Electroencephalography;Convolution;Transformers;Feature extraction;Decoding;Convolutional neural networks;Task analysis","","246","","46","CCBY","16 Dec 2022","","","IEEE","IEEE Journals"
"ERP Approach: What Could We Learn From?","P. Arico; F. Aloise; C. Giovannella","Neuroelectrical Imaging and BCI Laboratory, IRCCS Fondazione Santa lucia, Italy; Neuroelectrical Imaging and BCI Laboratory, IRCCS Fondazione Santa lucia, Italy; ISIM Garage-ScuolaIaD, University of Roma Tor Vergata, Rome, Italy",2012 IEEE 12th International Conference on Advanced Learning Technologies,"16 Aug 2012","2012","","","654","655","Event-related potential (ERP) studies are very specialized ones that can be used only to investigate specific problems to get a different perspective with respect to more traditional measurements techniques. The peculiarity of ERP measures (time windows, repetitions, etc.) requires a careful design of the experimental protocol to obtain meaningful data. In this paper we discuss how ERPs can be used to study elicitation of emotional perception by means of familiar visual stimuli and, as well, its modification due to the proposition of unexpected stimuli.","2161-377X","978-1-4673-1642-2","10.1109/ICALT.2012.208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268202","Event related potential;brain and emotions;visual tasks","Electroencephalography;Protocols;Visualization;Face;Educational institutions;Neuroscience;Electronic mail","","","","9","IEEE","16 Aug 2012","","","IEEE","IEEE Conferences"
"Event related potential measurements of the emotional stroop test in athletes of combat sports","S. B. Selman; M. Karadağ; M. Assem; A. D. Duru","İnsan ve Toplum Bilimleri Fakültesi, Psikoloji Bölümü, Turkey; Istanbul Universitesi, Fatih, Istanbul, TR; Istanbul Sehir Universitesi, Istanbul, TR; Marmara Universitesi, Istanbul, Istanbul, TR",2014 18th National Biomedical Engineering Meeting,"29 Jan 2015","2014","","","1","4","This research will investigate emotional processing of threat-relevant stimuli in athletes of combat sports by means of an ERP study. In this study, color-naming latency on threat-related words will be expected in athletes of combat sports on the Stroop task compared to athletes of non-combat sports; in other words, it is expected that there will be increased interference effect of threat-relevant stimuli on the Stroop task. In this context, participants will be shown neutral and threat-relevant stimuli randomly, and it will be investigated that whether the P300 wave of EEG show differences in response to threat-related words. After EEG data analysis, which were collected from four participants, it is found that ERP responses within the 280–400 ms time window, the amplitude of the total area of threat-related words is larger than neutral words for the group who are active in combat sports.","","978-1-4799-7572-3","10.1109/BIYOMUT.2014.7026378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7026378","","Electroencephalography;Interference;Abstracts;Context;Data analysis;Reactive power;Art","","","","7","IEEE","29 Jan 2015","","","IEEE","IEEE Conferences"
"Single trial visual event-related potential EEG analysis using the wavelet transform","R. E. Herrera; R. J. Sclabassi; Mingui Sun; R. E. Dahl; N. D. Ryan","Laboratory for Computational Neuroscience, Electrical Engineering Department, University of Pittsburgh, Pittsburgh, PA, USA; Laboratory for Computational Neuroscience, Department of Neurological Surgery, Electrical Engineering Departmentamnent, Department of Psychiatry, Department of Bioengineering, University of Pittsburgh, Pittsburgh, PA, USA; Laboratory for Computational Neuroscience, Department of Neurological Surgery, University of Pittsburgh, Pittsburgh, PA, USA; Department of Psychiatry, Laboratory for Computational Neuroscience, Pittsburgh, PA, USA; Department of Psychiatry, Laboratory for Computational Neuroscience, Pittsburgh, PA, USA",Proceedings of the First Joint BMES/EMBS Conference. 1999 IEEE Engineering in Medicine and Biology 21st Annual Conference and the 1999 Annual Fall Meeting of the Biomedical Engineering Society (Cat. N,"6 Aug 2002","1999","2","","947 vol.2","","We present in this paper a study of event-related potentials evoked by sequential presentation of facial images depicting different emotions. The objective of this study is to extract the emotion related potentials from few or single stimulus trials using the wavelet transform. This would permit the characterization of the subject response for each emotion presented.","1094-687X","0-7803-5674-8","10.1109/IEMBS.1999.804101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=804101","","Electroencephalography;Wavelet analysis;Wavelet transforms;Enterprise resource planning;Signal processing;Signal to noise ratio;Psychiatry;Biomedical engineering;Helium;Disk recording","","2","","1","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Rapid Detection of Emotion from Human Vocalizations","D. A. Sauter; M. Eimer",NA; NA,Journal of Cognitive Neuroscience,"19 May 2014","2010","22","3","474","481","The rapid detection of affective signals from conspecifics is crucial for the survival of humans and other animals; if those around you are scared, there is reason for you to be alert and to prepare for impending danger. Previous research has shown that the human brain detects emotional faces within 150 msec of exposure, indicating a rapid differentiation of visual social signals based on emotional content. Here we use event-related brain potential (ERP) measures to show for the first time that this mechanism extends to the auditory domain, using human nonverbal vocalizations, such as screams. An early fronto-central positivity to fearful vocalizations compared with spectrally rotated and thus acoustically matched versions of the same sounds started 150 msec after stimulus onset. This effect was also observed for other vocalized emotions (achievement and disgust), but not for affectively neutral vocalizations, and was linked to the perceived arousal of an emotion category. That the timing, polarity, and scalp distribution of this new ERP correlate are similar to ERP markers of emotional face processing suggests that common supramodal brain mechanisms may be involved in the rapid detection of affectively relevant visual and auditory signals.","0898-929X","","10.1162/jocn.2009.21215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6793252","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Multimedia implicit tagging using EEG signals","M. Soleymani; M. Pantic","Imperial College London, UK; Imperial College London, London, London, GB",2013 IEEE International Conference on Multimedia and Expo (ICME),"26 Sep 2013","2013","","","1","6","Electroencephalogram (EEG) signals reflect brain activities associated with emotional and cognitive processes. In this paper, we demonstrate how they can be used to find tags for multimedia content without users' direct input. Alternative methods for multimedia tagging is attracting increasing interest from multimedia community. The new portable EEG helmets are paving the way for employing brain waves in human computer interaction. In this paper, we demonstrate the performance of EEG for tagging purposes using two different scenarios on MAHNOB-HCI database. First, an emotional tagging and classification using a reduced set of electrodes is presented. The emotional responses of 24 participants to short video clips are classified into three classes on arousal and valence. We show how a reduced set of electrodes based on previous studies can preserve and even enhance the emotional classification rate. We then demonstrate the feasibility of using EEG signals for tag relevance tasks. A set of images were shown to participants first, without any tag and then with a relevant or irrelevant tag. The relevance of the tag was assessed based on the EEG responses of the participants in the first second after the tag was depicted. Finally, we demonstrate that by aggregating multiple participants' responses we can significantly improve the tagging accuracy.","1945-788X","978-1-4799-0015-2","10.1109/ICME.2013.6607623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6607623","EEG;affect;implicit tagging;tag relevance;multimedia","Electroencephalography;Tagging;Electrodes;Multimedia communication;Feature extraction;Databases;Accuracy","","23","","31","IEEE","26 Sep 2013","","","IEEE","IEEE Conferences"
"Human body odors of happiness and fear modulate the late positive potential component during neutral face processing: a preliminary ERP study on healthy subjects","A. L. Callara; C. Cecchetto; E. Dal Bò; L. Citi; C. Gentili; N. Vanello; E. P. Scilingo; A. Greco","Research Center “E. Piaggio”, University of Pisa, Italy; Department of General Psychology, University of Padova, Italy; Department of General Psychology, University of Padova, Italy; School of Computer Science and Electronic Engineering, University of Essex, UK; Department of General Psychology, University of Padova, Italy; Research Center “E. Piaggio”, University of Pisa, Italy; Research Center “E. Piaggio”, University of Pisa, Italy; Research Center “E. Piaggio”, University of Pisa, Italy",2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"8 Sep 2022","2022","","","4093","4096","Human body odors (HBOs) are powerful stimuli that can affect emotional, cognitive and behavioral processes. However, the characterization of the physiological response to HBOs is still to be fully investigated. Here, we analyzed the self-assessed emotion perception and the EEG event-related potentials (ERP) on 17 healthy young women during a simultaneous visual-olfactory stimulation. Particularly, we evaluated the effect of happiness and fear HBO on the amplitude of ERP waveforms elicited by neutral face processing. In addition, we evaluated the subjective valence and arousal perception of the presented neutral faces by means of the self-assessment-manikin test. We observed a significant increase in the amplitude of the late positive potential (LPP) for central left sites (i.e., C3) during the administration of HBOs with respect to clean air. On the other hand, we did not observe any significant change in the subjective valence and arousal scores as well as for the early components of the ERP (i.e., P100, N170, Vertex-Positive-Potential). Our preliminary results suggest that fear and happiness HBO can induce a protracted increase in the LPP, and possibly reflect an automatic and sustained engagement with emotionally significant content.","2694-0604","978-1-7281-2782-8","10.1109/EMBC48229.2022.9871495","Italian MIUR (i.e., Ministry of Education and Research); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871495","","Physiology;Electroencephalography;Behavioral sciences;Faces","Body Odor;Evoked Potentials;Facial Recognition;Fear;Female;Happiness;Healthy Volunteers;Humans","3","","34","IEEE","8 Sep 2022","","","IEEE","IEEE Conferences"
"Shared Attention Amplifies the Neural Processing of Emotional Faces","A. Schiano Lomoriello; P. Sessa; M. Doro; I. Konvalinka",Technical University of Denmark; University of Padova; University of Padova; Technical University of Denmark,Journal of Cognitive Neuroscience,"27 Jun 2022","2022","34","6","917","932","Sharing an experience, without communicating, affects people's subjective perception of the experience, often by intensifying it. We investigated the neural mechanisms underlying shared attention by implementing an EEG study where participants attended to and rated the intensity of emotional faces, simultaneously or independently. Participants performed the task in three experimental conditions: (a) alone; (b) simultaneously next to each other in pairs, without receiving feedback of the other's responses (shared without feedback); and (c) simultaneously while receiving the feedback (shared with feedback). We focused on two face-sensitive ERP components: The amplitude of the N170 was greater in the “shared with feedback” condition compared to the alone condition, reflecting a top–down effect of shared attention on the structural encoding of faces, whereas the EPN was greater in both shared context conditions compared to the alone condition, reflecting an enhanced attention allocation in the processing of emotional content of faces, modulated by the social context. Taken together, these results suggest that shared attention amplifies the neural processing of faces, regardless of the valence of facial expressions.","0898-929X","","10.1162/jocn_a_01841","Villum Fonden(grant numbers:00023213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808250","","","","","","","","27 Jun 2022","","","MIT Press","MIT Press Journals"
"The effect of noise removing on emotional classification","M. molavi; J. bin Yunus","Faculty of Health Science and Biomedical Engineering, Universiti Teknologi Malaysia, Johor, Malaysia; Faculty of Health Science and Biomedical Engineering, Universiti Teknologi Malaysia, Johor, Malaysia",2012 International Conference on Computer & Information Science (ICCIS),"10 Sep 2012","2012","1","","485","489","This paper explains the issues of study that was designed to evaluate the effect of denoising algorithm to detect emotional expression through Electroencephalogram (EEG). This research led to classify the EEG features due to emotion which was induced by the facial expression stimulus include of happy and sad and neutral cases. Event-related potential (ERP) method was selected to probe the ability of Independent components analysis (ICA) and principal components analysis (PCA) as denoising mathematical tool which is used for data preprocessing. The features were extracted by common spatial patterns (CSP) to decrease the dimensions of data. After that extracted components was classified by support vector machine (SVM) to show the effect of noise removing on data classification. The results show that ICA could provide the most accurate result for classifying emotional states in brain activity than other methods. However, the PCA was not shown a very different and inaccurate classification results.","","978-1-4673-1938-6","10.1109/ICCISci.2012.6297294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6297294","","Noise reduction;Principal component analysis;Electroencephalography;Noise;Support vector machines;Feature extraction;Accuracy","","1","","31","IEEE","10 Sep 2012","","","IEEE","IEEE Conferences"
"A Tale of Single-Channel Electroencephalography: Devices, Datasets, Signal Processing, Applications, and Future Directions","Y. Li; W. Zeng; W. Dong; D. Han; L. Chen; H. Chen; Z. Kang; S. Gong; H. Yan; W. T. Siok; N. Wang","Laboratory of Digital Image and Intelligent Computation, Shanghai Maritime University, Shanghai, China; Laboratory of Digital Image and Intelligent Computation, Shanghai Maritime University, Shanghai, China; Laboratory of Digital Image and Intelligent Computation, Shanghai Maritime University, Shanghai, China; Laboratory of Digital Image and Intelligent Computation, Shanghai Maritime University, Shanghai, China; Laboratory of Digital Image and Intelligent Computation, Shanghai Maritime University, Shanghai, China; Laboratory of Digital Image and Intelligent Computation, Shanghai Maritime University, Shanghai, China; Laboratory of Digital Image and Intelligent Computation, Shanghai Maritime University, Shanghai, China; Laboratory of Digital Image and Intelligent Computation, Shanghai Maritime University, Shanghai, China; Department of Neurology, Affiliated Lianyungang Hospital of Xuzhou Medical University, Lianyungang, China; Department of Chinese and Bilingual Studies, The Hong Kong Polytechnic University, Hong Kong, SAR, China; Department of Chinese and Bilingual Studies, The Hong Kong Polytechnic University, Hong Kong, SAR, China",IEEE Transactions on Instrumentation and Measurement,"25 Apr 2025","2025","74","","1","20","Single-channel electroencephalography (EEG) is a cost-effective, comfortable, and noninvasive method for monitoring brain activity, widely adopted by researchers, consumers, and clinicians. The increasing number and proportion of articles on single-channel EEG underscore its growing potential. This article provides a comprehensive review of single-channel EEG, focusing on development trends, devices, datasets, signal processing methods, recent applications, and future directions. Definitions of bipolar and unipolar configurations in single-channel EEG are clarified to guide future advancements. Applications mainly span sleep staging, emotion recognition, neurofeedback, educational research, and clinical diagnosis. In addition, we discuss about the artificial intelligence (AI)-based EEG generation techniques, advancements through the integration of advanced signal processing with AI, innovations in hardware development, and strategies for the integration of wearables enabled by the Internet of Things (IoT), collectively establishing a foundational roadmap for future developments in single-channel EEG systems and their applications.","1557-9662","","10.1109/TIM.2025.3556900","National Natural Science Foundation of China(grant numbers:31870979); Hong Kong Polytechnic University Start-Up Fund(grant numbers:P0053210); Hong Kong Polytechnic University Faculty Reserve Fund(grant numbers:P0053738); Internal Grant from Hong Kong Polytechnic University(grant numbers:P0048377); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10947211","Artificial intelligence (AI);clinical applications;emotion recognition;Internet of Things (IoT);signal processing;single-channel electroencephalography (EEG);sleep analysis;wearable devices","Electroencephalography;Electrodes;Sleep;Recording;Monitoring;Wearable devices;Scalp;Artificial intelligence;Sensors;Batteries","","","","220","IEEE","1 Apr 2025","","","IEEE","IEEE Journals"
"Emotional brain-computer interfaces","G. G. Molina; T. Tsoneva; A. Nijholt","Philips Research Europe, Eindhoven, Netherlands; Philips Research Europe, Eindhoven, Netherlands; INF, Universiteit Twente, Enschede, Netherlands",2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops,"8 Dec 2009","2009","","","1","9","Research in brain-computer interface (BCI) has significantly increased during the last few years. In addition to their initial role as assisting devices for the physically challenged, BCIs are now proposed for a wider range of applications. As in any HCI application, BCIs can also benefit from adapting their operation to the emotional state of the user. BCIs have the advantage of having access to brain activity which can provide significant insight into the user's emotional state. This information can be utilized in two manners. 1) Knowledge of the influence of the emotional state on brain activity patterns can allow the BCI to adapt its recognition algorithms, so that the intention of the user is still correctly interpreted in spite of signal deviations induced by the subject's emotional state. 2) The ability to recognize emotions can be used in BCIs to provide the user with more natural ways of controlling the BCI through affective modulation. Thus, controlling a BCI by recollecting a pleasant memory can be possible and can potentially lead to higher information transfer rates. These two approaches of emotion utilization in BCI are elaborated in detail in this paper in the framework of non-invasive EEG based BCIs.","2156-8111","978-1-4244-4800-5","10.1109/ACII.2009.5349478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5349478","","Brain computer interfaces;Electroencephalography;Signal processing;Electrodes;Frequency;Europe;Emotion recognition;Pattern recognition;Signal detection;Monitoring","","37","","54","IEEE","8 Dec 2009","","","IEEE","IEEE Conferences"
"A General Multi Time Scale Spatiotemporal Compound Model for EEG Classification","R. Chen; X. Liu; W. Dai; Y. Gao","School of computer science, Beijing University of Posts and Telecommunications, Beijing, China; School of computer science, Beijing University of Posts and Telecommunications, Beijing, China; School of computer science, Beijing University of Posts and Telecommunications, Beijing, China; School of computer science, Beijing University of Posts and Telecommunications, Beijing, China",2021 2nd International Conference on Artificial Intelligence and Computer Engineering (ICAICE),"24 Jun 2022","2021","","","377","381","Recently Brain computer interfaces (BCI), a direct communication technique between machine and brain, plays an important role in the fields of brain disease diagnose, rehabilitation and robotics with the help of electroencephalography (EEG). EEG-based brain signal feature extraction and task categorization have become a popular trend. The procedure of brain signal analysis includes three steps: pre-process, feature extraction and categorization. For a given BCI paradigm, these steps are tailored to explore distinct characteristics of its expected control signals. To generalize the process, we propose a multi time scale spatiotemporal compound classification model (MTSC) based on Convolution Neural Network (CNN). The model firstly utilizes 2D convolution along time axis capturing temporal feature, then depth-wise convolution along channel axis is done for capturing spatial feature. Both of two domain features composite a facet of original EEG signal. We set up different 2D convolution kernel size according to the signal sample rate in order to generate different views, which contains various time scale information. These views are weighted summed for classification. Experiments on four different paradigm datasets have been conducted comparing with well performed deep learning and traditional methods. The results show that our model achieves better marks on all datasets in accuracy and F1-score.","","978-1-6654-2186-7","10.1109/ICAICE54393.2021.00080","NSFC(grant numbers:61773037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797623","EEG;BCI;Deep learning;multi time scale spatiotemporal compound classification model (MTSC)","Convolution;Computational modeling;Brain modeling;Feature extraction;Electroencephalography;Data models;Brain-computer interfaces","","","","14","IEEE","24 Jun 2022","","","IEEE","IEEE Conferences"
"An EEG Method to Identify Image Preference With an Explicit/Implicit Task Brain-Computer Interface","Y. Li; S. Li; H. Qi","Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, China; Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, China; Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, China",IEEE Transactions on Affective Computing,"","2025","PP","99","1","14","Accurately determining an individual's preference for images remains a major challenge in the field of emotional research. This study proposes a novel paradigm for identifying individual image preferences using electroencephalography (EEG) signals and brain-computer interface (BCI). The paradigm involves both explicit and implicit tasks, where participants perform a typical event-related potential-based brain-computer interface(ERP-BCI) operation and their subjective image preferences are identified, respectively. Two experiments with a total of 27 participants demonstrate that event-related potential (ERP) signals during explicit BCI tasks are significantly influenced by target image preferences, enabling high-accuracy image preference recognition. Online experiments selecting positive and negative preference images from a candidate pool show top-1 accuracy approaching 100% and top-3 accuracy exceeding 90%. These results indicate the effectiveness of the proposed EEG-based image preference recognition paradigm, laying the groundwork for preference analysis applications.","1949-3045","","10.1109/TAFFC.2025.3554534","National Natural Science Foundation of China(grant numbers:82172057); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10938558","Brain-Computer Interface(BCI);electroencephalography (EEG);event - related potentials (ERP);explicit/implicit task paradigm;image preference recognition;machine learning;selective attention","Electroencephalography;Image recognition;Brain-computer interfaces;Visualization;Psychology;Training;Libraries;Faces;Ethics;Electrodes","","","","","IEEE","25 Mar 2025","","","IEEE","IEEE Early Access Articles"
"Evaluation of ERD/ERS caused by unpleasant sounds to be applied in BCIs","A. C. Atencio; T. F. B. Filho; A. Ferreira; A. B. Benevides","PPGEE, Federal University of Espirito Santo, Vitoria, Espirito Santo, Brazil; PPGEE, Federal University of Espirito Santo, Vitoria, Espirito Santo, Brazil; PPGEE, Federal University of Espirito Santo, Vitoria, Espirito Santo, Brazil; PPGEE, Federal University of Espirito Santo, Vitoria, Espirito Santo, Brazil",2013 ISSNIP Biosignals and Biorobotics Conference: Biosignals and Robotics for Better and Safer Living (BRC),"28 Mar 2013","2013","","","1","5","This paper presents the off-line evaluation of scalp EEG signals registered while a potential brain-computer-interface user was hearing unpleasant sounds. The EEG patterns of event-related desynchronization/synchronization are studied during the human perception of sound stimuli, which was given by scraping a sharp knife along the surface of a ridged metal bottle sound. This evaluation was conducted with the purpose of search the correlating EEG signals with emotional state caused by unpleasant stimuli and their influence of brain-computer-interface commands, as motor imagery commands, in order to increase the efficiency of this kind of human-machine-interface performance. It was observed that waveforms in μ and ß frequency bands of Fpl and Fp2 channels present variations that could been caused by neural activity due to the unpleasant sound stimuli.","2326-7844","978-1-4673-3025-1","10.1109/BRC.2013.6487533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6487533","","Electroencephalography;Electrodes;Stress;Emotion recognition;Brain-computer interfaces;Scalp;Pattern recognition","","4","","18","IEEE","28 Mar 2013","","","IEEE","IEEE Conferences"
"Typicality effect on N400 ERP in categories despite differences in semantic processing","M. F. Hnazaee; M. M. Van Hulle","Laboratory for Neuro- and Psychophysiology, KU Leuven - University of Leuven, Leuven, Belgium; Laboratory for Neuro- and Psychophysiology, KU Leuven - University of Leuven, Leuven, Belgium",2017 International Joint Conference on Neural Networks (IJCNN),"3 Jul 2017","2017","","","4379","4386","We investigate the effect of word typicality - the degree of membership of a word to its superordinate category - on the N400 event-related potential (ERP) using a single trial detection approach based on spatiotemporal beamforming. Unlike the norm in studies, where mostly concrete categories are used (imaginable objects), we considered a total of 6 basic categories: three abstract and unimaginable (emotion, event, illness), one abstract yet clearly imaginable (color), and two concrete categories, a coherent (mammals) and an incoherent one (furniture). We also investigated the source of the observed N400 ERPs in the brain to detect possible differences between the semantic processing of these categories. Our results show that, independently of word abstractness or concreteness, word typicality has a clear effect on N400 both in terms of amplitude and scalp localization as well as in N400 sources, all of which in turn is indicative of differences in difficulty of word processing.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7966410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966410","EEG-ERP;N400 component;prototype theory;word categorization;source localization","Semantics;Concrete;Electroencephalography;Presses;Electrodes;Prototypes;Image color analysis","","1","","33","IEEE","3 Jul 2017","","","IEEE","IEEE Conferences"
"User Identity Protection in EEG-Based Brain–Computer Interfaces","L. Meng; X. Jiang; J. Huang; W. Li; H. Luo; D. Wu","Key Laboratory of Image Processing and Intelligent Control, the Belt and Road Joint Laboratory on Measurement and Control Technology, and the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Key Laboratory of Image Processing and Intelligent Control, the Belt and Road Joint Laboratory on Measurement and Control Technology, and the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Key Laboratory of Image Processing and Intelligent Control, the Belt and Road Joint Laboratory on Measurement and Control Technology, and the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Key Laboratory of Image Processing and Intelligent Control, the Belt and Road Joint Laboratory on Measurement and Control Technology, and the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Civil and Hydraulic Engineering, Huazhong University of Science and Technology, Wuhan, China; Key Laboratory of Image Processing and Intelligent Control, the Belt and Road Joint Laboratory on Measurement and Control Technology, and the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"12 Sep 2023","2023","31","","3576","3586","A brain-computer interface (BCI) establishes a direct communication pathway between the brain and an external device. Electroencephalogram (EEG) is the most popular input signal in BCIs, due to its convenience and low cost. Most research on EEG-based BCIs focuses on the accurate decoding of EEG signals; however, EEG signals also contain rich private information, e.g., user identity, emotion, and so on, which should be protected. This paper first exposes a serious privacy problem in EEG-based BCIs, i.e., the user identity in EEG data can be easily learned so that different sessions of EEG data from the same user can be associated together to more reliably mine private information. To address this issue, we further propose two approaches to convert the original EEG data into identity-unlearnable EEG data, i.e., removing the user identity information while maintaining the good performance on the primary BCI task. Experiments on seven EEG datasets from five different BCI paradigms showed that on average the generated identity-unlearnable EEG data can reduce the user identification accuracy from 70.01% to at most 21.36%, greatly facilitating user privacy protection in EEG-based BCIs.","1558-0210","","10.1109/TNSRE.2023.3310883","National Key Research and Development Program of China(grant numbers:2022YFE0204700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10236508","Brain–computer interfaces;machine learning;privacy protection","Electroencephalography;Task analysis;Perturbation methods;Brain modeling;Feature extraction;Data privacy;Privacy","Humans;Brain-Computer Interfaces;Electroencephalography;Brain;Communication","7","","38","CCBY","31 Aug 2023","","","IEEE","IEEE Journals"
"Neural and Behavioral Evidence for Infants' Sensitivity to the Trustworthiness of Faces","S. Jessen; T. Grossmann","1Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; 1Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany",Journal of Cognitive Neuroscience,"6 Oct 2016","2016","28","11","1728","1736","Face evaluation is a key aspect of face processing in humans, serving important functions in regulating social interactions. Adults and preschool children readily evaluate faces with respect to a person's trustworthiness and dominance. However, it is unclear whether face evaluation is mainly a product of extensive learning or a foundational building block of face perception already during infancy. We examined infants' sensitivity to facial signs of trustworthiness (Experiment 1) and dominance (Experiment 2) by measuring ERPs and looking behavior in response to faces that varied with respect to the two facial attributes. Results revealed that 7-month-old infants are sensitive to facial signs of trustworthiness but not dominance. This sensitivity was reflected in infants' behavioral preference and in the modulation of brain responses previously linked to emotion detection from faces. These findings provide first evidence that processing faces with respect to trustworthiness has its origins in infancy and shed light on the behavioral and neural correlates of this early emerging sensitivity.","0898-929X","","10.1162/jocn_a_00999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7580967","","","","","","","","6 Oct 2016","","","MIT Press","MIT Press Journals"
"Functional Networks Based Diagnostics Concept for Depression Disorders","K. V. Ladonovskaya; E. A. Merkulova","dept. of diff. psychophysiology, State-Research Institute of Neuroscience and Medicine, Novosibirsk, Russia; State-Research Institute of Neuroscience and Medicine Novosibirsk State University, Novosibirsk, Russia",2022 IEEE 23rd International Conference of Young Professionals in Electron Devices and Materials (EDM),"19 Aug 2022","2022","","","326","329","Depression is the leading mental disorder and cause of disability. The current depression diagnostics based on symptoms manifestations detected by therapist. The neurological basis of symptoms and individual physiological information can help to prescribe the most suitable treatment and decrease the side effects. The RDoC concept is widely used framework for the scientific researches in depression. But unfortunately, all the scientific knowledge not much used in clinical purpose. in clinical purpose. According the concept, the symptoms result from dysfunctions in the particular brain networks. The neuronal activity of brain networks can be reflected in EEG/fMRI and estimated in widely used event related tests. We propose the adopted and optimized EEG/ERP tests to reach the maximum required information connected with the depression status in limited time, limited patient motivation and limited technical environment. The proposed tests load all the required brain networks and provide different types of results: behavioral, EEG ERP and EEG fingerprints. The individual physiological information collected in questionnaires can be used to decrease the influence of the individual variability. The tests proposed can be used not only in diagnostics, but also in treatment control and to control the changes in brain networks caused by prescribed treatment.","2325-419X","978-1-6654-9804-3","10.1109/EDM55285.2022.9855127","Russian Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9855127","EEG;ERP;RDoC;depression;MDD","Mental disorders;Fingerprint recognition;Depression;Physiology;Electroencephalography;Behavioral sciences;Electron devices","","","","14","IEEE","19 Aug 2022","","","IEEE","IEEE Conferences"
"Towards adaptive brain-computer interfaces: Improving accuracy of detection of event-related potentials","R. Moro; P. Berger; M. Bielikova","Faculty of Informatics and Information Technologies, Slovak University of Technology in Bratislava, Bratislava, Slovakia; Faculty of Informatics and Information Technologies, Slovak University of Technology in Bratislava, Bratislava, Slovakia; Faculty of Informatics and Information Technologies, Slovak University of Technology in Bratislava, Bratislava, Slovakia",2017 12th International Workshop on Semantic and Social Media Adaptation and Personalization (SMAP),"31 Aug 2017","2017","","","34","39","Electroencefalography (EEG) has a wide range of applications in human-computer interaction and in adaptation and personalization of the interfaces. It can be used either as a sensor, e.g., for emotion detection, or as an input device that allows to take actions based on the brain's response to the presented stimuli. For the latter, it is crucial to be able to reliably detect event-related potentials (ERPs), which can be a hard task because of the noise in the signal, especially when using affordable consumer-oriented devices, such as Emotiv Epoc. In the paper, we present a method of EEG signal processing and classification for detection of ERP P300 wave. We particularly focus on the adaptive channel selection and propose to use genetic algorithm combined with linear discriminant analysis to determine the optimal subset of electrodes for signal processing for each individual user. We evaluated our proposed method on a standard data set outperforming the existing approaches even with decreasing size of a training set. In addition, we conducted a user study with Emotiv Epoc device on a standard P300 Speller task in order to compare the results of our method and to find out, whether this device is suitable for P300 detection.","","978-1-5386-0756-5","10.1109/SMAP.2017.8022664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022664","EEG;event-related potentials;P300;Emotiv Epoc;genetic algorithm;adaptation","Electroencephalography;Genetic algorithms;Electrodes;Training;Signal processing;Principal component analysis;Sociology","","2","","15","IEEE","31 Aug 2017","","","IEEE","IEEE Conferences"
"Differences in EEG Brain Activity for Black/White Versus RGB Stimuli","A. Khadir; B. Beigzadeh","Biomechatronics and Cognitive Engineering Research Laboratory, School of Mechanical Engineering, Iran University of Science and Technology, Tehran, Iran; Biomechatronics and Cognitive Engineering Research Laboratory, School of Mechanical Engineering, Iran University of Science and Technology, Tehran, Iran",IEEE Access,"27 Feb 2024","2024","12","","28212","28224","Background: Color perception is vital in many aspects of human behavior. It is tremendously engaged in the early stage of information processing to accelerate attention. Several studies focused on different aspects of the psychological effect of colors, which showed that color designs induce positive emotion, increased cognitive effort, and better learning outcomes compared to achromatic stimuli. Considering the importance of our daily encounters with colored stimuli, especially the RGB, black and white, studying the effect of these stimuli on brain activities is essential. Method: We investigated the significant differences in spatiotemporal brain activity of black, white, and RGB information. We used a task in which 12 participants were presented with random black-and-white and RGB-colored stimuli in a dark room. Each stimulus was displayed on the whole screen of a CRT calibrated monitor for 10 seconds. A 64-channel EEG device was used to acquire the EEG data. Results: Our results show that for RGB-colored stimuli, the beta power of the occipito-parietal region in early period (85 - 120 ms after stimulus onset) for RGB is higher than that of black ( $p < 0.05$ ), while in late period (800 - 855 ms after stimulus onset), for RGB it is higher than that of both black and white ( $p < 0.05$ ). Moreover, the alpha power of the centro-parietal region in late period (930 - 1360 ms after stimulus onset) for RGB is higher than that of black ( $p < 0.01$ ). Finally, ITPC of alpha band in occipariatal region in the late period (840 - 920 ms after stimulus onset) for white is higher than black ( $p < 0.05$ ) and RGB ( $p < 0.01$ ). Conclusion: The results regarding brain responses to black/white and RGB stimuli, as well as beta and alpha-band differences in centro-pariatal and occipito-parietal regions provide valuable insights that can be interpretted within perception, emotional activities, and visual processes. Practical applications may span psychology, biofeedback, and BCI systems, with implications for cognitive training, rehabilitation, and human-computer interaction.","2169-3536","","10.1109/ACCESS.2024.3365748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433479","Color perception;EEG;alpha phase consistency;alpha and beta power","Color;Electroencephalography;Electrodes;Visualization;Image color analysis;Brain modeling;Psychology;Behavioral sciences;Human factors;Image color analysis;Emotion recognition","","","","88","CCBYNCND","13 Feb 2024","","","IEEE","IEEE Journals"
"EEG-Based Assessment of Perceived Realness in Stylized Face Images","M. T. Bagdasarian; A. Hilsmann; P. Eisert; G. Curio; K. -R. Müller; T. Wiegand; S. Bosse","Department of Video Coding and Analytics, Fraunhofer HHI, Berlin; Department of Vision and Imaging Technologies, Fraunhofer HHI, Berlin; Department of Vision and Imaging Technologies, Fraunhofer HHI, Berlin; Department of Neurology and Clinical Neurophysiology, Chartié, Berlin; Machine Learning Laboratory, Technical University of Berlin, Berlin, Germany; Department of Video Coding and Analytics, Fraunhofer HHI, Berlin; Department of Video Coding and Analytics, Fraunhofer HHI, Berlin",2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX),"23 Jun 2020","2020","","","1","4","In this paper, we investigate the perception of realness in rendered face images experimentally using electroencephalography. To this end, we presented ten subjects with 36 character images based on six different faces (varying in gender and emotional expression) rendered at six different levels of realness ranging from abstract, cartoon-like renderings to real photographs. In the first psychophysical part of our study, we asked participants to rate perceived realness, appeal, familiarity, reassurance, and attractiveness for the presented characters. In the second part, we recorded the electroencephalogram when presenting the character images at a stimulation frequency of fstim = 5 Hz. We show that the amplitudes of the odd harmonics of the elicited steady-state visual evoked potential correlate with the psychophysical responses (|ρ| = 0.83, p < 0.05).","2472-7814","978-1-7281-5965-2","10.1109/QoMEX48832.2020.9123145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9123145","face perception;ssvep;eeg;realness;character design;uncanny valley","Visualization;Electric potential;Rendering (computer graphics);Harmonic analysis;Electroencephalography;Distance measurement;Steady-state","","3","","38","IEEE","23 Jun 2020","","","IEEE","IEEE Conferences"
"Brain-computer interfacing for bio-perceptive and rehabilitative applications","A. Konar; A. Saha; R. Kar; A. Chakraborty","department of Electronics and Telecommunication Engineering, Jadavpur University, Kolkata, India; department of Electronics and Telecommunication Engineering, Jadavpur University, Kolkata, India; department of Electronics and Telecommunication Engineering, Jadavpur University, Kolkata, India; department of Compter Science and Engineering, St. Thomas' College of Engineering and Technology, Kolkata, India","Proceedings of the 2015 Third International Conference on Computer, Communication, Control and Information Technology (C3IT)","16 Mar 2015","2015","","","1","8","This paper offers a brief overview of the tutorial presentation to be offered at the International Conference on Computer, Communication, Control and Information Technology (C3IT'2015) by the first author. It covers foundations to applications of the Brain-Computer Interfacing research undertaken by a research group at Artificial Intelligence and Brain Imaging Laboratory of Jadavpur University, located in the department of Electronics and Tele-Communication Engineering. The coverage includes four important realizations using EEG Brain-Computer interfacing. The first realization includes EEG-driven position control of robotic links to move the end-affecter at the desired goal position by mental thoughts of the subject only. The second realization includes perceptual-ability measurement of subjects from their EEG response to smell stimuli. The third realization attempts to identify the cognitive failures in driving. The possible failures recognized from EEG signals of the driver includes failure due to lapse of visual attention, cognitive planning and motor execution to accelerate, brake or control the angular motion of the steering wheel. The last part of tutorial aims at detecting neuronal connectivity among the brain lobes during arousal of emotion of subjects.","","978-1-4799-4445-3","10.1109/C3IT.2015.7060105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7060105","Cognitive failures;EEG;Brain-Computer Interfacing;Bio-perception","Electroencephalography;Robots;Brain;Neurons;Electrodes;Visualization;Feature extraction","","2","","52","IEEE","16 Mar 2015","","","IEEE","IEEE Conferences"
"P1 as an objective auditory rehabilitation assessing indicator for cochlear implant children","G. Ni; Q. Zheng; Y. Liu; H. Liu; Z. Xu; D. Ming","Department of Biomedical Engineering, Lab of Neural Engineering & Rehabilitation, College of Precision Instruments and Optoelectronics Engineering, Academy of Medical Engineering and Translational Medicine Tianjin University, Tianjin, P. R. China; Department of Biomedical Engineering, Lab of Neural Engineering & Rehabilitation College of Precision Instruments and Optoelectronics Engineering Tianjin University, Tianjin, P. R. China; Department of Otolaryngology, Head and Neck Surgery, Beijing Children's Hospital, Capital Medical University National Center for Children's Health, Beijing Key Laboratory for Pediatric Diseases of Otolaryngology, Head and Neck Surgery, Beijing, P. R. China; Department of Otolaryngology, Head and Neck Surgery, Beijing Children's Hospital, Capital Medical University National Center for Children's Health, Beijing Key Laboratory for Pediatric Diseases of Otolaryngology, Head and Neck Surgery, Beijing, P. R. China; Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, P. R. China; Department of Biomedical Engineering, Lab of Neural Engineering & Rehabilitation, College of Precision Instruments and Optoelectronics Engineering, Academy of Medical Engineering and Translational Medicine Tianjin University, Tianjin, P. R. China",2019 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA),"20 Apr 2020","2019","","","1","4","Cochlear implants (CIs) provide a tool for hearing reconstruction. How to effectively and reasonably evaluate the auditory rehabilitation level of CI children has always been a difficult problem, especially for those with prelingual deafness. Many studies have used electroencephalograph (EEG) technology for CI users, which have shown that EEG is suitable for clinical postoperative evaluation. This study aims to explore changes of latencies and amplitudes of P1 wave in CI children under auditory stimulation. A pure tone at 1000 Hz was used as the stimuli to induce cortical auditory evoked potentials (CAEP). The characteristics of P1 wave were compared between normal hearing children and CI children over different implantation period. Results show that CI children started to have improved auditory perception after implantation, moreover, their P1 wave amplitude becomes similar to that of normal hearing children after six months. One year after implantation, the characteristics of P1 wave of CI children become similar to those of normal hearing children. Therefore, it seems that P1 could be used as an objective auditory rehabilitation assessing indicator for CI children.","2377-9322","978-1-5386-8344-6","10.1109/CIVEMSA45640.2019.9071598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9071598","cochlear implant;auditory rehabilitation;EEG;cortical auditory evoked potential","Auditory system;Electrodes;Cochlear implants;Electroencephalography;Pediatrics;Surgery;Head","","1","","14","IEEE","20 Apr 2020","","","IEEE","IEEE Conferences"
"Subject Representation Learning from EEG using Graph Convolutional Variational Autoencoders","A. Mishra; A. M. Samin; A. Etemad; J. Hashemi","School of Computing; Department of Electrical and Computer Engineering, Queen’s University, Kingston, Canada; Department of Electrical and Computer Engineering, Queen’s University, Kingston, Canada; School of Computing","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","We propose GC-VASE, a graph convolutional-based variational autoencoder that leverages contrastive learning for subject representation learning from EEG data. Our method successfully learns robust subject-specific latent representations using the split-latent space architecture tailored for subject identification. To enhance the model’s adaptability to unseen subjects without extensive retraining, we introduce an attention-based adapter network for fine-tuning, which reduces the computational cost of adapting the model to new subjects. Our method significantly outperforms other deep learning approaches, achieving state-of-the-art results with a subject balanced accuracy of 89.81% on the ERP-Core dataset and 70.85% on the SleepEDFx-20 dataset. After subject adaptive fine-tuning using adapters and attention layers, GC-VASE further improves the subject balanced accuracy to 90.31% on ERP-Core. Additionally, we perform a detailed ablation study to highlight the impact of the key components of our method.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10890073","Mitacs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890073","EEG;GNNs;Adapters;Representation Learning","Representation learning;Adaptation models;Accuracy;Computational modeling;Autoencoders;Contrastive learning;Brain modeling;Electroencephalography;Medical diagnosis;Speech processing","","","","26","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"Higher-order PLS for classification of ERPs with application to BCIs","Q. Zhao; L. Zhang; J. Cao; A. Cichocki","Rikagaku Kenkyujo, Wako, Saitama, JP; Shanghai Jiao Tong University, Shanghai, CN; Saitama Kogyo Daigaku, Fukaya, Saitama, JP; Rikagaku Kenkyujo, Wako, Saitama, JP",Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference,"17 Jan 2013","2012","","","1","5","The EEG signals recorded during Brain Computer Interfaces (BCIs) are naturally represented by multi-way arrays in spatial, temporal, and frequency domains. In order to effectively extract the underlying components from brain activities which correspond to the specific mental state, we propose the higher-order PLS approach to find the latent variables related to the target labels and then make classification based on latent variables. To this end, the low-dimensional latent space can be optimized by using the higher-order SVD on a cross-product tensor, and the latent variables are considered as shared components between observed data and target output. The EEG signals recorded under the P300-type affective BCI paradigm were used to demonstrate the effectiveness of our new approach.","","978-0-6157-0050-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6411931","","Tensile stress;Electroencephalography;Feature extraction;Principal component analysis;Vectors;Brain computer interfaces;Brain modeling","","","","22","","17 Jan 2013","","","IEEE","IEEE Conferences"
"The Role of the Eyes: Investigating Face Cognition Mechanisms Using Machine Learning and Partial Face Stimuli","I. Chanpornpakdi; T. Tanaka","Department of Electrical and Electronic Engineering, Tokyo University of Agriculture and Technology, Tokyo, Japan; Department of Electrical and Electronic Engineering, Tokyo University of Agriculture and Technology, Tokyo, Japan",IEEE Access,"18 Aug 2023","2023","11","","86122","86131","Face cognition mechanism has changed throughout the SARS-CoV-2 pandemic because of wearing masks. Previous studies found that holistic face processing enhances face cognition ability, and covering part of the face features lowers such an ability. However, the question of why people can recognize faces regardless of missing some clues about the face feature remains unsolved. To study the face cognition mechanism, event-related potential (ERP) evoked during the rapid serial visual presentation task is used. ERP is often hidden under large artifacts and needs to be averaged across the tremendous number of trials, but increasing the trial number can cause fatigue and affect evoked ERP. To overcome this limitation, we adopt machine learning and aim to investigate the partial face cognition mechanism without directly considering the pattern characteristic of the ERP. We implemented an xDAWN spatial filter covariance matrix method to enhance the data quality and a support vector machine classification model to predict the participant’s event of interest using ERP components evoked in the full and partial face cognition tasks. The combination of the missing two face components and the physical response was also investigated to explore the role of each face component and find the possibility of reducing fatigue caused during the experiment. Our results show that the classification accuracy decreased when the eye component was missing and became lowest  $(p < 0.005)$  when the eyes and mouth were absent, with an accuracy of 0.748 ± 0.092 in the button press task and 0.746 ± 0.084 in the no button press task (n.s.). We also observed that the button press error rate increased when the eyes were absent and reached its maximum when the eyes and mouth were covered  $(p < 0.05)$ . These results suggest that the eyes might be the most effective component, the mouth might also play a secondary role in face cognition, and no button press task could be used in substitution of a button press task to reduce the workload.","2169-3536","","10.1109/ACCESS.2023.3295118","Japan Science and Technology Agency (JST) Moonshot Research and Development(grant numbers:JPMJMS2237); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10182239","Partial face cognition;event-related potential;P300;machine learning;Xdawn","Face recognition;Task analysis;Cognition;Event detection;Presses;Visualization;Machine learning","","4","","50","CCBYNCND","13 Jul 2023","","","IEEE","IEEE Journals"
"Transfer Learning for EEG-Based Brain–Computer Interfaces: A Review of Progress Made Since 2016","D. Wu; Y. Xu; B. -L. Lu","Ministry of Education Key Laboratory of Image Processing and Intelligent Control, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Ministry of Education Key Laboratory of Image Processing and Intelligent Control, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Department of Computer Science and Engineering, Center for Brain-Like Computing and Machine Intelligence, Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Brain Science and Technology Research Center, and the Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Cognitive and Developmental Systems,"10 Mar 2022","2022","14","1","4","19","A brain–computer interface (BCI) enables a user to communicate with a computer directly using brain signals. The most common noninvasive BCI modality, electroencephalogram (EEG), is sensitive to noise/artifact and suffers between-subject/within-subject nonstationarity. Therefore, it is difficult to build a generic pattern recognition model in an EEG-based BCI system that is optimal for different subjects, during different sessions, for different devices and tasks. Usually, a calibration session is needed to collect some training data for a new subject, which is time consuming and user unfriendly. Transfer learning (TL), which utilizes data or knowledge from similar or relevant subjects/sessions/devices/tasks to facilitate learning for a new subject/session/device/task, is frequently used to reduce the amount of calibration effort. This article reviews journal publications on TL approaches in EEG-based BCIs in the last few years, i.e., since 2016. Six paradigms and applications—motor imagery, event-related potentials, steady-state visual evoked potentials, affective BCIs, regression problems, and adversarial attacks—are considered. For each paradigm/application, we group the TL approaches into cross-subject/session, cross-device, and cross-task settings and review them separately. Observations and conclusions are made at the end of the article, which may point to future research directions.","2379-8939","","10.1109/TCDS.2020.3007453","Science Fund for Distinguished Young Scholars of Hubei Province(grant numbers:2020CFA050); Hubei Technology Innovation Platform(grant numbers:2019AEA171); National Natural Science Foundation of China(grant numbers:61873321,U1913207); International Science and Technology Cooperation Program of China(grant numbers:2017YFE0128300); National Key Research and Development Program of China(grant numbers:2017YFB1002501); National Natural Science Foundation of China(grant numbers:61673266,61976135); SJTU Transmed Awards Research(grant numbers:WF540162605); Fundamental Research Funds for the Central Universities; Higher Education Discipline Innovation Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134411","Adversarial attacks;affective brain–computer interface (BCI);brain–computer interfaces;domain adaptation;electroencephalogram (EEG);transfer learning (TL)","Electroencephalography;Task analysis;Calibration;Brain modeling;Machine learning;Visualization;Probability distribution","","220","","120","IEEE","7 Jul 2020","","","IEEE","IEEE Journals"
"An ERP study about the effects of different spatial frequencies and orientations on human brain activity","L. Yang; L. L. H. Chan","Department of Electronic Engineering, City University of Hong Kong, Hong Kong; Department of Electronic Engineering, City University of Hong Kong, Hong Kong",2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"5 Nov 2015","2015","","","6202","6205","Spatial, temporal frequencies as well as orientations are important visual stimulus properties, which will affect human perception. In this paper, we investigated the effects of gratings with different spatial, temporal frequencies and orientations on visual evoked potentials. Two positive components (P1 and P2) were observed after stimulation. Our results showed that the amplitude of P1 component was higher for gratings with 0.3 cycles per degree (cpd) spatial frequency compared to 0.05 and 0.1 cpd. While the amplitude differences of P2 component occurred between 0.05 and 0.1 cpd. The amplitude of both components were higher when subjects were viewing gratings at vertical orientation than horizontal orientation.","1558-4615","978-1-4244-9271-8","10.1109/EMBC.2015.7319809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7319809","","Gratings;Electroencephalography;Visualization;Electrodes;Electric potential;Cities and towns;Time-frequency analysis","Adolescent;Adult;Algorithms;Brain;Electroencephalography;Evoked Potentials, Visual;Female;Humans;Male;Orientation;Reaction Time;Space Perception;Visual Pathways;Young Adult","","","13","IEEE","5 Nov 2015","","","IEEE","IEEE Conferences"
"Effect of attentional load on audio-visual integration: an ERP study","Y. Ren; Z. Zhou; J. Bi; J. Li; T. Wang; W. Yang","Department of Psychology, College of Humanities and Management, Guizhou University of Traditional Chinese Medicine, Guiyang, China; Department of Psychology, College of Humanities and Management, Guizhou University of Traditional Chinese Medicine, Guiyang, China; Department of Psychology, College of Humanities and Management, Guizhou University of Traditional Chinese Medicine, Guiyang, China; Department of Psychology, College of Humanities and Management, Guizhou University of Traditional Chinese Medicine, Guiyang, China; Department of Light and Chemical Engineering Guizhou, Light Industry Technical College, Guiyang, China; Department of Psychology Faculty of Education, Hubei University, Wuhan, China",2020 IEEE International Conference on Mechatronics and Automation (ICMA),"26 Oct 2020","2020","","","1443","1448","Audio-visual integration (AVI) is higher in attended conditions than unattended conditions. However, how the AVI was altered with the change of attentional load is rarely studies. In the current study, A dual-task paradigm including an auditory/visual discrimination task, evaluating the AVI effect and a rapid serial visual presentation task, manipulating the attentional load was conducted. The behavioral results showed faster response to all target under no- and low-attentional-load conditions than under high-attentional-load condition. The EEG analysis showed the theta and alpha oscillatory activity was higher for bimodal audio-visual stimulus than individual auditory or visual stimuli, and significantly highest AVI theta and alpha power under low-attentional-load condition than that under low-and high-attentional-load conditions (low > no = high). These results suggested AVI was greatly affect by attentional load.","2152-744X","978-1-7281-6416-8","10.1109/ICMA49215.2020.9233743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9233743","Audio-visual integration;Attentional load;EEG;Oscillation","","","","","28","IEEE","26 Oct 2020","","","IEEE","IEEE Conferences"
"Tracking of changes in latency and amplitude of the evoked potential by using adaptive LMS filters and exponential averagers","O. Svensson","Department of Audiology, Lund University, Lund, Sweden",IEEE Transactions on Biomedical Engineering,"6 Aug 2002","1993","40","10","1074","1079","The adaptive LMS algorithm in combination with exponential averagers are compared to the use of exponential averagers only in tracking latency and amplitude changes in the evoked potential. The estimator is intended for use in applications where neurologic functions are monitored by detecting changes in the evoked potential. Two different structures of the estimator are evaluated and it is found that averaging before filtering is to be preferred. It is shown that the desired signal to the LMS-filter can have a rather low SNR with only mirror influence on the estimator performance. The estimator which combines an LMS filter and an exponential averager was shown to detect changes in latency faster than the estimator which uses a nonfiltered average. The LMS filter is shown to exhibit bias in the estimate of the evoked potential due to the fact that response and background spectra has overlapping frequency ranges. The bias seems not to affect the latency estimation while amplitude estimation was clearly affected. Simulations are performed with both white noise and EEG background.<>","1558-2531","","10.1109/10.247809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=247809","","Delay;Least squares approximation;Adaptive filters;Frequency estimation;Amplitude estimation;Monitoring;Filtering;Mirrors;Brain modeling;White noise","Computer Simulation;Evoked Potentials;Humans;Models, Biological;Monitoring, Physiologic;Reaction Time","22","5","20","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Cognitive, affective, and experience correlates of speech quality perception in complex listening conditions","J. -N. Antons; K. u. R. Laghari; S. Arndt; R. Schleicher; S. Möller; D. O'Shaughnessy; T. H. Falk","Quality and Usability Laboratory, Berlin Institute of Technology, Germany; INRS-EMT, University of Quebec, Canada; Quality and Usability Laboratory, Berlin Institute of Technology, Germany; Quality and Usability Laboratory, Berlin Institute of Technology, Germany; Quality and Usability Laboratory, Berlin Institute of Technology, Germany; Universite du Quebec, Quebec, QC, CA; INRS-EMT, University of Quebec, Canada","2013 IEEE International Conference on Acoustics, Speech and Signal Processing","21 Oct 2013","2013","","","3672","3676","Subjective speech quality assessment depends on listener “quality” opinions after hearing a particular test speech stimulus. Subjective scores are given based on a perception and quality judgment process that is unique to a particular listener. These processes are postulated to be dependent on the listener's internal reference of what good and bad quality sounds like, as well as their mental and emotional states. To overcome this variability, subjective listening tests often average scores over several listeners. In this paper, we use electroencephalography (EEG) and self-assessment tools to investigate the neural and affective correlates of speech quality perception of reverberant speech, with the goal of obtaining new insights into human speech quality perception in complex listening environments. We show that EEG event related potentials (ERP) are a useful tool to monitor the conscious stages of neural-processing during a speech quality assessment task. Significant correlations were obtained between the so-called P300 ERP component and the reverberation time of the room, as well as between the P300 peak amplitude and emotional self-assessment ratings. These insights could lead to more effective ways of characterizing room acoustics for improved speech quality and intelligibility.","2379-190X","978-1-4799-0356-6","10.1109/ICASSP.2013.6638343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6638343","Electroencephalography;reverberation;speech quality assessment;Quality-of-Experience;emotions","Speech;Reverberation;Electroencephalography;Quality assessment;Correlation;Electric potential;Speech processing","","9","","16","IEEE","21 Oct 2013","","","IEEE","IEEE Conferences"
"Early Electrophysiological Correlates of Perceptual Consciousness Are Affected by Both Exogenous and Endogenous Attention","Ł. Doradzińska; M. Bola","Nencki Institute of Experimental Biology of Polish Academy of Sciences, Warsaw, Poland; Centre for Brain Research, Jagiellonian University, Krakow, Poland",Journal of Cognitive Neuroscience,"21 Jun 2024","2024","36","7","1297","1324","It has been proposed that visual awareness negativity (VAN), which is an early ERP component, constitutes a neural correlate of visual consciousness that is independent of perceptual and cognitive mechanisms. In the present study, we investigated whether VAN is indeed a specific marker of phenomenal awareness or rather reflects the involvement of attention. To this end, we reanalyzed data collected in a previously published EEG experiment in which awareness of visual stimuli and two aspects that define attentional involvement, namely, the inherent saliency and task relevance of a stimulus, were manipulated orthogonally. During the experimental procedure, participants (n = 41) were presented with images of faces that were backward-masked or unmasked, fearful or neutral, and defined as task-relevant targets or task-irrelevant distractors. Single-trial ERP analysis revealed that VAN was highly dependent on attentional manipulations in the early time window (140–200 msec), up to the point that the effect of awareness was not observed for attentionally irrelevant stimuli (i.e., neutral faces presented as distractors). In the late time window (200–350 msec), VAN was present in all attentional conditions, but its amplitude was significantly higher in response to fearful faces and task-relevant face images than in response to neutral ones and task-irrelevant ones, respectively. In conclusion, we demonstrate that the amplitude of VAN is highly dependent on both exogenous (stimulus saliency) and endogenous attention (task requirements). Our results challenge the view that VAN constitutes an attention-independent correlate of phenomenal awareness.","0898-929X","","10.1162/jocn_a_02156","National Science Center Poland(grant numbers:data collection: 2018/29/B/HS6/02152,data reanalysis: 2019/33/B/HS6/02233); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10568558","","","","","","","","21 Jun 2024","","","MIT Press","MIT Press Journals"
"Evaluating the Feasibility of a Novel Approach for SSVEP Detection Accuracy Improvement Using Phase Shifts","G. Sun; R. Wang; Y. Leng; Y. Yang; P. Lin; S. Ge","Science of the Ministry of Education, Southeast University, Nanjing, China; Graduate School of Systems Life Sciences, Kyushu University, Fukuoka, Japan; Science of the Ministry of Education, Southeast University, Nanjing, China; Science of the Ministry of Education, Southeast University, Nanjing, China; Engineering of the Education Ministry, Xi'an Jiaotong University, Xi'an, China; Science of the Ministry of Education, Southeast University, Nanjing, China",2016 3rd International Conference on Information Science and Control Engineering (ICISCE),"3 Nov 2016","2016","","","968","972","The canonical correlation analysis (CCA), double-partial least-squares (DPLS) methods and least absolute shrinkage and selection operator (LASSO) have been proven effectively in detecting the steady-state visual evoked potential (SSVEP) in SSVEP-based brain-computer interface systems. However, the accuracy of SSVEP classification can be affected by phase shifts of the electroencephalography data, so we explored the possibility of improving SSEVP detection using these methods at different phase shifts. After calculating the accuracy at different phases, we found that the phase shifts could affect the accuracy of SSVEP classification, the classification accuracy could improved about 1.1% mostly using the CCA method, meanwhile the comparison of the three methods was made at the same time and some differences between the CCA, DPLS and LASSO methods at the different phase shifts also be found. The results indicated that on the one hand, the accuracy of SSVEP detection was improved with the change of the phase, but on the other hand, although the three methods could obtain high classification accuracy, the DPLS and LASSO method showed larger fluctuations than the CCA method as the phase of the electroencephalography data of each participant or their average changed.","","978-1-5090-2535-0","10.1109/ICISCE.2016.210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726307","Brain-computer interface;steady-state visual evoked potential;least absolute shrinkage and selection operator;double partial least squares;canonical correlation analysis;phase shift","Electroencephalography;Feature extraction;Visualization;Brain modeling;Mathematical model;Correlation;Electrodes","","","","12","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Characterizing Autism Spectrum Disorder Through Fusion of Local Cortical Activation and Global Functional Connectivity Using Game-Based Stimuli and a Mobile EEG System","Y. -L. Tseng; C. -H. Lee; Y. -N. Chiu; W. -C. Tsai; J. -S. Wang; W. -C. Wu; Y. -L. Chien","Department of Electrical Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Psychiatry, National Taiwan University Hospital, Taipei, Taiwan; Department of Psychiatry, National Taiwan University Hospital, Taipei, Taiwan; Department of Electrical Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Psychiatry, National Taiwan University Hospital, Taipei, Taiwan",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"26 Aug 2024","2024","32","","3026","3035","The deficit in social interaction skills among individuals with autism spectrum disorder (ASD) is strongly influenced by personal experiences and social environments. Neuroimaging studies have previously highlighted the link between social impairment and brain activity in ASD. This study aims to develop a method for assessing and identifying ASD using a social cognitive game-based paradigm combined with electroencephalo-graphy (EEG) signaling features. Typically developing (TD) participants and autistic preadolescents and teenagers were recruited to participate in a social game while 12-channel EEG signals were recorded. The EEG signals underwent preprocessing to analyze local brain activities, including event-related potentials (ERPs) and time-frequency features. Additionally, the global brain network’s functional connectivity between brain regions was evaluated using phase-lag indices (PLIs). Subsequently, machine learning models were employed to assess the neurophysiological features. Results indicated pronounced ERP components, particularly the late positive potential (LPP), in parietal regions during social training. Autistic preadolescents and teenagers exhibited lower LPP amplitudes and larger P200 amplitudes compared to TD participants. Reduced theta synchronization was also observed in the ASD group. Aberrant functional connectivity within certain time intervals was noted in the ASD group. Machine learning analysis revealed that support-vector machines achieved a sensitivity of 100%, specificity of 91.7%, and accuracy of 95.8% as part of the performance evaluation when utilizing ERP and brain oscillation features for ASD characterization. These findings suggest that social interaction difficulties in autism are linked to specific brain activation patterns. Traditional behavioral assessments face challenges of subjectivity and accuracy, indicating the potential use of social training interfaces and EEG features for cognitive assessment in ASD.","1558-0210","","10.1109/TNSRE.2024.3417210","Taiwan National Science and Technology Council(grant numbers:112-2222-E-110-021); National Health Research Institutes(grant numbers:NHRI-EX113-11008PC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10639538","Electroencephalography;autism spectrum disorder;brain oscillations;functional connectivity;support-vector machine","Electroencephalography;Games;Face recognition;Oscillators;Task analysis;Synchronization;Autism","Humans;Autism Spectrum Disorder;Adolescent;Electroencephalography;Child;Male;Female;Evoked Potentials;Machine Learning;Cerebral Cortex;Video Games;Algorithms;Smartphone;Social Interaction","3","","94","CCBYNCND","20 Aug 2024","","","IEEE","IEEE Journals"
"Effect of Competing Stimuli for Steady-State Visually Evoked Potential and Steady-State Motion Visually Evoked Potential","Y. Gao; A. Ravi; N. Jiang","Department of Systems Design Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Systems Design Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Systems Design Engineering, University of Waterloo, Waterloo, ON, Canada",IEEE Access,"27 Sep 2021","2021","9","","129820","129829","Changes in stimuli proximity have been shown to affect the performance of brain computer interfaces (BCI) based on steady-state visual evoked potentials (SSVEP). Specifically, closely placed visual stimuli compete for neural representations, which is called the effect of competing stimuli. Recently, steady-state motion visual evoked potential (SSMVEP) has been proposed to alleviate some of the inherent limitations of SSVEP. In this study, the SSVEP and SSMVEP paradigms were systematically compared under three different inter-stimulus distances to modulate the effect of competing stimuli. Offline analysis was performed to study the steady-state response characteristics, strength of the responses and overall BCI decoding performance. Thirteen healthy subjects participated in the experiment; two types of visual stimulus with seven classes were presented: a flickering stimulus for SSVEP and a radial contraction-expansion checkerboard for the SSMVEP. The canonical correlation analysis (CCA) was used to study the signal characteristics and the offline decoding performance using only three EEG channels, O1, O2 and Oz. The results demonstrated that SSMVEP was not only less sensitive to competing stimuli, but also consistently outperformed SSVEP in their presence. Further, the SSMVEP response reached its steady-state faster than SSVEP. The signal characteristics analysis revealed that the SSVEP performances were better than SSMVEP in the lowest frequency tested (<9 Hz), and SSMVEP performance was significantly better in the highest frequencies investigated (>13 Hz). The findings in this study indicate that SSMVEP is likely a more practical BCI paradigm than the classic SSVEP for many real-world applications.","2169-3536","","10.1109/ACCESS.2021.3112218","Natural Sciences and Engineering Research Council of Canada (NSERC)-ENGAGE(grant numbers:401261605); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9536570","Brain–computer interfaces;electroencephalography;SSVEP;SSMVEP","Visualization;Steady-state;Electroencephalography;Decoding;Correlation;Protocols;Brain-computer interfaces","","3","","32","CCBYNCND","13 Sep 2021","","","IEEE","IEEE Journals"
"Deep Learning EEG Technology Development and Brain Computer Interface Chips Progress","W. Li; L. Chen; B. Lv; X. Li; W. Wang; K. Xu; X. Ding","School of Mechanical Engineering and Automation, Beihang University, Beijing, BJ, P.R.China; China Academy of Aerospace Electronics Technology, Beijing, BJ, P.R.China; Beijing Microelectronics Technology Institute, Beijing, BJ, P.R.China; Beijing Microelectronics Technology Institute, Beijing, BJ, P.R.China; Robotics Engineering Center, The 21ST Research Institute of China Electronic Technology Group Corporation, Shanghai, China; School of Mechanical Engineering and Automation, Beihang University, Beijing, BJ, P.R.China; School of Mechanical Engineering and Automation, Beihang University, Beijing, BJ, P.R.China","2024 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)","15 Aug 2024","2024","","","413","418","Brain Computer Interfaces establishes an interaction mode between the human brain and external devices, and has broad application prospects. With the development of neuroscience and artificial intelligence technology, brain computer interfaces have rapidly evolved from a single perception stage to a multimodal cognition and complex interaction control stage. This article elaborates on the functional zoning of the brain and cerebellum and the latest research on brain signal classification. Afterwards, the latest research progress of deep learning based EEG signal processing technology was analyzed in depth from three key directions: brain network analysis, research on neurological diseases, cognitive analysis, and emotion recognition. This paper provides a detailed description of the typical structure and main functional unit design ideas of Brain Computer Interface chips, and analyzes the core and difficult technologies from the aspects of acquisition, 3D heterogeneous integration, low-power design, software and brain science research. Finally, based on typical Brain Computer Interface design and application cases, the future development trends of Brain Computer Interface chips and deep learning EEG technology are proposed.","","979-8-3503-7451-3","10.1109/ICASSPW62465.2024.10626697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10626697","Brain Computer Interface;Microsystem;Deep Learning","Deep learning;Neurological diseases;Three-dimensional displays;Neuroscience;Pattern classification;Signal processing;Brain-computer interfaces","","","","31","IEEE","15 Aug 2024","","","IEEE","IEEE Conferences"
"Brain-Based Indicators of Passenger Trust During Open-Road Driving","K. M. DSouza; T. Dang; J. S. Metcalfe; S. Bhattacharya","Information Systems, Kennesaw State University, Kennesaw, Georgia; Electrical Engineering Technology, Kennesaw State University, Marietta, Georgia; US DEVCOM Army Research Laboratory Aberdeen Proving Ground, Human Research and Engineering Directorate, Maryland; Electrical Engineering Technology, Kennesaw State University, Marietta, Georgia",2021 IEEE 94th Vehicular Technology Conference (VTC2021-Fall),"10 Dec 2021","2021","","","1","6","Autonomous Driving has been continuously improving with the integration of bio-physiological data and deep learning systems. Passenger-driver behavior from psychological processes can provide insight into the trust levels of the dyad dynamic during an open-road drive. Measuring passenger trust can benefit in speeding up the adoption of self-driving cars. This area has not been fully explored from the passenger's point of view and can yield results that could potentially propel the progress of driver safety systems in autonomous driving. A novel approach to correlating the passenger-driver trust levels can be elicited from brain-based indicators that are extracted from time-locked electroencephalogram (EEG) signals that capture both sensory and cognitive processes. In this paper, we propose a trust identification technique utilizing evoked response potential (ERP) events such as P300 along with beta/alpha frequency ratios from specific passengers during braking, aggressive acceleration, and lane changing scenarios. The results obtained from the decomposition of these EEG signals into the frequency bands and application of machine learning techniques on data collected from frontal and parietal electrodes during these driving events prove the feasibility of this study. By examining additional passenger-driver pairs with varying social interaction and trust profiles in the future, we can strengthen the existence of a cognitive correlation between passenger-driver behavior and thus improve the efficiency of driver safety systems.","2577-2465","978-1-6654-1368-8","10.1109/VTC2021-Fall52928.2021.9625414","US DEVCOM Army Research Laboratory (ARL); Kennesaw State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9625414","P300;EEG;Spectral Analysis;Autonomy-Enabling Technology;ERP;Self-Driving Car;Vehicle-Passenger Behavior","Electrodes;Deep learning;Electric potential;Correlation;Psychology;Propulsion;Electroencephalography","","3","","19","IEEE","10 Dec 2021","","","IEEE","IEEE Conferences"
"Olfactory event-related potentials recordings analysis based on modified EEG registration system","R. Kotas; Z. Ciota","Department of Microelectronics and Computer Science, Lodz University of Technology, Lodz, Poland; Department of Microelectronics and Computer Science, Lodz University of Technology, Lodz, Poland",2014 Proceedings of the 21st International Conference Mixed Design of Integrated Circuits and Systems (MIXDES),"7 Aug 2014","2014","","","512","516","An external effect of the smelling process can be measured as olfactory evoked potentials (OEP). The amplitude of the potentials is in the range of single microvolts. Unfortunately, the precision of such potential measures is low, because of existing “body” noises. Additionally, other brain activities and even human emotion variations can distort the result. Therefore, further researches of electrical properties must be continued. Today's measurement methods of olfactory evoked potentials need several repetition cycles to obtain average values of the necessary potential. Because it is necessary to take into account olfactory weariness (attenuation), a repetition frequency is low and as a consequence, a patient survey is long (usually 20-30 min. using existing equipment).","","978-83-63578-05-3","10.1109/MIXDES.2014.6872253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6872253","event-related potentials (ERP);olfactory system diagnosis;brain activity;microprocessor","Olfactory;Electroencephalography;Electrodes;Electric potential;Diseases;Distortion measurement;Noise","","1","","11","","7 Aug 2014","","","IEEE","IEEE Conferences"
"Temporal Expectation Improves Recognition Memory for Spatially Attended Objects","A. Jones; E. V. Ward; E. L. Csiszer; J. Szymczak","Middlesex University, London, United Kingdom; Middlesex University, London, United Kingdom; Middlesex University, London, United Kingdom; Middlesex University, London, United Kingdom",Journal of Cognitive Neuroscience,"25 Oct 2022","2022","34","9","1616","1629","Recent evidence suggests that temporal expectation is beneficial to memory formation. Rhythmic presentation of stimuli during encoding enhances subsequent recognition and is associated with distinct neural activity compared with when stimuli are presented in an arrhythmic manner. However, no prior study has examined how temporal expectation interacts with another important form of facilitation—spatial attention—to affect memory. This study systematically manipulated temporal expectation and spatial attention during encoding to examine their combined effect on behavioral recognition and associated ERPs. Participants performed eight experimental blocks consisting of an encoding phase and recognition test, with EEG recorded throughout. During encoding, pairs of objects and checkerboards were presented and participants were cued to attend to the left or right stream and detect targets as quickly as possible. In four blocks, stimulus presentation followed a rhythmic (constant, predictable) temporal structure, and in the other four blocks, stimulus onset was arrhythmic (random, unpredictable). An interaction between temporal expectation and spatial attention emerged, with greater recognition in the rhythmic than the arrhythmic condition for spatially attended items. Analysis of memory-specific ERP components uncovered effects of spatial attention. There were late positive component and FN400 old/new effects in the attended condition for both rhythmic and arrhythmic items, whereas in the unattended condition, there was an FN400 old/new effect and no late positive component effect. The study provides new evidence that memory improvement as a function of temporal expectation is dependent upon spatial attention.","0898-929X","","10.1162/jocn_a_01872","Fundação Bial(grant numbers:111/18); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9927741","","","","","","","","25 Oct 2022","","","MIT Press","MIT Press Journals"
"Thinking in Emoticons: A Peek into the Future of Brain-Computer Interaction","M. N. Aslam; S. Jayanth; R. Patil","Dept. AI and DS, Nitte Meenakshi Institute of Technology, Bengaluru, India; Dept. AI and DS, Nitte Meenakshi Institute of Technology, Bengaluru, India; Dept. AI and DS, Nitte Meenakshi Institute of Technology, Bengaluru, India","2024 First International Conference on Software, Systems and Information Technology (SSITCON)","20 Dec 2024","2024","","","1","8","This paper presents an investigation into the application of Brain-Computer Interface (BCI) technology for emoji selection by analyzing electroencephalographic (EEG) signals. EEG data was captured to interpret neural activity, with a Support Vector Machine (SVM) classifier employed for accurate emoji recognition. The system demonstrated a classification accuracy of 93.28% while implementing advanced signal processing techniques that reduced noise and improved real-time performance. This research highlights the viability of thought-driven emoji selection and its implications for advancing accessible communication technologies and immersive virtual environments.","","979-8-3503-5293-1","10.1109/SSITCON62437.2024.10796399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10796399","Brain-Computer Interface (BCI);Electroencephalography (EEG);Support Vector Machine (SVM);Emoji Selection;Human-Computer Interaction","Support vector machines;Accuracy;Virtual environments;Signal processing algorithms;Software systems;Electroencephalography;Brain-computer interfaces;Real-time systems;Vectors;Emojis","","","","16","IEEE","20 Dec 2024","","","IEEE","IEEE Conferences"
"EEG source localization constrained by time varying fMRI","T. Nguyen; T. Potter; C. Karmonik; R. Grossman; Y. Zhang","Department of Biomedical Engineering, University of Houston, Houston, TX, USA; Department of Biomedical Engineering, University of Houston, Houston, TX, USA; Department of Neurosurgery, Houston Methodist Hospital, Houston, TX, USA; Department of Neurosurgery, Houston Methodist Hospital, Houston, TX, USA; Department of Biomedical Engineering, University of Houston, Houston, TX, USA",2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"5 Nov 2015","2015","","","630","633","A novel approach for Electroencephalogram (EEG) and functional Magnetic Resonance Imaging (fMRI) integration analysis was developed, specifically designed to explore the spatial and temporal details of the “sequential multi-event-related potential” type of neural activities. The approach utilizes the high temporal resolution nature of EEG to compute a current density mapping of the cortical activity, informed by the high spatial resolution fMRI in a time-variant, spatially selective manner. This method was implemented in the analysis of an EEG/fMRI study on motor activation in responses to a visual stimulus that evoked an emotional response. The processed windowed EEG signals were analyzed to select the temporally relevant partial fMRI mapping, which in turn was used to inform EEG source localization calculation. The results were compared against traditional fMRI-informed EEG approaches to demonstrate the spatiotemporal variant fMRI constraints feature as well as the performance of the developed method.","1558-4615","978-1-4244-9271-8","10.1109/EMBC.2015.7318441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318441","","Electroencephalography;Visualization;Covariance matrices;Imaging;Spatial resolution;Brain modeling;Sensors","Brain;Brain Mapping;Electroencephalography;Image Processing, Computer-Assisted;Magnetic Resonance Imaging","1","","9","IEEE","5 Nov 2015","","","IEEE","IEEE Conferences"
"Electroencephalogram (EEG) based authentication leveraging visual evoked potentials (VEP) resulting from exposure to emotionally significant images","R. J. Rodriguez","System Architecture Design, and Integration Directorate, Raytheon - Integrated Defense Systems, Sudbury, United States",2016 IEEE Symposium on Technologies for Homeland Security (HST),"15 Sep 2016","2016","","","1","6","Encephalogram (EEG) devices are one of the active research areas in human-computer interaction (HCI). They provide a unique brain-machine interface (BMI) for interacting with a growing number of applications. EEG devices interface with computational systems requiring access control. These controls rely on a number of authenticators, including “what you know”, “what you have”, and “what you are”. The “what you are” authenticator, formally known as a biometrics authenticator, is increasingly gaining acceptance. An emerging approach in physiological biometrics is cognitive biometrics, which measures brain's response to stimuli. These stimuli can be measured by a number of devices, including EEG systems. This work shows an approach to authenticate users interacting with their computational devices through the use of EEG devices. The results demonstrate the feasibility of using a unique hard-to-forge trait as an absolute biometrics authenticator by exploiting the signals generated by different areas of the brain when exposed to visual stimuli. The outcome of this research highlights the importance of the prefrontal cortex and temporal lobes to capture unique responses to images that trigger emotional responses. Additionally, the utilization of logarithmic band power processing combined with LDA as the machine learning algorithm provides higher accuracy when compared against common spatial patterns or windowed means processing in combination with GMM and SVM machine learning algorithms.","","978-1-5090-0770-7","10.1109/THS.2016.7568908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568908","Biometrics;EEG;BMI;Machine Learning;Visual Evoked Potential","Electroencephalography;Feature extraction;Iris recognition;Biological system modeling;Brain modeling;Access control","","6","","21","IEEE","15 Sep 2016","","","IEEE","IEEE Conferences"
"Effectiveness of flickering video clips as stimuli for SSVEP-based BCIs","Benzheng Li","Faculty of Science and Technology, University of Macau, Macau, SAR, China",TENCON 2015 - 2015 IEEE Region 10 Conference,"7 Jan 2016","2015","","","1","4","Flickering video clips can be used as stimuli in Steady state visual evoked potential (SSVEP)-based brain-computer interfaces (BCIs) with potentially high performance. This study aims to investigate the effectiveness of stimuli using various types of video clips with different emotional valences, scenes and actors' actions. Experimental result showed that flickering videos with affective contents can enhance the SSVEP response compared with neutral stimuli. Furthermore, pleasant stimuli and unpleasant stimuli have similar effects. More interestingly, among affective stimuli, flickering video made by close-up shot and moderate movement can provide the most enhancement on the SSVEP response.","2159-3450","978-1-4799-8641-5","10.1109/TENCON.2015.7373134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7373134","steady-state visual evoked potential;phase locking value;brain-computer interface;affective steady-state visual evoked potential","Crystals;Transient analysis;Chlorine","","","","10","IEEE","7 Jan 2016","","","IEEE","IEEE Conferences"
"Quantifying Cognitive State From EEG Using Dependence Measures","B. Fadlallah; S. Seth; A. Keil; J. Principe","Department of Electrical and Computer Engineering and Computational NeuroEngineering Laboratory, University of Florida, Gainesville, FL, USA; Department of Information and Computer Science, Aalto University, Aalto, Finland; Department of Psychology and NIMH Center for the Study of Emotion and Attention, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering and Computational NeuroEngineering Laboratory, University of Florida, Gainesville, FL, USA",IEEE Transactions on Biomedical Engineering,"14 Sep 2012","2012","59","10","2773","2781","The exquisite human ability to perceive facial features has been explained by the activity of neurons particularly responsive to faces, found in the fusiform gyrus and the anterior part of the superior temporal sulcus. This study hypothesizes and demonstrates that it is possible to automatically discriminate face processing from processing of a simple control stimulus based on processed EEGs in an online fashion with high temporal resolution using measures of statistical dependence applied on steady-state visual evoked potentials. Correlation, mutual information, and a novel measure of association, referred to as generalized measure of association (GMA), were applied on filtered current source density data. Dependences between channel locations were assessed for two separate conditions elicited by distinct pictures (a face and a Gabor grating) flickering at a rate of 17.5 Hz. Filter settings were chosen to minimize the distortion produced by bandpassing parameters on dependence estimation. Statistical analysis was performed for automated stimulus classification using the Kolmogorov-Smirnov test. Results show active regions in the occipito-parietal part of the brain for both conditions with a greater dependence between occipital and inferotemporal sites for the face stimulus. GMA achieved a higher performance in discriminating the two conditions. Because no additional face-like stimuli were examined, this study established a basic difference between one particular face and one nonface stimulus. Future work may use additional stimuli and experimental manipulations to determine the specificity of the current connectivity results.","1558-2531","","10.1109/TBME.2012.2210283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6248682","Brain connectivity;correlation;electroencephalogram (EEG);finite impulse response (FIR) least-square filter;generalized measure of association (GMA);mutual information (MI);steady-state visual evoked potential (ssVEP)","Correlation;Mutual information;Visualization;Electroencephalography;Q factor;Time series analysis","Algorithms;Brain Mapping;Cognition;Computer Simulation;Electroencephalography;Evoked Potentials, Visual;Humans;Male;Signal Processing, Computer-Assisted;Statistics, Nonparametric;Young Adult","22","","54","IEEE","25 Jul 2012","","","IEEE","IEEE Journals"
"The Possible Role of Insula and Default Mode Network in Schizophrenia During an Auditory Task: A Pilot EEG-fMRI Analysis","E. Bondi; F. L. Donati; A. M. Bianchi; F. M. Triulzi; Y. Torrente; A. D'Agostino; P. Brambilla; E. Maggioni","Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Health Sciences, University of Milan, Milan, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Neurordadiology Unit, Fondazione IRCCS Ca' Granda Maggiore Policlinico, Milan, Italy; Department of Neurosciences and Mental Health, Fondazione IRCCS Ca' Granda Maggiore Policlinico, Milan, Italy; Department of Mental Health and Addiction, ASST Santi Paolo e Carlo, Milan, Italy; Department of Pathophysiology and Transplantation, University of Milan, Milan, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy","2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)","24 Dec 2024","2024","","","395","399","The impairment of auditory perception in schizophrenic patients (SCZ), compared to healthy controls (HC), has been largely studied, identifying the N100 event-related potential as a possible biomarker for the discrimination between these two groups. However, the hemodynamic activity underlying this differential process is still not clear. In this context, the simultaneous combination of electroencephalography (EEG) and functional magnetic resonance imaging (fMRI) could unveil the hemodynamic correlates of neuronal events of interest, such as the N100, and inform on brain auditory processing with a higher spatial and temporal resolution than the single techniques. In this pilot work, we used EEG-driven fMRI and fMRI task-based connectivity analyses to investigate the neurovascular differences between two HCs and one SCZ during a three-tones auditory task. Although no differences were reported in terms of N100 amplitude, the EEG-driven fMRI analysis showed different N100 correlates between the two groups in the left insula, right prefrontal cortex, and precuneus. The different connectivity between participants and task conditions has been assessed using the left insula as seed for the generalized Psychophysiological Interactions (gPPI) model. The analysis showed generally lower connectivity for SCZ and alterations in regions included in the default mode and salience networks.","","979-8-3503-7800-9","10.1109/MetroXRAINE62247.2024.10796388","Italian Ministry of University and Research(grant numbers:2022RXM3H7); Italian Ministry of Health(grant numbers:GR-2018-12367290,PNC-E3-2022-23683266,C43C22001630001/MI-0117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10796388","simultaneous EEG-fMRI;schizophrenia;auditory;correlates","Somatosensory;Visualization;Temporal lobe;Functional magnetic resonance imaging;Schizophrenia;Brain modeling;Electroencephalography;Hemodynamics;Psychophysics;Spatial resolution","","","","26","IEEE","24 Dec 2024","","","IEEE","IEEE Conferences"
"Test-Retest Reliability of Time-Domain EEG Features to Assess Cognitive Load Using a Wireless Dry-Electrode System","O. Ortiz; D. Blustein; U. Kuruganti","Department of Kinesiology, University of New Brunswick, Fredericton, Canada; Department of Psychology, Rhodes College, Memphis, TN, USA; Marjorie McCain Human Performance Laboratory, Faculty of Kinesiology, University of New Brunswick, Fredericton, NB, Canada",2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"27 Aug 2020","2020","","","2885","2888","Human Machine Interfaces (HMIs) can provide critical support and improve daily task functionality for prosthesis users or social interaction for patients with locked-in syndrome using an assistive communication device. One goal in the development of sophisticated HMIs is to reduce the cognitive load (CL) they place on the user to promote the use of the technology. Electroencephalogram (EEG)-derived measures collected with wired wet-electrode systems have been used to assess CL in laboratory environments and have demonstrated acceptable test-retest reliability. Assessment of CL during real-world unconstrained HMI operation, however, requires the use of a wireless dry-electrode EEG system which provides easier electrode application and untethered movement. However, the test-retest reliability of wireless dry-electrode systems to quantify CL has not been explored. Ensuring the consistent capture of CL-related signals across multiple sessions is critical if these devices are to be used to assess how improvements in HMIs affect CL. Therefore, the current study used a wireless dry-electrode EEG system to compare Evoked Response Potential (ERP) features of a simple auditory oddball task to measure CL during two separate testing sessions a week apart. ERPs of 11 subjects were recorded while participants performed a virtual task at two difficulty levels. A significant correlation was found between the P300 component of the ERPs and subjective ratings of CL during both testing sessions. Furthermore, there was a statistically significant test-retest reliability for this same ERP feature and similar signal-to-noise ratios (SNRs) across sessions.Clinical Relevance- This is an initial step in validating wireless dry-electrode EEG systems to assess cognitive load across multiple sessions. The evidence presented is critical if dry-wireless EEG systems are to be used to identify aspects of HMIs that reduce CL in clinical and real-life environments. Assessing CL in unconstrained environments can better inform clinicians and technology developers in their design of future HMIs.","2694-0604","978-1-7281-1990-8","10.1109/EMBC44109.2020.9175762","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175762","","Electroencephalography;Task analysis;Feature extraction;Wireless communication;Reliability;Correlation;Electrodes","Cognition;Electrodes;Electroencephalography;Evoked Potentials;Humans;Reproducibility of Results","5","","21","IEEE","27 Aug 2020","","","IEEE","IEEE Conferences"
"Cybersickness-Provoking Virtual Reality Alters Brain Signals of Persons with Multiple Sclerosis","I. M. Arafat; S. M. Shahnewaz Ferdous; J. Quarles",University of Texas at San Antonio; University of Texas at San Antonio; University of Texas at San Antonio,2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),"30 Aug 2018","2018","","","1","120","This study investigates and compares brain signals between persons with and without Multiple Sclerosis (MS) when exposed to cybersickness-provoking Virtual Reality (VR). Cybersickness is a set of discomforts and commonly triggered by VR exposure. It has symptoms similar to motion sickness, such as dizziness, nausea, and disorientation etc. Although cybersickness has been studied for decades, populations with neurological disabilities, such as MS, have remained minimally studied. Cybersickness could have negative impact on effectiveness of VR-based rehabilitation systems and limit the accessibility of VR for persons with disabilities. MS can disrupt communication between neurons (signal carrying nerve cells) from different areas of the brain. Cybersickness also can affect brain signals, for example, frequency powers may change due to cybersickness. This study investigates the combination of MS and cybersickness in terms of brain signals. To investigate the effect of cybersickness on participants' brain signals, electroencephalogram (EEG) data were recorded before, during and after exposure to a cybersickness-provoking VR driving simulation. The EEG data suggests that in response to cybersickness-provoking VR exposure, participants with MS have mostly shown similar changes in brain activity with different magnitudes than participants without MS. Also, for at least one scalp location we have found completely opposite brain signals in MS-Group when compared to Non-MS-Group. Difference in magnitude or completely different trend in brain signals can imply that cybersickness affects persons with MS differently than persons without MS and may be different cybersickness reduction techniques are required for different populations.","","978-1-5386-3365-6","10.1109/VR.2018.8446194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446194","Cybersickness;Multiple Sclerosis (MS);VR;VE;Electroencephalogram (EEG);ERSP;ERP;User studies and evaluation;Ethical issues in VR.: Social and professional topics-User characteristics-People with disabilities;Human-centered computing-Human computer interaction (HCI)-HCI design and evaluation methods-User studies","Electroencephalography;Brain modeling;Neurons;Multiple sclerosis;Task analysis;Automobiles;Virtual reality","","21","","38","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Affective response to volitional input perturbations in obstacle avoidance and target tracking games","A. N. Patel; G. Chau; C. Chang; A. Sun; J. Huang; T. -P. Jung; V. Gilja","Department of Electrical and Computer Engineering, University of California, San Diego La Jolla, CA; Department of Electrical and Computer Engineering, University of California, San Diego La Jolla, CA; Department of Cognitive Science, University of California, San Diego, La Jolla, CA; Department of Electrical and Computer Engineering, University of California, San Diego La Jolla, CA; Department of Electrical and Computer Engineering, University of California, San Diego La Jolla, CA; Institute for Neural Computation, University of California, San Diego, La Jolla, CA; Department of Electrical and Computer Engineering, University of California, San Diego La Jolla, CA",2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"9 Dec 2021","2021","","","6679","6682","We present the use of two game-like tasks, Catnip and Dinorun, to explore affective responses to volitional control perturbations. We analyze behavioral and physiological measures with the self-assessment manikin (SAM), pupillometry, and electroencephalography (EEG) responses to provide intratrial emotional state as well as inter-trial correlates with selfreported survey responses. We find that subject gameplay characteristics significantly correlate with valence and dominance scores for both games, and that perturbations to the games produce a measurable decrease in response scores for Dinorun. During perturbation events, pupillometry analysis reveals considerable SAM-agnostic dilation, with stronger responses in more rigid trialized event structures. Furthermore, analyses of neural activity from central and parietal regions demonstrate significant measurable evoked responses to perturbed events across the majority of subjects for both games. By introducing perturbations, this set of experiments and analyses inform and enable further studies of affective responses to the loss of volitional control during engaging, game-like tasks.","2694-0604","978-1-7281-1179-7","10.1109/EMBC46164.2021.9630523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630523","","Target tracking;Perturbation methods;Neural activity;Games;Electroencephalography;Physiology;Task analysis","Electroencephalography;Emotions;Humans;Volition","","","14","IEEE","9 Dec 2021","","","IEEE","IEEE Conferences"
"A Human-Centric Metaverse Enabled by Brain-Computer Interface: A Survey","H. Y. Zhu; N. Q. Hieu; D. T. Hoang; D. N. Nguyen; C. -T. Lin","School of Computer Science, University of Technology Sydney, Sydney, NSW, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Sydney, NSW, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Sydney, NSW, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Sydney, NSW, Australia; CIBCI Lab, Human-centric AI Centre, Australian AI Institute, Faculty of Engineering and IT, University of Technology Sydney, Ultimo, NSW, Australia",IEEE Communications Surveys & Tutorials,"22 Aug 2024","2024","26","3","2120","2145","The growing interest in the Metaverse has generated momentum for members of academia and industry to innovate toward realizing the Metaverse world. The Metaverse is a unique, continuous, and shared virtual world where humans embody a digital form within an online platform. Through a digital avatar, Metaverse users should have a perceptual presence within the environment and can interact and control the virtual world around them. Thus, a human-centric design is a crucial element of the Metaverse. The human users are not only the central entity but also the source of multi-sensory data that can be used to enrich the Metaverse ecosystem. In this survey, we study the potential applications of Brain-Computer Interface (BCI) technologies that can enhance the experience of Metaverse users. By directly communicating with the human brain, the most complex organ in the human body, BCI technologies hold the potential for the most intuitive human-machine system operating at the speed of thought. BCI technologies can enable various innovative applications for the Metaverse through this neural pathway, such as user cognitive state monitoring, digital avatar control, virtual interactions, and imagined speech communications. This survey first outlines the fundamental background of the Metaverse and BCI technologies. We then discuss the current challenges of the Metaverse that can potentially be addressed by BCI, such as motion sickness when users experience virtual environments or the negative emotional states of users in immersive virtual applications. After that, we propose and discuss a new research direction called Human Digital Twin, in which digital twins can create an intelligent and interactable avatar from the user’s brain signals. We also present the challenges and potential solutions in synchronizing and communicating between virtual and physical entities in the Metaverse. Finally, we highlight the challenges, open issues, and future research directions for BCI-enabled Metaverse systems.","1553-877X","","10.1109/COMST.2024.3387124","Australian Research Council through the DECRA Project(grant numbers:DE210100651); Australian Research Council (ARC) under Discovery(grant numbers:DP210101093,DP220100803); Australian National Health and Medical Research Council (NHMRC) Ideas Grant(grant numbers:APP2021183); UTS Human-Centric AI Centre(grant numbers:(2023–2031)); Australia Defence Innovation Hub(grant numbers:P18-650825); Australian Cooperative Research Centres Projects (CRC-P) Round 11(grant numbers:CRCPXI000007); Lockheed Martin Corporation under Cooperative(grant numbers:4038); U.S. Office of Naval Research Global under Cooperative Agreement ONRG - NICOP - N62909-19-1-2058; AFOSR – DST Australian Autonomy Initiative Agreement(grant numbers:ID10134); NSW Defence Innovation Network and the NSW State Government of Australia for Financial Support in part of this Research(grant numbers:DINPP2019 S1-03/09,PP21-22.03.02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10496440","Metaverse;brain-computer interface;human digital twin;non-invasive BCI;computer vision;AI;IoT;sensors;VR;machine learning","Metaverse;Sensors;Surveys;Robot sensing systems;Avatars;Temperature sensors;Tutorials","","11","","219","CCBYNCND","10 Apr 2024","","","IEEE","IEEE Journals"
"Characteristics of High-Frequency SSVEPs Evoked by Visual Stimuli at Different Polar Angles","G. Ming; Y. Wang; W. Pei; H. Chen","State Key Laboratory on Integrated Optoelectronics, Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China; State Key Laboratory on Integrated Optoelectronics, Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China; State Key Laboratory on Integrated Optoelectronics, Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China; State Key Laboratory on Integrated Optoelectronics, Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China",2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"27 Aug 2020","2020","","","3031","3034","The mapping of visual space onto human striate cortex allows the location of stimuli to affect the scalp distributions of electroencephalogram (EEG). To clarify the relationship between the characteristics of elicited high-frequency steady-state visual evoked potentials (SSVEPs) and the polar angle of stimulus, this study divided the annulus into eight symmetrical annular sectors (i.e., octants) as separate visual stimuli. For both 30 Hz and 60 Hz, the response intensity and classification accuracy indicated that the annular sectors in the lower visual field evoked stronger responses than those in the upper visual field. This paper also evaluated the phase differences between SSVEPs at specific polar angles and found clear individual differences across subjects. These findings may lead to inspirations for the design of new space coding methods for the SSVEP-based brain-computer interfaces (BCIs).","2694-0604","978-1-7281-1990-8","10.1109/EMBC44109.2020.9175498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175498","","Visualization;Signal to noise ratio;Electrodes;Retina;Electroencephalography;Spatial filters;Bars","Brain-Computer Interfaces;Electroencephalography;Evoked Potentials, Visual;Humans;Photic Stimulation;Visual Cortex","3","","11","IEEE","27 Aug 2020","","","IEEE","IEEE Conferences"
"Initial assessment of artifact filtering for RSVP Keyboard™","M. Haghighi; M. Akcakaya; U. Orhan; D. Erdogmus; B. Oken; M. Fried-Oken","Department of Electrical and Computer Engineering, Northeastern University, Boston, Massachusetts; Department of Electrical and Computer Engineering, Northeastern University, Boston, Massachusetts; Department of Electrical and Computer Engineering, Northeastern University, Boston, Massachusetts; Department of Electrical and Computer Engineering, Northeastern University, Boston, Massachusetts; Oregon Health and Science University, Portland, Oregon; Oregon Health and Science University, Portland, Oregon",2013 IEEE Signal Processing in Medicine and Biology Symposium (SPMB),"13 Feb 2014","2013","","","1","5","RSVP Keyboard™ is an electroencephalography (EEG)-based spelling interface that uses evoked response potential classification with the help of language models. As in any brain computer interface, severe physiological and environmental signal artifacts that affect signal quality in EEG are a detriment to performance. To alleviate the negative effects of such artifacts on RSVP Keyboard™, we implemented a filter that is based on an existing methodology from the literature. Using statistical modeling of pre-recorded EEG that includes three types of artifacts intentionally generated by operators, we perform Monte Carlo simulations of copy-phrase tasks and analyze the effect of artifact filtering on estimated typing performance. The presented results demonstrate an evidence against the usability of the tested method for online artifact reduction applications.","","978-1-4799-3007-4","10.1109/SPMB.2013.6736777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6736777","EEG;ERP;Language Model;Kernel Density Estimate;Artifact Filtering;Independent Component Analysis","Electroencephalography;Brain models;Accuracy;Feature extraction;Interpolation;Computational modeling","","1","","16","IEEE","13 Feb 2014","","","IEEE","IEEE Conferences"
"Effects of feedback latency on P300-based brain-computer interface","M. Arvaneh; T. E. Ward; I. H. Robertson","Trinity College Institute of Neuroscience, Insight Centre for Data Analytics, Dublin, Ireland; Dept. of Electronic Engineering, National University of Ireland, Maynooth, Ireland; Trinity College Institute of Neuroscience, Insight Centre for Data Analytics, Dublin, Ireland",2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"5 Nov 2015","2015","","","2315","2318","Feedback has been shown to affect performance when using a Brain-Computer Interface (BCI) based on sensorimotor rhythms. In contrast, little is known about the influence of feedback on P300-based BCIs. There is still an open question whether feedback affects the regulation of P300 and consequently the operation of P300-based BCIs. In this paper, for the first time, the influence of feedback on the P300-based BCI speller task is systematically assessed. For this purpose, 24 healthy participants performed the classic P300-based BCI speller task, while only half of them received feedback. Importantly, the number of flashes per letter was reduced on a regular basis in order to increase the frequency of providing feedback. Experimental results showed that feedback could significantly improve the P300-based BCI speller performance, if it was provided in short time intervals (e.g. in sequences as short as 4 to 6 flashes per row/column). Moreover, our offline analysis showed that providing feedback remarkably enhanced the relevant ERP patterns and attenuated the irrelevant ERP patterns, such that the discrimination between target and non-target EEG trials increased.","1558-4615","978-1-4244-9271-8","10.1109/EMBC.2015.7318856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7318856","","Ash;Electroencephalography;Training;Signal to noise ratio;Brain-computer interfaces;Accuracy;Calibration","Adolescent;Adult;Brain-Computer Interfaces;Calibration;Electroencephalography;Event-Related Potentials, P300;Feedback;Female;Humans;Male;Signal-To-Noise Ratio;Surveys and Questionnaires;Task Performance and Analysis;Young Adult","1","","15","IEEE","5 Nov 2015","","","IEEE","IEEE Conferences"
"The Mindful Brain: A Systematic Review of the Neural Correlates of Trait Mindfulness","I. N. Treves; K. Pichappan; J. Hammoud; C. C. C. Bauer; S. Ehmann; M. D. Sacchet; J. D. E. Gabrieli","Massachusetts Institute of Technology; Massachusetts Institute of Technology; Center for Precision Psychiatry, Department of Psychiatry, Massachusetts General Hospital, Boston, MA; Massachusetts Institute of Technology; West Chester University of Pennsylvania; West Chester University of Pennsylvania; Massachusetts Institute of Technology",Journal of Cognitive Neuroscience,"29 Oct 2024","2024","36","11","2518","2555","Trait self-report mindfulness scales measure one's disposition to pay nonjudgmental attention to the present moment. Concerns have been raised about the validity of trait mindfulness scales. Despite this, there is extensive literature correlating mindfulness scales with objective brain measures, with the goal of providing insight into mechanisms of mindfulness, and insight into associated positive mental health outcomes. Here, we systematically examined the neural correlates of trait mindfulness. We assessed 68 correlational studies across structural magnetic resonance imaging, task-based fMRI, resting-state fMRI, and EEG. Several consistent findings were identified, associating greater trait mindfulness with decreased amygdala reactivity to emotional stimuli, increased cortical thickness in frontal regions and insular cortex regions, and decreased connectivity within the default-mode network. These findings converged with results from intervention studies and those that included mindfulness experts. On the other hand, the connections between trait mindfulness and EEG metrics remain inconclusive, as do the associations between trait mindfulness and between-network resting-state fMRI metrics. ERP measures from EEG used to measure attentional or emotional processing may not show reliable individual variation. Research on body awareness and self-relevant processing is scarce. For a more robust correlational neuroscience of trait mindfulness, we recommend larger sample sizes, data-driven, multivariate approaches to self-report and brain measures, and careful consideration of test–retest reliability. In addition, we should leave behind simplistic explanations of mindfulness, as there are many ways to be mindful, and leave behind simplistic explanations of the brain, as distributed networks of brain areas support mindfulness.","0898-929X","","10.1162/jocn_a_02230","Tan-Yang Center at Massachusetts Institute of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10738334","","","","","","","CCBY","29 Oct 2024","","","MIT Press","MIT Press Journals"
"Somatosensory-evoked potentials and cortical activities evoked by magnetic stimulation on acupoint in human","H. Yu; G. Xu; R. Yang; S. Yang; Y. Geng; Y. Chen; W. Li; H. Sun","Province-Ministry Joint Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability, Hebei University of Technology, Tianjin, China; Province-Ministry Joint Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability, Hebei University of Technology, Tianjin, China; Province-Ministry Joint Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability, Hebei University of Technology, Tianjin, China; Province-Ministry Joint Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability, Hebei University of Technology, Tianjin, China; Province-Ministry Joint Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability, Hebei University of Technology, Tianjin, China; Province-Ministry Joint Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability, Hebei University of Technology, Tianjin, China; Province-Ministry Joint Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability, Hebei University of Technology, Tianjin, China; Province-Ministry Joint Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability, Hebei University of Technology, Tianjin, China",2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society,"13 Nov 2009","2009","","","3445","3448","Two acupuncture manipulations are clinically used: manual manipulation and electrical acupuncture. There is little published on the EEG changes during magnetic stimulation on an acupuncture site. In this study, EEG data in response to magnetic stimulation on HeGu (LI 4) acupoint were measured to determine whether magnetic acupoint stimulation might modulate ongoing EEG or not. Eighteen healthy volunteers (13 male, 5 female) 20 to 35 years old were chosen in this experiment, with consent obtained before the study. The highest evoked potential was recorded in FCZ electrode, at about 140-170ms (P150) after acupoint stimulation, but not mock point stimulation. Comparison of the somatosensory-evoked potentials in response to acupoint stimulation and mock point stimulation showed that P150 was specific to acupoint stimulation. With regard to the location of P150 in the human brain, we suggest that magnetic stimulation on HeGu acupoint would affect specific brain areas compared with the mock point. The difference in the anatomical structure of acupoint and non-acupoint may explain the specific acupoint-brain correlation, and P150 may be a characteristic activation in response to acupoint afferent.","1558-4615","978-1-4244-3296-7","10.1109/IEMBS.2009.5334641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5334641","","Magnetic stimulation;Humans;Electroencephalography;Pain;Electromagnetic fields;Magnetic modulators;Brain;Psychology;Needles;USA Councils","Acupuncture;Adult;Brain;Brain Mapping;Brain Mapping;Cerebral Cortex;Computer Simulation;Electrodes;Electroencephalography;Evoked Potentials, Somatosensory;Female;Hand;Humans;Magnetics;Male;Middle Aged;Software","1","","14","IEEE","13 Nov 2009","","","IEEE","IEEE Conferences"
"Design and Implementation of a P300-Based Brain-Computer Interface for Controlling an Internet Browser","E. M. Mugler; C. A. Ruf; S. Halder; M. Bensch; A. Kubler","Bioengineering Department, University of Illinois, Chicago, Chicago, IL, USA; Institute of Medical Psychology and Behavioral Neurobiology, University of Tübingen, Tubingen, Germany; Institute of Medical Psychology and Behavioral Neurobiology, University of Tübingen, Tubingen, Germany; Department of Computer Engineering, University of Tübingen, Tubingen, Germany; Department of Psychology I: Biological Psychology, Clinical Psychology and Psychotherapy, University of Würzburg, Wurzburg, Germany",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"6 Dec 2010","2010","18","6","599","609","An electroencephalographic (EEG) brain-computer interface (BCI) internet browser was designed and evaluated with 10 healthy volunteers and three individuals with advanced amyotrophic lateral sclerosis (ALS), all of whom were given tasks to execute on the internet using the browser. Participants with ALS achieved an average accuracy of 73% and a subsequent information transfer rate (ITR) of 8.6 bits/min and healthy participants with no prior BCI experience over 90% accuracy and an ITR of 14.4 bits/min. We define additional criteria for unrestricted internet access for evaluation of the presented and future internet browsers, and we provide a review of the existing browsers in the literature. The P300-based browser provides unrestricted access and enables free web surfing for individuals with paralysis.","1558-0210","","10.1109/TNSRE.2010.2068059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559475","Brain–computer interface (BCI);electroencephalography;rehabilitation","Browsers;Internet;Brain computer interfaces;Electroencephalography;Patient rehabilitation","Adult;Affect;Algorithms;Amyotrophic Lateral Sclerosis;Brain;Data Interpretation, Statistical;Depression;Disease Progression;Electroencephalography;Equipment Design;Event-Related Potentials, P300;Female;Humans;Information Systems;Internet;Male;Middle Aged;Motivation;Paralysis;Paralysis;Quality of Life;User-Computer Interface;Young Adult","135","","48","IEEE","30 Aug 2010","","","IEEE","IEEE Journals"
"Neural Correlates of Subjective Awareness and Unconscious Processing: An ERP Study","D. Lamy; M. Salti; Y. Bar-Haim",NA; NA; NA,Journal of Cognitive Neuroscience,"19 May 2014","2009","21","7","1435","1446","The aim of the present study was to dissociate the ERP (Event Related Potentials) correlates of subjective awareness from those of unconscious perception. In a backward masking paradigm, participants first produced a forced-choice response to the location of a liminal target presented for an individually calibrated duration, and then reported on their subjective awareness of the target's presence. We recorded (Event-Related Potentials) ERPs and compared the ERP waves when observers reported being aware vs. unaware of the target but localized it correctly, thereby isolating the neural correlates of subjective awareness while controlling for differences in objective performance. In addition, we compared the ERPs when participants were subjectively unaware of the target's presence and localized it correctly versus incorrectly, thereby isolating the neural correlates of unconscious perception. All conditions involved stimuli that were physically identical and were presented for the same duration. Both behavioral measures were associated with modulation of the amplitude of the P3 component of the ERP. Importantly, this modulation was widely spread across all scalp locations for subjective awareness, but was restricted to the parietal electrodes for unconscious perception. These results indicate that liminal stimuli that do not affect performance undergo considerable processing and that subjective awareness is associated with a late wave of activation with widely distributed topography.","0898-929X","","10.1162/jocn.2009.21064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6793625","","","","1","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Combing Multiple Visual Stimuli to Enhance the Performance of VEP-Based Biometrics","H. Qu; H. Zhao; Q. Wei; W. Pei; X. Gao; Y. Wang","Department of Electronic Engineering, Nanchang University, Nanchang, China; Department of Biomedical Engineering, School of Biomedical Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Nanchang University, Nanchang, China; Key Laboratory of Solid-State Optoelectronics Information Technology, Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China; Department of Biomedical Engineering, School of Biomedical Engineering, Tsinghua University, Beijing, China; Key Laboratory of Solid-State Optoelectronics Information Technology, Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Information Forensics and Security,"9 Sep 2024","2024","19","","7982","7993","In recent years, electroencephalography (EEG) has received increasing attention in the field of biometrics because of its unique advantages such as covertness, resistance to spoofing, sensitivity to emotional and mental states, and continuous nature. Visual evoked potentials (VEPs) have been widely used in EEG-based biometrics owing to fast recognition speed and high accuracy. This study proposes a new method to combine multiple visual stimuli for VEP-based individual identification. Correct recognition rate (CRR) was estimated using steady-state VEPs (ss-VEPs), and code modulated VEPs (c-VEPs) recorded from a group of 35 subjects. c-VEPs achieved a 100% CRR using 3.1-s of VEP data (a 10.8-s duration, including 7.7-s intervals) in the cross-session condition. An online system based on the combination of stimuli optimized from the data of 35 subjects was further developed and validated with an additional group of 22 subjects. A cross-session CRR of 99.55% was achieved using the same parameters. These results indicate that the proposed VEP-based individual identification method using multiple visual stimuli shows great potential for practical applications.","1556-6021","","10.1109/TIFS.2024.3452628","National Key Research and Development Program of China(grant numbers:2022YFF1202303); National Natural Science Foundation of China(grant numbers:62066028,62071447); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10659912","Biometrics;electroencephalography;person identification;visual evoked potentials;cross-session performance","Electroencephalography;Biometrics;Visualization;Identification of persons;Classification algorithms;Authentication;Feature extraction","","1","","45","IEEE","30 Aug 2024","","","IEEE","IEEE Journals"
"Assessment of musical training induced neuroplasticity by auditory event related potentials and neural networks","S. -F. Liang; C. -S. Liu; W. -L. Chang; Y. -H. Tsao; L. -W. Ko; C. -T. Lin","Department of Computer Science and Information Engineering, the Institute of Medical Informatics, National Cheng Kung University, Tainan County, Taiwan; Department of Computer Science and Information Engineering, the Institute of Medical Informatics, National Cheng Kung University, Tainan County, Taiwan; Department of Computer Science and Information Engineering, the Institute of Medical Informatics, National Cheng Kung University, Tainan County, Taiwan; Department of Computer Science and Information Engineering, the Institute of Medical Informatics, National Cheng Kung University, Tainan County, Taiwan; Brain Research Center, National Chiao Tung University, Hsinchu, Taiwan; Brain Research Center, National Chiao Tung University, Hsinchu, Taiwan",2009 International Joint Conference on Neural Networks,"31 Jul 2009","2009","","","1797","1801","Music provides a tool to study numerous aspects of neuroscience from motion-skill to emotion since listening to and producing music involves many brain functions. The musician's brain is also regarded as an ideal model to investigate plasticity of the human brain. In this paper, an EEG-based neural network is proposed to assess neuroplasticity induced by musical training. A musical chord perception experiment is designed to acquire and compare the behavioral and neural responses of musicians and non-musicians. The ERPs elicited by the consonant and dissonant chords are combined together as the features of the model. The principle component analysis (PCA) is used to reduce feature dimensions and the dimension-reduced features are input to a feedforward neural network to recognize the brain potentials belong to a musician or a non-musician. The accuracy can reach 97% in average for leave-one-out cross validation of six subjects in this experiment. It demonstrates the feasibility of assessing effects of musical training by ERP signals elicited by musical chord perception.","2161-4407","978-1-4244-3548-7","10.1109/IJCNN.2009.5179029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5179029","","Neuroplasticity;Neural networks;Biological neural networks;Music;Brain modeling;Enterprise resource planning;Neuroscience;Humans;Principal component analysis;Feedforward neural networks","","2","","16","IEEE","31 Jul 2009","","","IEEE","IEEE Conferences"
"A Novel Fast ICA-FBCCA Algorithm and Convolutional Neural Network for Single-Flicker SSVEP-Based BCIs","S. N. Aghili; S. Kilani; E. Rouhani; A. Akhavan","Department of Electrical and Computer Engineering, Iran University of Science and Technology, Tehran, Iran; Department of Electrical and Computer Engineering, Iran University of Science and Technology, Tehran, Iran; Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran; Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran",IEEE Access,"3 Jan 2024","2024","12","","630","642","Brain-computer interface (BCI) systems have been developed to assist individuals with neuromuscular disorders to communicate with their surroundings using their brain signals. One attractive branch of BCI is steady-state visual evoked potential (SSVEP), which has acceptable speed and accuracy and is non-invasive. However, SSVEP-based EEG signals suffer from eye-fatigue problems, resulting in artifacts that affect the accuracy of the system. Thus, researchers are still working to improve SSVEP-based BCI systems. This paper proposes robust machine-learning algorithm for single-flicker SSVEP detection. A novel approach based on fast independent component analysis and filter-bank canonical correlation analysis (fast ICA-FBCCA) is developed to extract features from the single-flicker SSVEP signal. The clean features learned by fast ICA-FBCCA are then applied to a discrete wavelet transform (DWT) technique and fed to a convolutional neural network (CNN) with only one convolutional layer and a smaller number of parameters. The effectiveness of the proposed technique is evaluated using two datasets. The results were evaluated using two datasets. The findings clearly demonstrate that the proposed method outperforms traditional methods, with average target recognition accuracy and standard deviation values of 97 ± 3.1% among 6 subjects for dataset 1 and 82.12 ± 10.7% among 12 subjects for dataset 2. Overall, these findings suggest that the proposed method is a promising approach for improving the accuracy and reliability of the single-flicker SSVEP-based BCI systems.","2169-3536","","10.1109/ACCESS.2023.3347336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10374086","Brain–computer interface (BCI);single-flicker steady-state visual evoked potential;fast independent component analysis (fast ICA);filter-bank canonical correlation analysis (FBCCA);convolutional neural network (CNN)","Feature extraction;Electroencephalography;Visualization;Convolutional neural networks;Discrete wavelet transforms;Electromyography;Guidelines","","","","78","CCBYNCND","25 Dec 2023","","","IEEE","IEEE Journals"
"Design a soft assistive device for elbow movement training in peripheral nerve injuries","K. Tripanpitak; T. V. J. Tarvainen; I. Sönmezisik; J. Wu; W. Yu","Department of Medical Engineering, Chiba University, Chiba, Japan; Chiba Daigaku, Chiba, Chiba, JP; Department of Medical Engineering, Chiba University, Chiba, Japan; Department of Medical Engineering, Chiba University, Chiba, Japan; Department of Medical Engineering, Chiba University, Chiba, Japan",2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),"26 Mar 2018","2017","","","544","548","In recent years, robotic assistive devices have been widely used to improve the rehabilitation outcome of upper limb disability. Meanwhile in the peripheral nerve injuries disability, the brachial plexus injury (BPI) incidence has increased in developing countries which affects the quality of life for patients due to pain during insufficient arm movement of the patients who go under operative or conservative treatment. Pain will not stop the rehabilitation processes, but may lower the motivation of training. Our ultimate goal is to design a soft assistive device for elbow by developing wearable exoskeleton for promoting restoration of motor function with minimal pain. Pneumatic artificial muscles (PAMs) were applied to our prototype due to the properties which provide high power to weight ratio, light weight and simplicity to install. These actuators were regulated by a controller to perform elbow movements in flexion-extension, and pronation-supination. Furthermore, our work system also measured electromyography (EMG) and pain-related evoked potential (PREP) as estimation of user intended motion and pain feedback control, respectively. We use stimulation device with surface electrode which induced pinprick-like sensation to activate nociceptive fibers and recorded electroencephalography (EEG) on the scalp for measurement of pain during applied device with human arm. Therefore, this 2 degree of freedoms (DoF) assistive device can improve elbow movement while affect the least pain to the wearer.","","978-1-5386-3742-5","10.1109/ROBIO.2017.8324473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8324473","assistive device;elbow movement;brachial plexus injury (BPI);pneumatic artificial muscle (PAM);pain-related evoked potential (PREP)","Elbow;Prototypes;Pain;Muscles;Sockets;Assistive devices;Electromyography","","6","","17","IEEE","26 Mar 2018","","","IEEE","IEEE Conferences"
"The Impact of Linguistic Prediction Violations on Downstream Recognition Memory and Sentence Recall","R. J. Hubbard; K. D. Federmeier",University of Illinois Urbana–Champaign; University of Illinois Urbana–Champaign,Journal of Cognitive Neuroscience,"28 Feb 2024","2024","36","1","1","23","Predicting upcoming words during language comprehension not only affects processing in the moment but also has consequences for memory, although the source of these memory effects (e.g., whether driven by lingering pre-activations, re-analysis following prediction violations, or other mechanisms) remains underspecified. Here, we investigated downstream impacts of prediction on memory in two experiments. First, we recorded EEG as participants read strongly and weakly constraining sentences with expected, unexpected but plausible, or semantically anomalous endings (“He made a holster for his gun / father / train”) and were tested on their recognition memory for the sentence endings. Participants showed similar rates of false alarms for predicted but never presented sentence endings whether the prediction violation was plausible or anomalous, suggesting that these arise from pre-activation of the expected words during reading. During sentence reading, especially in strongly constraining sentences, plausible prediction violations elicited an anterior positivity; anomalous endings instead elicited a posterior positivity, whose amplitude was predictive of later memory for those anomalous words. ERP patterns at the time of recognition differentiated plausible and anomalous sentence endings: Words that had been plausible prediction violations elicited enhanced late positive complex amplitudes, suggesting greater episodic recollection, whereas anomalous sentence endings elicited greater N1 amplitudes, suggesting attentional tagging. In a follow-up behavioral study, a separate group of participants read the same sentence stimuli and were tested for sentence-level recall. We found that recall of full sentences was impaired when sentences ended with a prediction violation. Taken together, the results suggest that prediction violations draw attention and affect encoding of the violating word, in a manner that depends on plausibility, and that this, in turn, may impair future memory of the gist of the sentence.","0898-929X","","10.1162/jocn_a_02078","National Institute of Aging(grant numbers:R01AG026308); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10453538","","","","","","","","28 Feb 2024","","","MIT Press","MIT Press Journals"
"Stimulus Design for Visual Evoked Potential Based Brain-Computer Interfaces","H. Xu; S. -H. Hsu; M. Nakanishi; Y. Lin; T. -P. Jung; G. Cauwenberghs","Swartz Center of Computational Neuroscience, Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA; Swartz Center of Computational Neuroscience, Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA; Swartz Center of Computational Neuroscience, Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA; Swartz Center of Computational Neuroscience, Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA; Department of Bioengineering, Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA; Department of Bioengineering, Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"6 Jun 2023","2023","31","","2545","2551","Visual stimuli design plays an important role in brain-computer interfaces (BCIs) based on visual evoked potentials (VEPs). Variations in stimulus parameters have been shown to affect both decoding accuracy and subjective perception experience, implying the need for a trade-off in design. In this study, we comprehensively and systematically compared various combinations of amplitude contrast and spectral content parameters in the stimulus design to quantify their impact on decoding performance and subject comfort. Specifically, three parameters were investigated: 1) contrast level, 2) temporal pattern (periodic steady-state or pseudo-random code-modulated), and 3) frequency range. We collected electroencephalogram (EEG) data and subjective perception ratings from ten subjects and evaluated the decoding accuracy and subject comfort rating for different combinations of the stimulus parameters. Our results indicate that while high-frequency steady-state VEP (SSVEP) stimuli were rated the most comfortable, they also had the lowest decoding accuracy. Conversely, low-frequency SSVEP stimuli were rated the least comfortable but had the highest decoding accuracy. Standard and high-frequency M-sequence code-modulated VEPs (c-VEPs) produced intermediates between the two. We observed a consistent trade-off relationship between decoding accuracy and subjective comfort level across all parameters. Based on our findings, we offer c-VEP as a preferable stimulus for achieving reliable decoding accuracy while maintaining a reasonable level of comfortability.","1558-0210","","10.1109/TNSRE.2023.3280081","National Science Foundation(grant numbers:IIP-1719130); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10142244","Brain-computer interfaces;electroencephalography;m-sequence;stimulus design;visual evoked potentials","Visualization;Decoding;Frequency modulation;Steady-state;Monitoring;Electroencephalography;Binary codes","Humans;Evoked Potentials, Visual;Brain-Computer Interfaces;Photic Stimulation;Electroencephalography;Neurologic Examination;Algorithms","3","","28","CCBY","1 Jun 2023","","","IEEE","IEEE Journals"
"A Shared Control Framework for Human-Multirobot Foraging With Brain-Computer Interface","W. Dai; Y. Liu; H. Lu; Z. Zheng; Z. Zhou","College of Intelligence Science and Technology, National University of Defense Technology, Changsha, Hunan, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, Hunan, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, Hunan, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, Hunan, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, Hunan, China",IEEE Robotics and Automation Letters,"19 Jul 2021","2021","6","4","6305","6312","With the rapid development of multi-robot systems (MRSs), they can be widely used to perform various tasks in typical environments. However, the inevitable disadvantages of onboard sensor errors, communication delays, and underspecified environmental factors seriously affect the operation of MRSs. Therefore, this letter considers a shared control framework suitable for human-multirobot foraging with a brain-computer interface (BCI) as a means of allowing a human operator to express opinions, permitting the robots to rely on human experience and knowledge to improve cooperation. An opinion dynamics model is used to find the consensus opinion of the MRS, which, however, is likely not accurate due to the biased nature of the available environmental information. When the human operator learns the opinion of the robots, he/she can then either accept it or reject it and express his/her own opinion via the BCI. Of course, this human judgment may also be incorrect, or the BCI may suffer from false detections. Thus, the MRS does not directly follow the human operator's opinion; instead, it is added to the opinion dynamics model as a new node to generate the final consensus opinion. Extensive simulation results show that the proposed framework can markedly improve the efficiency of foraging compared with robot-only or human-only performance and traditional human-robot interaction methods.","2377-3766","","10.1109/LRA.2021.3092290","National Natural Science Foundation of China(grant numbers:U1913202,U1813205); Hunan Provincial Innovation Foundation For Postgraduate(grant numbers:CX2018B010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9464651","Multi-robot systems;brain-machine interfaces;human-robot collaboration","Robots;Task analysis;Robot sensing systems;Drones;Collaboration;Brain-computer interfaces;Input devices","","8","","25","IEEE","24 Jun 2021","","","IEEE","IEEE Journals"
"Neuroscience of virtual reality","K. Sharma; H. S. Aswal; R. Chauhan; R. Rawat; R. Gupta","Computer Science and Engineering, Graphic Era Hill University, Dehradun, Uttarakhand, India; Computer Science and Engineering, Graphic Era Hill University, Dehradun, Uttarakhand, India; Computer Science and Engineering, Graphic Era Hill University, Dehradun, Uttarakhand, India; Computer Science and Engineering, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India; Chitkara University Institute of Engineering and Tech, Chitkara University, Punjab, India","2024 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)","20 Mar 2024","2024","","","1","6","Virtual reality (VR) has emerged as a transformative tool in neuroscience research, offering a novel approach to study the intricate workings of the human brain. This abstract provides an overview of the growing intersection between neuroscience and virtual reality, highlighting the potential it holds for understanding the brain’s functions, perception, and behavior. By immersing users in digitally simulated environments, VR enables researchers to probe neural responses to various stimuli and conditions while maintaining a high degree of experimental control. This abstract explores the advantages of VR in neuroscience, such as the ability to investigate spatial cognition, perception, and emotional responses in ecologically valid settings. Moreover, it discusses the challenges and future prospects of VR applications in neuroscience, including the integration of real-time neuroimaging, the development of immersive therapeutic interventions, and the ethical considerations surrounding the use of VR in research. The abstract concludes with an emphasis on the promise of VR as a valuable tool in unraveling the mysteries of the brain, ultimately fostering a deeper understanding of neurological disorders and human cognition.","","979-8-3503-0641-5","10.1109/IITCEE59897.2024.10467267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10467267","Therapeutic interventions;Neuroimaging;Spatial cognition;Human cognition","Neurological diseases;Neuroimaging;Ethics;Neuroscience;Three-dimensional displays;Medical services;Immersive experience","","1","","20","IEEE","20 Mar 2024","","","IEEE","IEEE Conferences"
"A Lightweight Deep Learning Model for EEG Classification Across Visual Stimuli","Y. Liu; S. Goh; T. Low; Z. Quince; S. Teragawa","University of Southern Queensland, Toowoomba, Australia; University of Southern Queensland, Toowoomba, Australia; University of Southern Queensland, Toowoomba, Australia; University of Southern Queensland, Toowoomba, Australia; Dalian University of Technology, Dalian, China",2024 27th International Conference on Computer Supported Cooperative Work in Design (CSCWD),"10 Jul 2024","2024","","","2900","2905","Visual stimuli have a multifaceted impact on brain activity, yet the nuanced differences in how various types of stimuli affect electroencephalogram (EEG) signals are still under investigation. This study endeavors to classify EEG signals in response to a range of visual stimuli by crafting a lightweight deep learning model. Utilizing the 170 EEG dataset from the ERP core, which encompasses recordings from 40 healthy participants exposed to roughly 10-minute sessions of randomly presented sets of normal and scrambled photographs. Each set consisted of images portraying either normal or scrambled representations of faces and cars, encapsulating four unique visual stimuli. By harnessing the EEG data from the 40 participants, our Reset18-based model attained an impressive average classification accuracy of 98.13% for face images and 97.81% for car images, significantly surpassing the performance of traditional machine learning models. otably, this marks the inaugural application of the Reset18 model to the 170 dataset classification experiment within the ERP core. The findings of this study enrich our comprehension of the brain’s distinct cognitive responses to these stimuli and the manifestation of these differences in EEG signals. The successful deployment of this model paves the way for furthering the exploration and development of brain-computer interface technologies.","2768-1904","979-8-3503-4918-4","10.1109/CSCWD61410.2024.10580396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10580396","EEG;Deep learning;Classification;Visual stimuli","Deep learning;Visualization;Accuracy;Computational modeling;Brain modeling;Feature extraction;Electroencephalography","","","","37","IEEE","10 Jul 2024","","","IEEE","IEEE Conferences"
"Spelling With a Small Mobile Brain-Computer Interface in a Moving Wheelchair","Q. T. Obeidat; T. A. Campbell; J. Kong","Computer Science Department, Al-Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia; Institute of Behavioral Sciences, University of Helsinki, Helsinki, Finland; Department of Computer Science, North Dakota State University, Fargo, ND, USA",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"9 Nov 2017","2017","25","11","2169","2179","Research into brain-computer interfaces (BCIs), which spell words using brain signals, has revealed that a desktop version of such a speller, the edges paradigm, offers several advantages: This edges paradigm outperforms the benchmark row-column paradigm in terms of accuracy, bitrate, and user experience. It has remained unknown whether these advantages prevailed with a new version of the edges paradigm designed for a mobile device. This paper investigated and evaluated in a rolling wheelchair a mobile BCI, which implemented the edges paradigm on small displays with which visual crowding tends to occur. How the mobile edge paradigm outperforms the mobile row-column paradigm has implications for understanding how principles of visual neurocognition affect BCI speller use in a mobile context. This investigation revealed that all the advantages of the edges paradigm over the row-column paradigm prevailed in this setting. However, the reduction in adjacent errors for the edges paradigm was unprecedentedly limited to horizontal adjacent errors. The interpretation offered is that dimensional constraints of visual interface design on a smartphone thus affected the neurocognitive processes of crowding.","1558-0210","","10.1109/TNSRE.2017.2700025","National Science Foundation(grant numbers:CNS-1126570); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7915770","Brain-computer interface (BCI);edges paradigm (EP);event-related potentials (ERP);P300 speller;row-column paradigm (RCP);smartphone","Mobile communication;Electroencephalography;Visualization;Mobile handsets;Benchmark testing;Fatigue;Wheelchairs","Adult;Algorithms;Brain-Computer Interfaces;Cognition;Communication Aids for Disabled;Event-Related Potentials, P300;Female;Healthy Volunteers;Humans;Male;Photic Stimulation;Psychomotor Performance;Smartphone;Software;Visual Perception;Wheelchairs;Young Adult","11","","58","IEEE","2 May 2017","","","IEEE","IEEE Journals"
"Adding Real-Time Bayesian Ranks to Error-Related Potential Scores Improves Error Detection and Auto-Correction in a P300 Speller","T. Zeyl; E. Yin; M. Keightley; T. Chau","Bloorview Research Institute, Toronto, Canada; College of Mechatronic Engineering and Automation, National University of Defense Technology, Changsha, China; Bloorview Research Institute, Toronto, Canada; Bloorview Research Institute, Toronto, Canada",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"6 Jan 2016","2016","24","1","46","56","Brain-computer interface (BCI) spellers could improve access to communication for people with profound physical disabilities; however, improved speed and accuracy of these spellers is required to make them practical for everyday use. Here we introduce the combination of P300-speller confidence with the error-related potential (ErrP) to improve online single-trial error detection and correction accuracies in a BCI speller. First, we present a mechanism for obtaining P300-confidence using a real-time Bayesian dynamic stopping framework that makes novel use of additional stimuli that occur due to epoch and filter delays. Second, we propose an ensemble of decision trees to combine ErrP and P300-confidence features. Third, we describe the unique attentional differences between error and correct feedback in our spelling interface and discuss how these differences affect ErrP physiology. We tested online error detection on 11 typically developed adults using a BCI system trained on a previous day and found an average sensitivity of 86.67% and specificity of 96.59%. Automatic correction increased selection accuracy by 13.67% and utility grew by a factor of 4.48. We found, however, that the improved performance was primarily attributable to the inclusion of P300 confidence in error detection, calling into question the significance of single-trial ErrP detection.","1558-0210","","10.1109/TNSRE.2015.2461495","National Natural Science Foundation of China(grant numbers:61375117,71201148,61420106001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217833","Brain–computer interface;dynamic stopping;EEG;error-related potential;P300 speller","Ash;Detectors;Training;Accuracy;Delays;Real-time systems;Electroencephalography","Adult;Algorithms;Bayes Theorem;Brain-Computer Interfaces;Communication Aids for Disabled;Computer Peripherals;Electroencephalography;Event-Related Potentials, P300;Evoked Potentials, Visual;Female;Humans;Male;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Task Performance and Analysis;Word Processing;Young Adult","33","","55","IEEE","21 Aug 2015","","","IEEE","IEEE Journals"
"Differences in source analysis accuracy of AEP generators following FastICA and TDSEP-ICA denoising","N. Castaneda-Villa; C. J. James","SPCG, Institute of Sound and Vibration Research, University of Southampton, UK; SPCG, Institute of Sound and Vibration Research, University of Southampton, UK","4th IET International Conference on Advances in Medical, Signal and Information Processing - MEDSIP 2008","29 Aug 2008","2008","","","1","4","Different factors can affect the accuracy of the source localization of evoked potentials: the SNR of the data, the head model, and the number of sources, mention but a few. Another fundamental factor is the correct application of independent components analysis (ICA) to both filter out artefacts and select the independent components (IC) related to the neurological response. In this paper we assess the differences in the source analysis accuracy of the auditory evoked potential (AEP) generators between a temporal ICA (TDSEP-ICA) algorithm and a statistically based algorithm (FastICA) in EEG, from children with cochlear implants (CIs). The parameters used to compare both ICA algorithms and validate the source localization include: residual standard deviation, confidence ellipsoids, localization and time of best dipole fit. Here we show that pre-processing using TDSEP- ICA facilitates the identification of the AEP peaks and the source analysis procedure. The results obtained in this research could be used as objective technique for a general evaluation of the performance of children with CIs.","0537-9989","978-0-86341-934-8","10.1049/cp:20080439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4609087","FastICA;TDSEP-ICA;Source analysis;Auditory Evoked Potentials;Cochlear Implants","","","","","","","29 Aug 2008","","","IET","IET Conferences"
"The effect of static and dynamic visual stimulations on error-evoked brain responses","R. Xu; Y. Wang; N. Wang; X. Shi; L. Meng; D. Ming","Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, China; Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, China; Department of Biomedical Engineering, Tianjin University, Tianjin, China; Department of Biomedical Engineering, Tianjin University, Tianjin, China; Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, China; Academy of Medical Engineering and Translational Medicine, Tianjin University, Tianjin, China",2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),"27 Aug 2020","2020","","","2877","2880","Error-related potentials (ErrPs) can reflect the brain's response to errors. Recently, it has been used in the studies on neural mechanisms of human cognition, such as error detection and conflict monitoring. Moreover, ErrPs have provided technical support for the development of brain-computer interface (BCI). However, the different effects of visual stimulation modes (dynamic or static) on ErrPs have not been revealed. This may seriously affect the recognition accuracy of the ErrPs in practical applications. Therefore, the aim of this study was to investigate how people respond to different types of visual stimulations. Nineteen participants were recruited in the ErrPs-based tasks with two visual stimulation modes (dynamic and static). The ErrPs were analyzed and the feature values (N1, P2, P3, N6 and P8, named by the occurrence time) were statistically compared. The results showed that the difference between correctness and error was reflected in P3, N6, P8 in dynamic stimulation; and N1, P3, N6 and P8 in static stimulation. In the event-related potential based on error, the differences between dynamic and static tasks were reflected in N1 and P2. In conclusion, this study found that the features with later occurrence were significantly affected by correctness and error in both cases, while the error-related change in N1 only existed under the static stimulation. We also found that the recognition of stimulation modes came earlier within about 300 ms after the start of visual stimulation.","2694-0604","978-1-7281-1990-8","10.1109/EMBC44109.2020.9175983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175983","Error-Related Potentials (ErrPs);Dynamic Visual Stimulation;Static Visual Stimulation","","Brain;Brain-Computer Interfaces;Electroencephalography;Evoked Potentials;Humans;Photic Stimulation","","","17","IEEE","27 Aug 2020","","","IEEE","IEEE Conferences"
"Modularized Brain Network for Eliminating Volume Conduction Effects","D. D. Chakladar; F. S. Liwicki","Machine Learning Group, Luleå University of Technology, Luleå, Sweden; Machine Learning Group, Luleå University of Technology, Luleå, Sweden","2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20 Jan 2025","2024","","","4212","4218","Understanding brain dynamics through connectivity networks is a growing topic of neuroscience. The volume conduction (VC) effect can be approximated as a linear mixing of the electrical fields of the brain regions, leading to spurious connectivity results. The proposed modularized brain connectivity network consists of three methods: Surface Laplacian (SL), partial correlation, and phase lag index (PLI) to eliminate VC effects from the brain connectivity network. SL is initially applied to the raw Electroencephalography (EEG) signal, and Event-related potential peak-wise modules for each EEG event are identified. Next, the optimum EEG channels are selected using the partial correlation method, and the source channel of each module is identified. Finally, the resultant brain connectivity network is constructed by adding the edges (i.e., PLI value) between the source channels of two modules. The experiment is performed on an EEG-based driving dataset. The performance of the proposed brain network for each driving event is evaluated based on graph measures such as mean local efficiency (MLE) and global efficiency (GE). After eliminating the VC effects, the modularized brain connectivity network significantly improves information processing rates (in terms of graph measures) across the brain region. We achieved maximum average GE (AGE) and average MLE (AMLE) values of 0.742 and 0.825 with the proposed brain network.","","978-1-6654-1020-5","10.1109/SMC54092.2024.10831826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10831826","","Location awareness;Maximum likelihood estimation;Electric potential;Correlation;Neuroscience;Laplace equations;Information processing;Germanium;Electroencephalography;Indexes","","1","","28","IEEE","20 Jan 2025","","","IEEE","IEEE Conferences"
"Cue Competition Affects Temporal Dynamics of Edge-assignment in Human Visual Cortex","J. L. Brooks; S. E. Palmer","1University College London; 2University of California, Berkeley",Journal of Cognitive Neuroscience,"19 May 2014","2011","23","3","631","644","Edge-assignment determines the perception of relative depth across an edge and the shape of the closer side. Many cues determine edge-assignment, but relatively little is known about the neural mechanisms involved in combining these cues. Here, we manipulated extremal edge and attention cues to bias edge-assignment such that these two cues either cooperated or competed. To index their neural representations, we flickered figure and ground regions at different frequencies and measured the corresponding steady-state visual-evoked potentials (SSVEPs). Figural regions had stronger SSVEP responses than ground regions, independent of whether they were attended or unattended. In addition, competition and cooperation between the two edge-assignment cues significantly affected the temporal dynamics of edge-assignment processes. The figural SSVEP response peaked earlier when the cues causing it cooperated than when they competed, but sustained edge-assignment effects were equivalent for cooperating and competing cues, consistent with a winner-take-all outcome. These results provide physiological evidence that figure–ground organization involves competitive processes that can affect the latency of figural assignment.","0898-929X","","10.1162/jocn.2010.21433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6794295","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Clustering of advertising images using electroencephalogram","I. Chanpornpakdi; M. Noda; T. Tanaka; Y. Harpaz; A. B. Geva","Tokyo University of Agriculture and Technology, Tokyo, Japan; Tokyo University of Agriculture and Technology, Tokyo, Japan; Tokyo University of Agriculture and Technology, Tokyo, Japan; Ben-Gurion University of the Negev, Beersheba, Israel; InnerEye Ltd, Herzliya, Israel",2022 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC),"21 Dec 2022","2022","","","267","274","Packaging and advertisements of brands affect customers' decision-making on purchasing products and could lead to business loss. Hence, neuromarketing, the application of neuroscience in the marketing field, is introduced aiming to understand customers' cognitive functions toward advertisements or products. Our study focused on identifying how the brain respond to different types of advertising image of the same brand were perceived using electroencephalogram (EEG). We performed an experiment using 33 different Coca-Cola advertising images in RSVP (rapid serial visual presentation) task on 23 participants. A seven channels EEG dry headset was used to record the visual event-related potential (ERP), specifically, the positive peak found at 300 to 700 ms after image onset; P300, to compare the perception response. We applied k-means and hierarchical clustering to the obtained EEG data, and achieved the best clustering for three clusters, yielding different P300 amplitudes and latencies. The typical Coca-Cola ads, red color with Cola-cola text on the ads, induced a faster and larger response, implying better perception than the unconventional or black color ads. We conclude that ERP clustering may be a useful tool for neuromarketing. However, the relationship between the EEG-based cluster and the image-based cluster should be further investigated to confirm the suggestion.","2640-0103","978-616-590-477-3","10.23919/APSIPAASC55919.2022.9980161","JSPS Kakenhi(grant numbers:20H00235); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9980161","","Headphones;Visualization;Electric potential;Image color analysis;Neuromarketing;Information processing;Packaging","","","","17","","21 Dec 2022","","","IEEE","IEEE Conferences"
"Regression Prediction of Perceptual Integration Capabilities and N270 Component Using Enhanced Electroencephalography Network","C. Chen; Y. Ma; C. Wang","School of Electrical Engineering and Automation, Tianjin University of Technology, Tianjin, China; School of Electrical Engineering and Automation, Tianjin University of Technology, Tianjin, China; Xuanwu Hospital, Capital Medical University, Beijing, China",2024 IEEE 25th China Conference on System Simulation Technology and its Application (CCSSTA),"1 Oct 2024","2024","","","182","187","This study aims to investigate the brain electrical signals and perceptual integration abilities of pilots in low-visibility flight environments, focusing on the N270 event-related potential (ERP). The N270 occurs approximately 200 to 300 milliseconds after receiving visual stimuli and primarily appears in the parieto-occipital and occipital areas of the brain. It reflects the brain’s activities in processing visual information, attention allocation, emotional processing, and cognitive control, particularly in response to visual stimuli such as faces and facial expressions. To assess and predict pilots’ cognitive abilities under low-visibility conditions, this study designed a new deep learning algorithm called Enhanced Generative Encoder Network(EGEnet). Building on the existing EEGNet model, EGEnet incorporates residual modules, normalization layers, and dropout layers to enhance feature learning capabilities and model stability. Through automated feature extraction and regression prediction, EGEnet effectively evaluates pilots’ perceptual integration abilities. Moreover, EGEnet demonstrates high accuracy and robustness in processing and reconstructing brain electrical data. This study provides a novel method for individual pilot assessment, promoting the development of intelligent and personalized training and technical support based on passive auditory ERP paradigms.","","979-8-3503-6660-0","10.1109/CCSSTA62096.2024.10691804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10691804","N270;deep learning;Enhanced Generative Encoder Network(EGEnet);regression prediction","Training;Representation learning;Visualization;Process control;Brain modeling;Prediction algorithms;Stability analysis;Robustness;Systems simulation;Resource management","","","","21","IEEE","1 Oct 2024","","","IEEE","IEEE Conferences"
"Age-related Electrophysical Correlates of Cross-modal Attention Switching","P. -C. Huang; L. A. P. Schils; I. Koch; D. N. Stephan; S. Hsieh","National Cheng Kung University, Tainan, Taiwan; RWTH Aachen University; RWTH Aachen University; RWTH Aachen University; National Cheng Kung University, Tainan, Taiwan",Journal of Cognitive Neuroscience,"3 Jan 2025","2025","37","1","43","62","The human experience demands seamless attentional switches between sensory modalities. Aging raises questions about how declines in auditory and visual processing affect cross-modal attention switching. This study used a cued cross-modal attention-switching paradigm where visual and auditory stimuli were simultaneously presented on either spatially congruent or incongruent sides. A modality cue indicated the target modality, requiring a spatially left versus right key-press response. EEG recordings were collected during task performance. We investigated whether the mixing costs (decreased performance for repetition trials in a mixed task compared with a single task) and switch costs (decreased performance for a switch of target modality compared with a repetition) in cross-modal attention-switching paradigms would exhibit similarities in terms of behavioral performance and the ERP components to those observed in the traditional unimodal attention-switching paradigms. Specifically, we focused on the ERP components: cue-locked P3 (mixing/switch-related increased positivity), target-locked P3 (mixing/switch-related decreased positivity), and target-locked lateralized readiness potential (mixing/switch-related longer latency). In addition, we assessed how aging impacts cross-modal attention-switching performance. Results revealed that older adults exhibited more pronounced mixing and switch costs than younger adults, especially when visual and auditory stimuli were presented on incongruent sides. ERP findings showed increased cue-locked P3 amplitude, prolonged cue-locked P3 latency, decreased target-locked P3 amplitude, prolonged target-locked P3 latency in association with switch costs, and prolonged onset latency of the target-locked lateralized readiness potential in association with the mixing costs. Age-related effects were significant only for cue-locked P3 amplitude, cue-locked P3 latency (switch-related), and target-locked P3 latency (switch-related). These findings suggest that the larger mixing costs and switch costs in older adults were due to the inefficient use of modality cues to update a representation of the relevant task sets, requiring more processing time for evaluating and categorizing the target.","0898-929X","","10.1162/jocn_a_02248","Deutsche Forschungsgemeinschaft(grant numbers:STE 2466/1-1); National Science and Technology Council(grant numbers:109-2923-H-006-002-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10824758","","","","","","","CCBY","3 Jan 2025","","","MIT Press","MIT Press Journals"
"Non-Invasive, Cost-Effective, Early Diagnosis of Mild Cognitive Impairment in an Outpatient Setting: Pilot Study","A. T. White; R. B. Merino; S. Hardin; S. Kim","East Carolina University, Greenville, NC, US; East Carolina University, Greenville, NC, US; East Carolina University, Greenville, NC, US; East Carolina University, Greenville, NC, US",2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"28 Oct 2018","2018","","","13","16","Mild cognitive impairment (MCI) and Alzheimer's Disease (AD) affect millions worldwide, yet no curative treatments for these neuro-degenerative disorders have been developed to date. The current study aims to propose a noninvasive, cost-effective, early diagnostic protocol for individuals suffering with MCI in an outpatient setting. Elderly participants (n=11) were screened for MCI utilizing the Montreal Cognitive Assessment (MoCA) questionnaire preceding a visual stimuli task. Participants were presented with facial stimuli to elicit event related potentials (ERP) while their cortical activity was recorded utilizing electroencephalogram (EEG). Combining regional neurophysiological biomarkers into a multidimensional feature space allowed for differentiation between healthy and MCI participants based on their respective MoCA scores. This study illustrates the feasibility of recording reliable EEG in an outpatient setting while presenting a novel method for diagnosing MCI in elderly (age >60) populations.","1558-4615","978-1-5386-3646-6","10.1109/EMBC.2018.8512268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8512268","","Statistics;Electrodes;Biomarkers;Electroencephalography;Diseases;Senior citizens","Aged;Alzheimer Disease;Cognitive Dysfunction;Early Diagnosis;Electroencephalography;Evoked Potentials;Female;Humans;Male;Middle Aged;Neuropsychological Tests;Outpatients;Pilot Projects;Surveys and Questionnaires","3","","18","IEEE","28 Oct 2018","","","IEEE","IEEE Conferences"
"Endogenous Attention Affects Decision-related Neural Activity but Not Afferent Visual Responses","A. Morrow; A. Pilipenko; E. Turkovich; S. Sankaran; J. Samaha","University of California, Santa Cruz; University of California, Santa Cruz; University of California, Santa Cruz; University of California, Santa Cruz; University of California, Santa Cruz",Journal of Cognitive Neuroscience,"29 Oct 2024","2024","36","11","2481","2494","Endogenous shifts of spatial attention toward an upcoming stimulus are associated with improvements in behavioral responses to the stimulus, preparatory retinotopic shifts in alpha power, and changes in ERPs. Although attentional modulation of several early sensory ERPs is well established, there is still debate about under what circumstances attention affects the earliest cortical visual evoked response—the C1 ERP component—which is putatively generated from afferent input into primary visual cortex. Moreover, the effects of spatial attention on the recently discovered ERP signature of evidence accumulation—the central parietal positivity (CPP)—have not been fully characterized. The present study assessed the effect of spatial attention on the C1 and CPP components through a spatially cued contrast discrimination task using stimuli that were specifically designed to produce large-amplitude C1 responses and that varied in sensory evidence strength to characterize the CPP. Participants responded according to which of two checkerboard stimuli had greater contrast following an 80% valid cue toward the upper or lower visual field. Prestimulus alpha power changed topographically based on the cue, suggesting participants shifted attention to prepare for the upcoming stimuli. Despite these attentional shifts in alpha power and the fact that the stimuli reliably elicited C1 responses several times greater than many prior studies, there was no evidence of an attention effect on the C1. The CPP, however, showed a clear increase in build-up rate on valid trials. Our findings suggest that endogenous attention may not affect the early C1 ERP component but may improve behavior at a decision stage, as reflected in brain signals related to evidence accumulation (the CPP).","0898-929X","","10.1162/jocn_a_02239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10738327","","","","","","","","29 Oct 2024","","","MIT Press","MIT Press Journals"
"A Special Role of Syllables, But Not Vowels or Consonants, for Nonadjacent Dependency Learning","I. Weyers; J. L. Mueller",University of Vienna; University of Vienna,Journal of Cognitive Neuroscience,"25 Oct 2022","2022","34","8","1467","1487","Successful language processing entails tracking (morpho)syntactic relationships between distant units of speech, so-called nonadjacent dependencies (NADs). Many cues to such dependency relations have been identified, yet the linguistic elements encoding them have received little attention. In the present investigation, we tested whether and how these elements, here syllables, consonants, and vowels, affect behavioral learning success as well as learning-related changes in neural activity in relation to item-specific NAD learning. In a set of two EEG studies with adults, we compared learning under conditions where either all segment types (Experiment 1) or only one segment type (Experiment 2) was informative. The collected behavioral and ERP data indicate that, when all three segment types are available, participants mainly rely on the syllable for NAD learning. With only one segment type available for learning, adults also perform most successfully with syllable-based dependencies. Although we find no evidence for successful learning across vowels in Experiment 2, dependencies between consonants seem to be identified at least passively at the phonetic-feature level. Together, these results suggest that successful item-specific NAD learning may depend on the availability of syllabic information. Furthermore, they highlight consonants' distinctive power to support lexical processes. Although syllables show a clear facilitatory function for NAD learning, the underlying mechanisms of this advantage require further research.","0898-929X","","10.1162/jocn_a_01874","Deutsche Forschungsgemeinschaft(grant numbers:MU 3112/3-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9928127","","","","","","","CCBY","25 Oct 2022","","","MIT Press","MIT Press Journals"
"Global Semantic Expectancy and Language Comprehension","M. S. George; S. Mannes; J. E. Hoffinan",NA; NA; University of Delaware,Journal of Cognitive Neuroscience,"19 May 2014","1994","6","1","70","83","Previous research on the N400 component of the event-related brain potential (ERP) has dealt primarily with measuring the degree of expectancy on the part of the reader as a result of the context within a sentence. Research has shown that when the final word in a sentence is unexpected or incoherent, a greater N400 amplitude is elicited than if the final word is expected or coherent within the context of the sentence. The present study investigated whether the N400 component is sensitive to global, as well as local, semantic expectancy. Global coherence refers to the ease with which subjects can relate the current proposition they are reading with theme-related ideas. In the present study, the effect of global coherence on event-related brain potentials was tested using four titled and untitled paragraphs (Bransford & Johnson, 1972; Dooling & Lachman, 1971), presented one word at a time. These paragraphs are noncoherent, and are made coherent only with the presentation of a title. The EEG was recorded in response to every word in all four paragraphs. We found an increase in N400 amplitude in response to the words in the Untitled paragraphs relative to the Titled paragraphs, indicating that global coherence does affect the N400. In addition, subjects in the Titled group showed an enhanced P1-N1 component relative to the Untitled group suggesting that the presence of global coherence allows greater attention to be allocated to early visual processing of words.","0898-929X","","10.1162/jocn.1994.6.1.70","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6793651","","","","1","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Neurophysiological Correlates of Motor and Working Memory Performance following Subthalamic Nucleus Stimulation","K. Selzler; M. Burack; R. Bender; M. Mapstone",NA; NA; NA; NA,Journal of Cognitive Neuroscience,"19 May 2014","2013","25","1","37","48","Subthalamic nucleus (STN) deep brain stimulation (DBS) has become an accepted treatment for the motor manifestations of Parkinson disease (PD). The beneficial motor effects of STN DBS are likely due to modulation of BG output to frontal cortical regions associated with motor control, but the underlying neurophysiology of STN DBS effects, especially at the level of the cortex, is not well understood. In this study, we examined the effects of STN DBS on motor disability and visual working memory, a cognitive process supported by pFC. We tested 10 PD participants off medications, ON and OFF stimulation, along with 20 normal controls on a visual working memory task while simultaneously recording cortical EEG. In the OFF state, PD patients had poor motor function, were slower and less accurate in performing the working memory task, and had greater amplitudes and shorter latencies of the N200 ERP response. DBS improved clinical motor function, reduced N200 amplitudes, and increased N200 latencies but had little effect on working memory performance. We conclude that STN DBS normalizes neurophysiological activity in fronto striatal circuits and this may independently affect motor and cognitive function.","0898-929X","","10.1162/jocn_a_00306","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6794879","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Table of contents","",,2013 International Winter Workshop on Brain-Computer Interface (BCI),"22 Apr 2013","2013","","","1","4","The following topics are dealt with: stroke rehabilitation; mobile real-time EEG imaging; high-performance neural prosthetics; sonication-based brain-brain interfacing; cognitive brain state decoding; EEG-based person authentication; EEG-based brain-computer interface; ECoG signal classification; EEG-based emotion recognition; neurosensory tissue image; steady-state visual evoked potential; and fMRI-based BCI.","","978-1-4673-5974-0","10.1109/IWW-BCI.2013.6506651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6506651","","","","","","","IEEE","22 Apr 2013","","","IEEE","IEEE Conferences"
